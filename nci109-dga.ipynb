{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511ecc73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:05.496102Z",
     "iopub.status.busy": "2024-06-16T13:04:05.495704Z",
     "iopub.status.idle": "2024-06-16T13:04:21.452983Z",
     "shell.execute_reply": "2024-06-16T13:04:21.451435Z"
    },
    "papermill": {
     "duration": 15.971309,
     "end_time": "2024-06-16T13:04:21.455873",
     "exception": false,
     "start_time": "2024-06-16T13:04:05.484564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.5.3\r\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'NCI109'\n",
    "if 'first_run' not in globals():\n",
    "    !pip install torch torch-geometric\n",
    "    first_run = False\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5620b5d9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:21.476973Z",
     "iopub.status.busy": "2024-06-16T13:04:21.476466Z",
     "iopub.status.idle": "2024-06-16T13:04:28.902197Z",
     "shell.execute_reply": "2024-06-16T13:04:28.900698Z"
    },
    "papermill": {
     "duration": 7.439895,
     "end_time": "2024-06-16T13:04:28.905379",
     "exception": false,
     "start_time": "2024-06-16T13:04:21.465484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.io import fs, read_txt_array\n",
    "import torch_geometric.transforms as T\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import math\n",
    "from typing import Callable, List, Optional, Tuple, Dict\n",
    "from torch import Tensor\n",
    "import os\n",
    "import requests\n",
    "from torch_geometric.utils import coalesce, cumsum, one_hot, remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa5a17d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:28.927580Z",
     "iopub.status.busy": "2024-06-16T13:04:28.926239Z",
     "iopub.status.idle": "2024-06-16T13:04:28.933404Z",
     "shell.execute_reply": "2024-06-16T13:04:28.932142Z"
    },
    "papermill": {
     "duration": 0.020733,
     "end_time": "2024-06-16T13:04:28.935926",
     "exception": false,
     "start_time": "2024-06-16T13:04:28.915193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MyTransform(BaseTransform):\n",
    "#     def __init__(self, set_ids = False, indices = None, set_initial_features=False, embedding=None, cos_sim=None, z_score=None):\n",
    "#         super(MyTransform, self).__init__()\n",
    "#         self.current_id = 0  # Initialize a counter for unique IDs\n",
    "#         self.set_initial_features = set_initial_features\n",
    "#         self.embedding = embedding  # Assume this is a function if not None\n",
    "#         self.cos_sim = cos_sim      # Assume this is a dictionary or list if not None\n",
    "#         self.z_score = z_score      # Assume this is a dictionary or list if not None\n",
    "#         self.indices = indices\n",
    "#         if set_ids:\n",
    "#             self.assign_ids()\n",
    "\n",
    "#     def assign_ids(self):\n",
    "#         # Create an ID tensor for all data points\n",
    "#         id_tensor = torch.arange(self.indices)\n",
    "#         for i, data in enumerate(self):\n",
    "#             data.id = id_tensor[i]\n",
    "\n",
    "#     def __call__(self, data: Data) -> Data:\n",
    "#         # Assign a unique ID and increment the counter\n",
    "#         if self.set_initial_features:\n",
    "#             data.id = self.current_id\n",
    "#             self.current_id += 1\n",
    "#             data.num_edges = data.edge_index.size(1)  # Number of edges\n",
    "#             data.adj_mat = self.to_numpy_adj(data)  # Convert edge index to adjacency matrix\n",
    "\n",
    "#         if self.embedding:\n",
    "#             data.embedding = self.embedding[data.id] # Assume embedding function takes Data and modifies it\n",
    "\n",
    "#         if self.cos_sim is not None:\n",
    "#             data.cos_sim = self.cos_sim[data.id]  # Fetch cosine similarity based on ID\n",
    "\n",
    "#         if self.z_score is not None:\n",
    "#             data.z_score = self.z_score[data.id]  # Fetch z-score based on ID\n",
    "\n",
    "#         return data\n",
    "\n",
    "#     def to_numpy_adj(self, data):\n",
    "#         # Creates an adjacency matrix from edge_index\n",
    "#         adj_mat = np.zeros((data.num_nodes, data.num_nodes))\n",
    "#         edge_index = data.edge_index.numpy()\n",
    "#         adj_mat[edge_index[0], edge_index[1]] = 1\n",
    "#         return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470b9636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:28.956785Z",
     "iopub.status.busy": "2024-06-16T13:04:28.956353Z",
     "iopub.status.idle": "2024-06-16T13:04:28.964537Z",
     "shell.execute_reply": "2024-06-16T13:04:28.962994Z"
    },
    "papermill": {
     "duration": 0.021664,
     "end_time": "2024-06-16T13:04:28.967221",
     "exception": false,
     "start_time": "2024-06-16T13:04:28.945557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IDAddingDataset:\n",
    "    def __init__(self, dataset, attr_func):\n",
    "        self.dataset = dataset\n",
    "        self.attr_func = attr_func\n",
    "        self.indices = np.arange(0, len(dataset.indices()))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.id = self.indices[idx]\n",
    "        data.num_edges = self.dataset[idx].edge_index.size(1)\n",
    "        data.adj_mat = to_scipy_sparse_matrix(self.dataset[idx].edge_index, num_nodes=self.dataset[idx].num_nodes).toarray().astype(int)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dc1024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:28.990289Z",
     "iopub.status.busy": "2024-06-16T13:04:28.988676Z",
     "iopub.status.idle": "2024-06-16T13:04:28.996984Z",
     "shell.execute_reply": "2024-06-16T13:04:28.995667Z"
    },
    "papermill": {
     "duration": 0.022514,
     "end_time": "2024-06-16T13:04:28.999609",
     "exception": false,
     "start_time": "2024-06-16T13:04:28.977095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingAddingDataset:\n",
    "    def __init__(self, dataset, embedding_dict):\n",
    "        self.dataset = dataset\n",
    "        self.embedding_dict = embedding_dict\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.embedding = self.embedding_dict[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872db4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.022462Z",
     "iopub.status.busy": "2024-06-16T13:04:29.021681Z",
     "iopub.status.idle": "2024-06-16T13:04:29.029362Z",
     "shell.execute_reply": "2024-06-16T13:04:29.027975Z"
    },
    "papermill": {
     "duration": 0.021887,
     "end_time": "2024-06-16T13:04:29.032039",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.010152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalAddingDataset:\n",
    "    def __init__(self, Embedding_dataset, cos_sims, all_z_scores):\n",
    "        self.dataset = Embedding_dataset\n",
    "        self.cos_sims = cos_sims\n",
    "        self.all_z_scores = all_z_scores\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.cos_sim = self.cos_sims[self.dataset[idx].id]\n",
    "        data.z_score = self.all_z_scores[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04fb4a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.054281Z",
     "iopub.status.busy": "2024-06-16T13:04:29.052846Z",
     "iopub.status.idle": "2024-06-16T13:04:29.062230Z",
     "shell.execute_reply": "2024-06-16T13:04:29.060788Z"
    },
    "papermill": {
     "duration": 0.023016,
     "end_time": "2024-06-16T13:04:29.064793",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.041777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stable_hash(value):\n",
    "    return hashlib.md5(str(value).encode()).hexdigest()\n",
    "def get_WL_embedding(data, n_iter):\n",
    "    graph = data.adj_mat\n",
    "    graph_hash_dict = {}\n",
    "    labels = [np.sum(graph[x]) for x in range(len(graph))]  # Initialize labels based on node degrees\n",
    "    for _ in range(n_iter):\n",
    "        neighbor_labels = [sorted([labels[j] for j in range(len(graph)) if graph[i, j] == 1]) for i in range(len(graph))]\n",
    "        hashes = np.array([stable_hash((labels[i], tuple(neighbor_labels[i]))) for i in range(len(graph))])\n",
    "        \n",
    "        for unique_hash in set(hashes):\n",
    "            graph_hash_dict[unique_hash] = np.sum(hashes == unique_hash)\n",
    "\n",
    "        labels = hashes.tolist()\n",
    "\n",
    "    return graph_hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec8e976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.086221Z",
     "iopub.status.busy": "2024-06-16T13:04:29.085842Z",
     "iopub.status.idle": "2024-06-16T13:04:29.102035Z",
     "shell.execute_reply": "2024-06-16T13:04:29.100828Z"
    },
    "papermill": {
     "duration": 0.030056,
     "end_time": "2024-06-16T13:04:29.104835",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.074779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_vectors(dataset):\n",
    "    all_hashes = set()\n",
    "    all_classes = set()\n",
    "    for graph in dataset:\n",
    "        all_hashes.update(graph.embedding.keys())\n",
    "        all_classes.add(graph.y.item())\n",
    "    all_classes.add('all')\n",
    "\n",
    "    vector_sum_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    category_sum_dict = {_cls: 0 for _cls in all_classes}\n",
    "    mean_vector_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    \n",
    "    \n",
    "    for graph in dataset:\n",
    "        for _hash, count in graph.embedding.items():\n",
    "            vector_sum_dict[graph.y.item()][_hash] += count\n",
    "            category_sum_dict[graph.y.item()] += 1\n",
    "            vector_sum_dict['all'][_hash] += count\n",
    "            category_sum_dict['all'] += 1\n",
    "    for _cls, hash_counts in vector_sum_dict.items():\n",
    "        for _hash, count in hash_counts.items():\n",
    "            mean_vector_dict[_cls][_hash] = count/category_sum_dict[_cls]\n",
    "    return all_hashes, all_classes, mean_vector_dict\n",
    "\n",
    "def get_cos_sim(dataset, all_hashes, all_classes, mean_vectors):\n",
    "    cos_sims, norm_dict = {}, {}\n",
    "    graph_norm = math.sqrt(sum(count**2 for count in graph.embedding.values()))\n",
    "    for _class in all_classes:\n",
    "        norm_dict[_class] = math.sqrt(sum(count**2 for count in mean_vectors[_class].values()))\n",
    "    all_numerator = sum(count * mean_vectors['all'][_hash] for _hash, count in graph.embedding.items())\n",
    "    all_denom = norm_dict['all'] * graph_norm\n",
    "    cos_sims['all'] = all_numerator / all_denom\n",
    "\n",
    "    class_numerator = sum(count * mean_vectors[graph.y.item()][_hash] for _hash, count in graph.embedding.items())\n",
    "    class_denom = norm_dict[graph.y.item()] * graph_norm\n",
    "    cos_sims['class'] = class_numerator / class_denom\n",
    "    \n",
    "    return cos_sims\n",
    "\n",
    "def calc_z_scores(graph, cos_sims, class_cos_sims):\n",
    "    # Ensure data types are numpy arrays for statistical computation\n",
    "    all_cos_sims = np.array(class_cos_sims['all'])\n",
    "    cat_cos_sims = np.array(class_cos_sims[graph.y.item()])\n",
    "    \n",
    "    # Calculate means and standard deviations for 'all' and specific 'class'\n",
    "    all_mean = np.mean(all_cos_sims)\n",
    "    cat_mean = np.mean(cat_cos_sims)\n",
    "    all_std_dev = np.std(all_cos_sims)\n",
    "    class_std_dev = np.std(cat_cos_sims)\n",
    "    \n",
    "    # Compute z-scores using the standard formula, include flooring to nearest 0.5 if needed\n",
    "    z_scores = {\n",
    "        'all': (cos_sims[graph.id]['all']) / all_std_dev,\n",
    "        'class': (cos_sims[graph.id]['class']) / class_std_dev\n",
    "    }\n",
    "    \n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12eeecb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.125766Z",
     "iopub.status.busy": "2024-06-16T13:04:29.125346Z",
     "iopub.status.idle": "2024-06-16T13:04:29.130531Z",
     "shell.execute_reply": "2024-06-16T13:04:29.129137Z"
    },
    "papermill": {
     "duration": 0.018689,
     "end_time": "2024-06-16T13:04:29.133279",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.114590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.io.tu import read_tu_data\n",
    "# data, slices, sizes = read_tu_data('/kaggle/working/', 'ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd544486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.156888Z",
     "iopub.status.busy": "2024-06-16T13:04:29.156462Z",
     "iopub.status.idle": "2024-06-16T13:04:29.173755Z",
     "shell.execute_reply": "2024-06-16T13:04:29.172332Z"
    },
    "papermill": {
     "duration": 0.0339,
     "end_time": "2024-06-16T13:04:29.176900",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.143000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "# from typing import Callable, List, Optional\n",
    "\n",
    "# from torch_geometric.data import Data, InMemoryDataset\n",
    "# from torch_geometric.io import fs#, read_tu_data\n",
    "\n",
    "# def read_file(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "#     name: str,\n",
    "#     dtype: Optional[torch.dtype] = None,\n",
    "# ) -> Tensor:\n",
    "#     path = osp.join(folder, f'{prefix}_{name}.txt')\n",
    "#     return read_txt_array(path, sep=',', dtype=dtype)\n",
    "# def cat(seq: List[Optional[Tensor]]) -> Optional[Tensor]:\n",
    "#     values = [v for v in seq if v is not None]\n",
    "#     values = [v for v in values if v.numel() > 0]\n",
    "#     values = [v.unsqueeze(-1) if v.dim() == 1 else v for v in values]\n",
    "#     return torch.cat(values, dim=-1) if len(values) > 0 else None\n",
    "# def split(data: Data, batch: Tensor) -> Tuple[Data, Dict[str, Tensor]]:\n",
    "#     node_slice = cumsum(torch.from_numpy(np.bincount(batch)))\n",
    "\n",
    "#     assert data.edge_index is not None\n",
    "#     row, _ = data.edge_index\n",
    "#     edge_slice = cumsum(torch.from_numpy(np.bincount(batch[row])))\n",
    "\n",
    "#     # Edge indices should start at zero for every graph.\n",
    "#     data.edge_index -= node_slice[batch[row]].unsqueeze(0)\n",
    "\n",
    "#     slices = {'edge_index': edge_slice}\n",
    "#     if data.x is not None:\n",
    "#         slices['x'] = node_slice\n",
    "#     else:\n",
    "#         # Imitate `collate` functionality:\n",
    "#         data._num_nodes = torch.bincount(batch).tolist()\n",
    "#         data.num_nodes = batch.numel()\n",
    "#     if data.edge_attr is not None:\n",
    "#         slices['edge_attr'] = edge_slice\n",
    "#     if data.y is not None:\n",
    "#         assert isinstance(data.y, Tensor)\n",
    "#         if data.y.size(0) == batch.size(0):\n",
    "#             slices['y'] = node_slice\n",
    "#         else:\n",
    "#             slices['y'] = torch.arange(0, int(batch[-1]) + 2, dtype=torch.long)\n",
    "\n",
    "#     return data, slices\n",
    "# def read_tu_data(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "# ) -> Tuple[Data, Dict[str, Tensor], Dict[str, int]]:\n",
    "#     files = fs.glob(osp.join(folder, f'{prefix}_*.txt'))\n",
    "#     names = [osp.basename(f)[len(prefix) + 1:-4] for f in files]\n",
    "\n",
    "#     edge_index = read_file(folder, prefix, 'A', torch.long).t() - 1\n",
    "#     batch = read_file(folder, prefix, 'graph_indicator', torch.long) - 1\n",
    "\n",
    "#     node_attribute = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_attributes' in names:\n",
    "#         node_attribute = read_file(folder, prefix, 'node_attributes')\n",
    "#         if node_attribute.dim() == 1:\n",
    "#             node_attribute = node_attribute.unsqueeze(-1)\n",
    "\n",
    "#     node_label = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_labels' in names:\n",
    "#         node_label = read_file(folder, prefix, 'node_labels', torch.long)\n",
    "#         if node_label.dim() == 1:\n",
    "#             node_label = node_label.unsqueeze(-1)\n",
    "#         node_label = node_label - node_label.min(dim=0)[0]\n",
    "#         node_labels = list(node_label.unbind(dim=-1))\n",
    "#         node_labels = [one_hot(x) for x in node_labels]\n",
    "#         if len(node_labels) == 1:\n",
    "#             node_label = node_labels[0]\n",
    "#         else:\n",
    "#             node_label = torch.cat(node_labels, dim=-1)\n",
    "\n",
    "#     edge_attribute = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_attributes' in names:\n",
    "#         edge_attribute = read_file(folder, prefix, 'edge_attributes')\n",
    "#         if edge_attribute.dim() == 1:\n",
    "#             edge_attribute = edge_attribute.unsqueeze(-1)\n",
    "\n",
    "#     edge_label = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_labels' in names:\n",
    "#         edge_label = read_file(folder, prefix, 'edge_labels', torch.long)\n",
    "#         if edge_label.dim() == 1:\n",
    "#             edge_label = edge_label.unsqueeze(-1)\n",
    "#         edge_label = edge_label - edge_label.min(dim=0)[0]\n",
    "#         edge_labels = list(edge_label.unbind(dim=-1))\n",
    "#         edge_labels = [one_hot(e) for e in edge_labels]\n",
    "#         if len(edge_labels) == 1:\n",
    "#             edge_label = edge_labels[0]\n",
    "#         else:\n",
    "#             edge_label = torch.cat(edge_labels, dim=-1)\n",
    "\n",
    "#     x = cat([node_attribute, node_label])\n",
    "#     edge_attr = cat([edge_attribute, edge_label])\n",
    "\n",
    "#     y = None\n",
    "#     if 'graph_attributes' in names:  # Regression problem.\n",
    "#         y = read_file(folder, prefix, 'graph_attributes')\n",
    "#     elif 'graph_labels' in names:  # Classification problem.\n",
    "#         y = read_file(folder, prefix, 'graph_labels', torch.long)\n",
    "#         _, y = y.unique(sorted=True, return_inverse=True)\n",
    "\n",
    "#     num_nodes = int(edge_index.max()) + 1 if x is None else x.size(0)\n",
    "#     edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "#     edge_index, edge_attr = coalesce(edge_index, edge_attr, num_nodes)\n",
    "#     cos_sim = torch.tensor([-1.0])\n",
    "#     z_score = torch.tensor([-1.0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data = Data(\n",
    "#         x=x,\n",
    "#         edge_index=edge_index,\n",
    "#         edge_attr=edge_attr,\n",
    "#         y=y,\n",
    "#         cos_sim=torch.tensor([-1.0]),  # Custom attribute\n",
    "#         z_score=torch.tensor([-1.0])   # Custom attribute\n",
    "#     )\n",
    "#     data, slices = split(data, batch)\n",
    "\n",
    "#     sizes = {\n",
    "#         'num_node_attributes': node_attribute.size(-1),\n",
    "#         'num_node_labels': node_label.size(-1),\n",
    "#         'num_edge_attributes': edge_attribute.size(-1),\n",
    "#         'num_edge_labels': edge_label.size(-1),\n",
    "#     }\n",
    "\n",
    "#     return data, slices, sizes\n",
    "\n",
    "# class MyTUDataset(InMemoryDataset):\n",
    "#     r\"\"\"A variety of graph kernel benchmark datasets, *.e.g.*,\n",
    "#     :obj:`\"IMDB-BINARY\"`, :obj:`\"REDDIT-BINARY\"` or :obj:`\"PROTEINS\"`,\n",
    "#     collected from the `TU Dortmund University\n",
    "#     <https://chrsmrrs.github.io/datasets>`_.\n",
    "#     In addition, this dataset wrapper provides `cleaned dataset versions\n",
    "#     <https://github.com/nd7141/graph_datasets>`_ as motivated by the\n",
    "#     `\"Understanding Isomorphism Bias in Graph Data Sets\"\n",
    "#     <https://arxiv.org/abs/1910.12091>`_ paper, containing only non-isomorphic\n",
    "#     graphs.\n",
    "\n",
    "#     .. note::\n",
    "#         Some datasets may not come with any node labels.\n",
    "#         You can then either make use of the argument :obj:`use_node_attr`\n",
    "#         to load additional continuous node attributes (if present) or provide\n",
    "#         synthetic node features using transforms such as\n",
    "#         :class:`torch_geometric.transforms.Constant` or\n",
    "#         :class:`torch_geometric.transforms.OneHotDegree`.\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Root directory where the dataset should be saved.\n",
    "#         name (str): The `name\n",
    "#             <https://chrsmrrs.github.io/datasets/docs/datasets/>`_ of the\n",
    "#             dataset.\n",
    "#         transform (callable, optional): A function/transform that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "#             version. The data object will be transformed before every access.\n",
    "#             (default: :obj:`None`)\n",
    "#         pre_transform (callable, optional): A function/transform that takes in\n",
    "#             an :obj:`torch_geometric.data.Data` object and returns a\n",
    "#             transformed version. The data object will be transformed before\n",
    "#             being saved to disk. (default: :obj:`None`)\n",
    "#         pre_filter (callable, optional): A function that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "#             value, indicating whether the data object should be included in the\n",
    "#             final dataset. (default: :obj:`None`)\n",
    "#         force_reload (bool, optional): Whether to re-process the dataset.\n",
    "#             (default: :obj:`False`)\n",
    "#         use_node_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous node attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         use_edge_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous edge attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         cleaned (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain only non-isomorphic graphs. (default: :obj:`False`)\n",
    "\n",
    "#     **STATS:**\n",
    "\n",
    "#     .. list-table::\n",
    "#         :widths: 20 10 10 10 10 10\n",
    "#         :header-rows: 1\n",
    "\n",
    "#         * - Name\n",
    "#           - #graphs\n",
    "#           - #nodes\n",
    "#           - #edges\n",
    "#           - #features\n",
    "#           - #classes\n",
    "#         * - MUTAG\n",
    "#           - 188\n",
    "#           - ~17.9\n",
    "#           - ~39.6\n",
    "#           - 7\n",
    "#           - 2\n",
    "#         * - ENZYMES\n",
    "#           - 600\n",
    "#           - ~32.6\n",
    "#           - ~124.3\n",
    "#           - 3\n",
    "#           - 6\n",
    "#         * - PROTEINS\n",
    "#           - 1,113\n",
    "#           - ~39.1\n",
    "#           - ~145.6\n",
    "#           - 3\n",
    "#           - 2\n",
    "#         * - COLLAB\n",
    "#           - 5,000\n",
    "#           - ~74.5\n",
    "#           - ~4914.4\n",
    "#           - 0\n",
    "#           - 3\n",
    "#         * - IMDB-BINARY\n",
    "#           - 1,000\n",
    "#           - ~19.8\n",
    "#           - ~193.1\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - REDDIT-BINARY\n",
    "#           - 2,000\n",
    "#           - ~429.6\n",
    "#           - ~995.5\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - ...\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#     \"\"\"\n",
    "\n",
    "#     url = 'https://www.chrsmrrs.com/graphkerneldatasets'\n",
    "#     cleaned_url = ('https://raw.githubusercontent.com/nd7141/'\n",
    "#                    'graph_datasets/master/datasets')\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         root: str,\n",
    "#         name: str,\n",
    "#         transform: Optional[Callable] = None,\n",
    "#         pre_transform: Optional[Callable] = None,\n",
    "#         pre_filter: Optional[Callable] = None,\n",
    "#         force_reload: bool = False,\n",
    "#         use_node_attr: bool = False,\n",
    "#         use_edge_attr: bool = False,\n",
    "#         cleaned: bool = False,\n",
    "#     ) -> None:\n",
    "#         self.name = name\n",
    "#         self.cleaned = cleaned\n",
    "#         super().__init__(root, transform, pre_transform, pre_filter,\n",
    "#                          force_reload=force_reload)\n",
    "\n",
    "#         out = fs.torch_load(self.processed_paths[0])\n",
    "#         if not isinstance(out, tuple) or len(out) < 3:\n",
    "#             raise RuntimeError(\n",
    "#                 \"The 'data' object was created by an older version of PyG. \"\n",
    "#                 \"If this error occurred while loading an already existing \"\n",
    "#                 \"dataset, remove the 'processed/' directory in the dataset's \"\n",
    "#                 \"root folder and try again.\")\n",
    "#         assert len(out) == 3 or len(out) == 4\n",
    "\n",
    "#         if len(out) == 3:  # Backward compatibility.\n",
    "#             data, self.slices, self.sizes = out\n",
    "#             data_cls = Data\n",
    "#         else:\n",
    "#             data, self.slices, self.sizes, data_cls = out\n",
    "\n",
    "#         if not isinstance(data, dict):  # Backward compatibility.\n",
    "#             self.data = data\n",
    "#         else:\n",
    "#             self.data = data_cls.from_dict(data)\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         if self._data.x is not None and not use_node_attr:\n",
    "#             num_node_attributes = self.num_node_attributes\n",
    "#             self._data.x = self._data.x[:, num_node_attributes:]\n",
    "#         if self._data.edge_attr is not None and not use_edge_attr:\n",
    "#             num_edge_attrs = self.num_edge_attributes\n",
    "#             self._data.edge_attr = self._data.edge_attr[:, num_edge_attrs:]\n",
    "\n",
    "#     @property\n",
    "#     def raw_dir(self) -> str:\n",
    "#         name = f'raw{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def processed_dir(self) -> str:\n",
    "#         name = f'processed{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def num_node_labels(self) -> int:\n",
    "#         return self.sizes['num_node_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_node_attributes(self) -> int:\n",
    "#         return self.sizes['num_node_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_labels(self) -> int:\n",
    "#         return self.sizes['num_edge_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_attributes(self) -> int:\n",
    "#         return self.sizes['num_edge_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self) -> List[str]:\n",
    "#         names = ['A', 'graph_indicator']\n",
    "#         return [f'{self.name}_{name}.txt' for name in names]\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self) -> str:\n",
    "#         return 'data.pt'\n",
    "        \n",
    "        \n",
    "#         #Original Function\n",
    "# #     def download(self) -> None:\n",
    "# #         url = self.cleaned_url if self.cleaned else self.url\n",
    "# #         fs.cp(f'{url}/{self.name}.zip', self.raw_dir, extract=True)\n",
    "# #         for filename in fs.ls(osp.join(self.raw_dir, self.name)):\n",
    "# #             fs.mv(filename, osp.join(self.raw_dir, osp.basename(filename)))\n",
    "# #         fs.rm(osp.join(self.raw_dir, self.name))\n",
    "        \n",
    "#     #Dummy Function for already downloaded files\n",
    "#     def download(self) -> None:\n",
    "#         files = {\n",
    "#     'ENZYMES_A.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_A.txt',\n",
    "#     'ENZYMES_graph_indicator.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_indicator.txt',\n",
    "#     'ENZYMES_graph_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_labels.txt',\n",
    "#     'ENZYMES_node_attributes.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_attributes.txt',\n",
    "#     'ENZYMES_node_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_labels.txt'\n",
    "#     }\n",
    "#         dest_dir = '/kaggle/working/ENZYMES/raw/'\n",
    "\n",
    "#         # Ensure destination directory exists\n",
    "#         if not os.path.exists(dest_dir):\n",
    "#             os.makedirs(dest_dir)\n",
    "\n",
    "#         # Function to download and save a file\n",
    "#         def download_and_save(url, destination):\n",
    "#             # Make the HTTP GET request to the file URL\n",
    "#             if os.dir.exists()\n",
    "#             response = requests.get(url)\n",
    "#             if response.status_code == 200:\n",
    "#                 # Write the file contents in binary mode\n",
    "#                 filename = os.path.join(destination, url.split('/')[-1])\n",
    "#                 with open(filename, 'wb') as file:\n",
    "#                     file.write(response.content)\n",
    "#                 print(f\"File saved as {filename}\")\n",
    "#             else:\n",
    "#                 print(f\"Failed to download {url}\")\n",
    "\n",
    "#         # Download and save each file\n",
    "#         for file_url in files.values():\n",
    "#             download_and_save(file_url, dest_dir)\n",
    "\n",
    "#     def process(self) -> None:\n",
    "#         self.data, self.slices, sizes = read_tu_data(self.raw_dir, self.name)\n",
    "#         print(self.data.cos_sim)\n",
    "#         if self.pre_filter is not None or self.pre_transform is not None:\n",
    "#             data_list = [self.get(idx) for idx in range(len(self))]\n",
    "\n",
    "#             if self.pre_filter is not None:\n",
    "#                 data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "#             self.data, self.slices = self.collate(data_list)\n",
    "#             self._data_list = None  # Reset cache.\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         fs.torch_save(\n",
    "#             (self._data.to_dict(), self.slices, sizes, self._data.__class__),\n",
    "#             self.processed_paths[0],\n",
    "#         )\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f'{self.name}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012ba5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:29.200216Z",
     "iopub.status.busy": "2024-06-16T13:04:29.199762Z",
     "iopub.status.idle": "2024-06-16T13:04:34.431946Z",
     "shell.execute_reply": "2024-06-16T13:04:34.430379Z"
    },
    "papermill": {
     "duration": 5.247079,
     "end_time": "2024-06-16T13:04:34.435264",
     "exception": false,
     "start_time": "2024-06-16T13:04:29.188185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/NCI109.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "data = TUDataset(root=f'/working/{DATASET}', name=f'{DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccde11be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:34.458514Z",
     "iopub.status.busy": "2024-06-16T13:04:34.457881Z",
     "iopub.status.idle": "2024-06-16T13:04:34.464301Z",
     "shell.execute_reply": "2024-06-16T13:04:34.463170Z"
    },
    "papermill": {
     "duration": 0.021013,
     "end_time": "2024-06-16T13:04:34.466768",
     "exception": false,
     "start_time": "2024-06-16T13:04:34.445755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import aiohttp  # Import aiohttp to access ClientConnectorError\n",
    "# from requests.exceptions import SSLError\n",
    "\n",
    "# try:\n",
    "#     from torch_geometric.datasets import TUDataset\n",
    "#     data = TUDataset(root='/working/NCI1', name='NCI1')\n",
    "# except aiohttp.ClientConnectorSSLError as e:  # Catch connection errors specifically\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except requests.exceptions.SSLError as e:\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except Exception as e:  # Catch any other exceptions\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9ed97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:34.488878Z",
     "iopub.status.busy": "2024-06-16T13:04:34.487666Z",
     "iopub.status.idle": "2024-06-16T13:04:34.494323Z",
     "shell.execute_reply": "2024-06-16T13:04:34.492697Z"
    },
    "papermill": {
     "duration": 0.020646,
     "end_time": "2024-06-16T13:04:34.497257",
     "exception": false,
     "start_time": "2024-06-16T13:04:34.476611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ID_dataset = IDAddingDataset(data, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16f9370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:34.518957Z",
     "iopub.status.busy": "2024-06-16T13:04:34.518396Z",
     "iopub.status.idle": "2024-06-16T13:04:34.533510Z",
     "shell.execute_reply": "2024-06-16T13:04:34.532145Z"
    },
    "papermill": {
     "duration": 0.028953,
     "end_time": "2024-06-16T13:04:34.536010",
     "exception": false,
     "start_time": "2024-06-16T13:04:34.507057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 32], x=[16, 38], y=[1], id=2, num_edges=32, adj_mat=[16, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc2d5c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:34.558717Z",
     "iopub.status.busy": "2024-06-16T13:04:34.558238Z",
     "iopub.status.idle": "2024-06-16T13:04:44.040019Z",
     "shell.execute_reply": "2024-06-16T13:04:44.038737Z"
    },
    "papermill": {
     "duration": 9.496682,
     "end_time": "2024-06-16T13:04:44.043104",
     "exception": false,
     "start_time": "2024-06-16T13:04:34.546422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "for graph in ID_dataset:\n",
    "    embeddings_dict[graph.id] = get_WL_embedding(graph, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b33988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:44.066037Z",
     "iopub.status.busy": "2024-06-16T13:04:44.064801Z",
     "iopub.status.idle": "2024-06-16T13:04:44.071303Z",
     "shell.execute_reply": "2024-06-16T13:04:44.069897Z"
    },
    "papermill": {
     "duration": 0.020538,
     "end_time": "2024-06-16T13:04:44.073814",
     "exception": false,
     "start_time": "2024-06-16T13:04:44.053276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Embedding_dataset = EmbeddingAddingDataset(ID_dataset, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7b4edae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:44.095852Z",
     "iopub.status.busy": "2024-06-16T13:04:44.094733Z",
     "iopub.status.idle": "2024-06-16T13:04:52.848125Z",
     "shell.execute_reply": "2024-06-16T13:04:52.846726Z"
    },
    "papermill": {
     "duration": 8.767768,
     "end_time": "2024-06-16T13:04:52.851250",
     "exception": false,
     "start_time": "2024-06-16T13:04:44.083482",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_hashes, all_classes, mean_vector = get_mean_vectors(Embedding_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "642a7351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:52.873844Z",
     "iopub.status.busy": "2024-06-16T13:04:52.872557Z",
     "iopub.status.idle": "2024-06-16T13:04:52.880708Z",
     "shell.execute_reply": "2024-06-16T13:04:52.879461Z"
    },
    "papermill": {
     "duration": 0.021997,
     "end_time": "2024-06-16T13:04:52.883192",
     "exception": false,
     "start_time": "2024-06-16T13:04:52.861195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 'all'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5956a903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:52.905410Z",
     "iopub.status.busy": "2024-06-16T13:04:52.904434Z",
     "iopub.status.idle": "2024-06-16T13:05:45.430901Z",
     "shell.execute_reply": "2024-06-16T13:05:45.429581Z"
    },
    "papermill": {
     "duration": 52.540879,
     "end_time": "2024-06-16T13:05:45.433856",
     "exception": false,
     "start_time": "2024-06-16T13:04:52.892977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sims = {}\n",
    "class_cos_sims = {_class: [] for _class in all_classes}\n",
    "for graph in Embedding_dataset:\n",
    "    cos_sims[graph.id] = get_cos_sim(graph, all_hashes, all_classes, mean_vector)\n",
    "    class_cos_sims[graph.y.item()].append(cos_sims[graph.id]['class'])\n",
    "    class_cos_sims['all'].append(cos_sims[graph.id]['all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef577845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:45.455850Z",
     "iopub.status.busy": "2024-06-16T13:05:45.455352Z",
     "iopub.status.idle": "2024-06-16T13:05:45.463902Z",
     "shell.execute_reply": "2024-06-16T13:05:45.462691Z"
    },
    "papermill": {
     "duration": 0.022318,
     "end_time": "2024-06-16T13:05:45.466198",
     "exception": false,
     "start_time": "2024-06-16T13:05:45.443880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5853465584530863,\n",
       " 0.5068019238049677,\n",
       " 0.7339678442660369,\n",
       " 0.5571225493548922,\n",
       " 0.8686873381624867,\n",
       " 0.5766082289683534,\n",
       " 0.46177875321140516,\n",
       " 0.7429263342252902,\n",
       " 0.7739490692842468,\n",
       " 0.6581520969526358,\n",
       " 0.43287565319196136,\n",
       " 0.595201332120336,\n",
       " 0.7927690261360428,\n",
       " 0.5420758231828203,\n",
       " 0.7377277810012453,\n",
       " 0.8455716277332197,\n",
       " 0.7809851319167144,\n",
       " 0.7248867603180328,\n",
       " 0.7578647234552629,\n",
       " 0.6211631832126006,\n",
       " 0.5813039156159345,\n",
       " 0.5326632439413594,\n",
       " 0.7367305230848631,\n",
       " 0.7842632530639515,\n",
       " 0.5192667923418167,\n",
       " 0.706978092838242,\n",
       " 0.3055597577975961,\n",
       " 0.7967321632233072,\n",
       " 0.6085941712884149,\n",
       " 0.6143583041510753]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cos_sims[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e7fe70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:45.487821Z",
     "iopub.status.busy": "2024-06-16T13:05:45.487349Z",
     "iopub.status.idle": "2024-06-16T13:05:51.591140Z",
     "shell.execute_reply": "2024-06-16T13:05:51.589805Z"
    },
    "papermill": {
     "duration": 6.118003,
     "end_time": "2024-06-16T13:05:51.593928",
     "exception": false,
     "start_time": "2024-06-16T13:05:45.475925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_z_scores = {}\n",
    "\n",
    "for graph in Embedding_dataset:\n",
    "    all_z_scores[graph.id] = calc_z_scores(graph, cos_sims, class_cos_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4af690a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:51.616441Z",
     "iopub.status.busy": "2024-06-16T13:05:51.615995Z",
     "iopub.status.idle": "2024-06-16T13:05:51.621581Z",
     "shell.execute_reply": "2024-06-16T13:05:51.620356Z"
    },
    "papermill": {
     "duration": 0.020786,
     "end_time": "2024-06-16T13:05:51.624394",
     "exception": false,
     "start_time": "2024-06-16T13:05:51.603608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final transform and dataset\n",
    "Final_dataset = FinalAddingDataset(Embedding_dataset, cos_sims, all_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cc2472b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:51.646208Z",
     "iopub.status.busy": "2024-06-16T13:05:51.645810Z",
     "iopub.status.idle": "2024-06-16T13:07:14.266965Z",
     "shell.execute_reply": "2024-06-16T13:07:14.265489Z"
    },
    "papermill": {
     "duration": 82.635856,
     "end_time": "2024-06-16T13:07:14.270338",
     "exception": false,
     "start_time": "2024-06-16T13:05:51.634482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_node_dict = {_cls: {graph.id: graph.num_nodes for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "num_node_mean_dict = {_cls: sum(num_node_dict[_cls].values())/len(num_node_dict[_cls].values()) for _cls in all_classes}\n",
    "node_diff_dict = {_cls: {graph.id: graph.num_nodes - num_node_mean_dict[_cls] for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "pos_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "neg_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "for _cls, _dict in node_diff_dict.items():\n",
    "    for idx, node_diff in _dict.items():\n",
    "        if node_diff > 0:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "        else:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "pos_num_node_dict = {_cls: len(pos_diff_dict[_cls]) for _cls in all_classes}\n",
    "neg_num_node_dict = {_cls: len(neg_diff_dict[_cls]) for _cls in all_classes}\n",
    "percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "for _cls, _dict in pos_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/pos_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/pos_num_node_dict[_cls]\n",
    "for _cls, _dict in neg_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1], reverse=True)):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/neg_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/neg_num_node_dict[_cls]\n",
    "    \n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684fda91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:14.293834Z",
     "iopub.status.busy": "2024-06-16T13:07:14.292688Z",
     "iopub.status.idle": "2024-06-16T13:07:14.299999Z",
     "shell.execute_reply": "2024-06-16T13:07:14.298544Z"
    },
    "papermill": {
     "duration": 0.022281,
     "end_time": "2024-06-16T13:07:14.303053",
     "exception": false,
     "start_time": "2024-06-16T13:07:14.280772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.14489944269445118, 'class': 0.216796875}\n",
      "{'all': 0.23285679670462806, 'class': 0.3232421875}\n",
      "{'all': 0.06421129149503271, 'class': 0.10302734375}\n",
      "{'all': 0.32832566028592197, 'class': 0.43994140625}\n",
      "{'all': 0.9825539132541798, 'class': 0.99560546875}\n",
      "{'all': 0.025199903077295856, 'class': 0.03857421875}\n",
      "{'all': 0.2781681608916889, 'class': 0.37841796875}\n",
      "{'all': 0.23309910346498666, 'class': 0.32373046875}\n",
      "{'all': 0.27841046765204747, 'class': 0.37890625}\n",
      "{'all': 0.18269929731039497, 'class': 0.26025390625}\n",
      "{'all': 0.003876908165737824, 'class': 0.00732421875}\n",
      "{'all': 0.01453840562151684, 'class': 0.02294921875}\n",
      "{'all': 0.8265083595832323, 'class': 0.9130859375}\n",
      "{'all': 0.18294160407075358, 'class': 0.2607421875}\n",
      "{'all': 0.4623212987642355, 'class': 0.5869140625}\n",
      "{'all': 0.6127937969469348, 'class': 0.73828125}\n",
      "{'all': 0.3285679670462806, 'class': 0.4404296875}\n",
      "{'all': 0.46256360552459413, 'class': 0.58740234375}\n",
      "{'all': 0.2786527744124061, 'class': 0.37939453125}\n",
      "{'all': 0.1451417494548098, 'class': 0.21728515625}\n"
     ]
    }
   ],
   "source": [
    "num_node_percentile_dict = percentile_dict\n",
    "for x in range(20):\n",
    "    print(num_node_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebf2850d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:14.326103Z",
     "iopub.status.busy": "2024-06-16T13:07:14.325045Z",
     "iopub.status.idle": "2024-06-16T13:07:38.155585Z",
     "shell.execute_reply": "2024-06-16T13:07:38.154214Z"
    },
    "papermill": {
     "duration": 23.84509,
     "end_time": "2024-06-16T13:07:38.158424",
     "exception": false,
     "start_time": "2024-06-16T13:07:14.313334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim_dict = {_cls: {} for _cls in all_classes}\n",
    "for graph in Final_dataset:\n",
    "    cos_sim_dict[graph.y.item()][graph.id] = graph.cos_sim['class']\n",
    "    cos_sim_dict['all'][graph.id] = graph.cos_sim['all']\n",
    "            \n",
    "\n",
    "cat_len_dict = {_cls: len(cos_sim_dict[_cls].values()) for _cls in all_classes}\n",
    "cos_sim_percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "\n",
    "\n",
    "for _cls, _dict in cos_sim_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            cos_sim_percentile_dict[idx]['class'] = i/cat_len_dict[_cls]\n",
    "        else:\n",
    "            cos_sim_percentile_dict[idx]['all'] = i/cat_len_dict[_cls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3d38910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:38.181148Z",
     "iopub.status.busy": "2024-06-16T13:07:38.180677Z",
     "iopub.status.idle": "2024-06-16T13:07:38.187724Z",
     "shell.execute_reply": "2024-06-16T13:07:38.186177Z"
    },
    "papermill": {
     "duration": 0.021139,
     "end_time": "2024-06-16T13:07:38.189969",
     "exception": false,
     "start_time": "2024-06-16T13:07:38.168830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.41289071965107826, 'class': 0.33203125}\n",
      "{'all': 0.21904531136418706, 'class': 0.1845703125}\n",
      "{'all': 0.7673855100557305, 'class': 0.79150390625}\n",
      "{'all': 0.2214683789677732, 'class': 0.26904296875}\n",
      "{'all': 0.9975769323964139, 'class': 0.99853515625}\n",
      "{'all': 0.34892173491640416, 'class': 0.30859375}\n",
      "{'all': 0.11339956384783136, 'class': 0.138671875}\n",
      "{'all': 0.7404894596559244, 'class': 0.8251953125}\n",
      "{'all': 0.9023503755754786, 'class': 0.919921875}\n",
      "{'all': 0.5061788223891447, 'class': 0.52685546875}\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(cos_sim_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e25433b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:38.211877Z",
     "iopub.status.busy": "2024-06-16T13:07:38.211324Z",
     "iopub.status.idle": "2024-06-16T13:07:38.365910Z",
     "shell.execute_reply": "2024-06-16T13:07:38.364693Z"
    },
    "papermill": {
     "duration": 0.168831,
     "end_time": "2024-06-16T13:07:38.368555",
     "exception": false,
     "start_time": "2024-06-16T13:07:38.199724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles = [x for x in range(35, 91, 5)]\n",
    "cats = ['class', 'all']\n",
    "metrics = ['random', 'graph_order', 'cos_sim']\n",
    "train_indices_dict = {cat: {metric: {percentile: [] for percentile in percentiles} for metric in metrics} for cat in cats}\n",
    "for percentile in percentiles:\n",
    "    for idx, cat_pairs in cos_sim_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01*percentile:\n",
    "                train_indices_dict[cat]['cos_sim'][percentile].append(idx)\n",
    "    for idx, cat_pairs in num_node_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01* percentile:\n",
    "                train_indices_dict[cat]['graph_order'][percentile].append(idx)\n",
    "    for _cls, id_pairs in num_node_dict.items():\n",
    "        for cat in cats:\n",
    "            size = int(percentile * 0.01 * len(id_pairs))\n",
    "            train_indices_dict[cat]['random'][percentile] = np.random.choice(list(id_pairs.keys()), size, replace=False)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a515c91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:38.390416Z",
     "iopub.status.busy": "2024-06-16T13:07:38.389954Z",
     "iopub.status.idle": "2024-06-16T13:07:38.425622Z",
     "shell.execute_reply": "2024-06-16T13:07:38.424205Z"
    },
    "papermill": {
     "duration": 0.0498,
     "end_time": "2024-06-16T13:07:38.428309",
     "exception": false,
     "start_time": "2024-06-16T13:07:38.378509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}_train_indices_dict.pkl'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(train_indices_dict, file)\n",
    "\n",
    "print(\"Dict saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2c437fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:38.450707Z",
     "iopub.status.busy": "2024-06-16T13:07:38.450259Z",
     "iopub.status.idle": "2024-06-16T13:07:38.455780Z",
     "shell.execute_reply": "2024-06-16T13:07:38.454690Z"
    },
    "papermill": {
     "duration": 0.01966,
     "end_time": "2024-06-16T13:07:38.458233",
     "exception": false,
     "start_time": "2024-06-16T13:07:38.438573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # for x in range(6):\n",
    "# all_z_scores = [graph.num_nodes for graph in Final_dataset]\n",
    "# num_node_mean = sum(all_z_scores)/600\n",
    "# all_z_scores = [x - num_node_mean for x in all_z_scores]\n",
    "# percentiles = [50, 95, 99]  # Change these values based on your requirements (xx%)\n",
    "# percentile_values = np.percentile(all_z_scores, percentiles)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "# plt.title('Histogram of Z-Scores with Percentiles')\n",
    "# plt.xlabel('Z-Score')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # Add vertical lines for each percentile\n",
    "# for perc, value in zip(percentiles, percentile_values):\n",
    "#     plt.axvline(x=value, color='r', linestyle='--', label=f'{perc}th percentile: {value:.2f}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c65cc57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:38.480319Z",
     "iopub.status.busy": "2024-06-16T13:07:38.479865Z",
     "iopub.status.idle": "2024-06-16T13:07:48.131376Z",
     "shell.execute_reply": "2024-06-16T13:07:48.129745Z"
    },
    "papermill": {
     "duration": 9.666056,
     "end_time": "2024-06-16T13:07:48.134348",
     "exception": false,
     "start_time": "2024-06-16T13:07:38.468292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}.pt'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    torch.save(Final_dataset, file)\n",
    "\n",
    "print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48acfdf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:07:48.157378Z",
     "iopub.status.busy": "2024-06-16T13:07:48.156423Z",
     "iopub.status.idle": "2024-06-16T13:07:48.164703Z",
     "shell.execute_reply": "2024-06-16T13:07:48.163228Z"
    },
    "papermill": {
     "duration": 0.022775,
     "end_time": "2024-06-16T13:07:48.167221",
     "exception": false,
     "start_time": "2024-06-16T13:07:48.144446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of '/kaggle/working/':\n",
      "NCI109.pt\n",
      "NCI109_train_indices_dict.pkl\n",
      "__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory you want to list\n",
    "directory_path = '/kaggle/working/'\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "contents = os.listdir(directory_path)\n",
    "\n",
    "print(\"Contents of '/kaggle/working/':\")\n",
    "for item in contents:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae290349",
   "metadata": {
    "papermill": {
     "duration": 0.009761,
     "end_time": "2024-06-16T13:07:48.187248",
     "exception": false,
     "start_time": "2024-06-16T13:07:48.177487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 228.327847,
   "end_time": "2024-06-16T13:07:50.819511",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-16T13:04:02.491664",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
