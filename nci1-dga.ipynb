{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed571634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:32.381142Z",
     "iopub.status.busy": "2024-06-16T13:02:32.380726Z",
     "iopub.status.idle": "2024-06-16T13:02:46.701973Z",
     "shell.execute_reply": "2024-06-16T13:02:46.700758Z"
    },
    "papermill": {
     "duration": 14.333615,
     "end_time": "2024-06-16T13:02:46.704413",
     "exception": false,
     "start_time": "2024-06-16T13:02:32.370798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.5.3\r\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'NCI1'\n",
    "if 'first_run' not in globals():\n",
    "    !pip install torch torch-geometric\n",
    "    first_run = False\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96798f5e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:46.723979Z",
     "iopub.status.busy": "2024-06-16T13:02:46.723591Z",
     "iopub.status.idle": "2024-06-16T13:02:53.189869Z",
     "shell.execute_reply": "2024-06-16T13:02:53.188922Z"
    },
    "papermill": {
     "duration": 6.478761,
     "end_time": "2024-06-16T13:02:53.192205",
     "exception": false,
     "start_time": "2024-06-16T13:02:46.713444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.io import fs, read_txt_array\n",
    "import torch_geometric.transforms as T\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import math\n",
    "from typing import Callable, List, Optional, Tuple, Dict\n",
    "from torch import Tensor\n",
    "import os\n",
    "import requests\n",
    "from torch_geometric.utils import coalesce, cumsum, one_hot, remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98943c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.211640Z",
     "iopub.status.busy": "2024-06-16T13:02:53.211108Z",
     "iopub.status.idle": "2024-06-16T13:02:53.217048Z",
     "shell.execute_reply": "2024-06-16T13:02:53.216093Z"
    },
    "papermill": {
     "duration": 0.017903,
     "end_time": "2024-06-16T13:02:53.219103",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.201200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MyTransform(BaseTransform):\n",
    "#     def __init__(self, set_ids = False, indices = None, set_initial_features=False, embedding=None, cos_sim=None, z_score=None):\n",
    "#         super(MyTransform, self).__init__()\n",
    "#         self.current_id = 0  # Initialize a counter for unique IDs\n",
    "#         self.set_initial_features = set_initial_features\n",
    "#         self.embedding = embedding  # Assume this is a function if not None\n",
    "#         self.cos_sim = cos_sim      # Assume this is a dictionary or list if not None\n",
    "#         self.z_score = z_score      # Assume this is a dictionary or list if not None\n",
    "#         self.indices = indices\n",
    "#         if set_ids:\n",
    "#             self.assign_ids()\n",
    "\n",
    "#     def assign_ids(self):\n",
    "#         # Create an ID tensor for all data points\n",
    "#         id_tensor = torch.arange(self.indices)\n",
    "#         for i, data in enumerate(self):\n",
    "#             data.id = id_tensor[i]\n",
    "\n",
    "#     def __call__(self, data: Data) -> Data:\n",
    "#         # Assign a unique ID and increment the counter\n",
    "#         if self.set_initial_features:\n",
    "#             data.id = self.current_id\n",
    "#             self.current_id += 1\n",
    "#             data.num_edges = data.edge_index.size(1)  # Number of edges\n",
    "#             data.adj_mat = self.to_numpy_adj(data)  # Convert edge index to adjacency matrix\n",
    "\n",
    "#         if self.embedding:\n",
    "#             data.embedding = self.embedding[data.id] # Assume embedding function takes Data and modifies it\n",
    "\n",
    "#         if self.cos_sim is not None:\n",
    "#             data.cos_sim = self.cos_sim[data.id]  # Fetch cosine similarity based on ID\n",
    "\n",
    "#         if self.z_score is not None:\n",
    "#             data.z_score = self.z_score[data.id]  # Fetch z-score based on ID\n",
    "\n",
    "#         return data\n",
    "\n",
    "#     def to_numpy_adj(self, data):\n",
    "#         # Creates an adjacency matrix from edge_index\n",
    "#         adj_mat = np.zeros((data.num_nodes, data.num_nodes))\n",
    "#         edge_index = data.edge_index.numpy()\n",
    "#         adj_mat[edge_index[0], edge_index[1]] = 1\n",
    "#         return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6def4a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.239163Z",
     "iopub.status.busy": "2024-06-16T13:02:53.238225Z",
     "iopub.status.idle": "2024-06-16T13:02:53.245453Z",
     "shell.execute_reply": "2024-06-16T13:02:53.244411Z"
    },
    "papermill": {
     "duration": 0.019411,
     "end_time": "2024-06-16T13:02:53.247456",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.228045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IDAddingDataset:\n",
    "    def __init__(self, dataset, attr_func):\n",
    "        self.dataset = dataset\n",
    "        self.attr_func = attr_func\n",
    "        self.indices = np.arange(0, len(dataset.indices()))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.id = self.indices[idx]\n",
    "        data.num_edges = self.dataset[idx].edge_index.size(1)\n",
    "        data.adj_mat = to_scipy_sparse_matrix(self.dataset[idx].edge_index, num_nodes=self.dataset[idx].num_nodes).toarray().astype(int)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d20eca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.266646Z",
     "iopub.status.busy": "2024-06-16T13:02:53.266251Z",
     "iopub.status.idle": "2024-06-16T13:02:53.272115Z",
     "shell.execute_reply": "2024-06-16T13:02:53.271152Z"
    },
    "papermill": {
     "duration": 0.01768,
     "end_time": "2024-06-16T13:02:53.274046",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.256366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingAddingDataset:\n",
    "    def __init__(self, dataset, embedding_dict):\n",
    "        self.dataset = dataset\n",
    "        self.embedding_dict = embedding_dict\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.embedding = self.embedding_dict[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5cc1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.293213Z",
     "iopub.status.busy": "2024-06-16T13:02:53.292847Z",
     "iopub.status.idle": "2024-06-16T13:02:53.299014Z",
     "shell.execute_reply": "2024-06-16T13:02:53.298112Z"
    },
    "papermill": {
     "duration": 0.018066,
     "end_time": "2024-06-16T13:02:53.301038",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.282972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalAddingDataset:\n",
    "    def __init__(self, Embedding_dataset, cos_sims, all_z_scores):\n",
    "        self.dataset = Embedding_dataset\n",
    "        self.cos_sims = cos_sims\n",
    "        self.all_z_scores = all_z_scores\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.cos_sim = self.cos_sims[self.dataset[idx].id]\n",
    "        data.z_score = self.all_z_scores[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d435ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.319933Z",
     "iopub.status.busy": "2024-06-16T13:02:53.319566Z",
     "iopub.status.idle": "2024-06-16T13:02:53.327495Z",
     "shell.execute_reply": "2024-06-16T13:02:53.326424Z"
    },
    "papermill": {
     "duration": 0.019725,
     "end_time": "2024-06-16T13:02:53.329592",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.309867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stable_hash(value):\n",
    "    return hashlib.md5(str(value).encode()).hexdigest()\n",
    "def get_WL_embedding(data, n_iter):\n",
    "    graph = data.adj_mat\n",
    "    graph_hash_dict = {}\n",
    "    labels = [np.sum(graph[x]) for x in range(len(graph))]  # Initialize labels based on node degrees\n",
    "    for _ in range(n_iter):\n",
    "        neighbor_labels = [sorted([labels[j] for j in range(len(graph)) if graph[i, j] == 1]) for i in range(len(graph))]\n",
    "        hashes = np.array([stable_hash((labels[i], tuple(neighbor_labels[i]))) for i in range(len(graph))])\n",
    "        \n",
    "        for unique_hash in set(hashes):\n",
    "            graph_hash_dict[unique_hash] = np.sum(hashes == unique_hash)\n",
    "\n",
    "        labels = hashes.tolist()\n",
    "\n",
    "    return graph_hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2745ccd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.348784Z",
     "iopub.status.busy": "2024-06-16T13:02:53.348406Z",
     "iopub.status.idle": "2024-06-16T13:02:53.361780Z",
     "shell.execute_reply": "2024-06-16T13:02:53.360759Z"
    },
    "papermill": {
     "duration": 0.02537,
     "end_time": "2024-06-16T13:02:53.363828",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.338458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_vectors(dataset):\n",
    "    all_hashes = set()\n",
    "    all_classes = set()\n",
    "    for graph in dataset:\n",
    "        all_hashes.update(graph.embedding.keys())\n",
    "        all_classes.add(graph.y.item())\n",
    "    all_classes.add('all')\n",
    "\n",
    "    vector_sum_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    category_sum_dict = {_cls: 0 for _cls in all_classes}\n",
    "    mean_vector_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    \n",
    "    \n",
    "    for graph in dataset:\n",
    "        for _hash, count in graph.embedding.items():\n",
    "            vector_sum_dict[graph.y.item()][_hash] += count\n",
    "            category_sum_dict[graph.y.item()] += 1\n",
    "            vector_sum_dict['all'][_hash] += count\n",
    "            category_sum_dict['all'] += 1\n",
    "    for _cls, hash_counts in vector_sum_dict.items():\n",
    "        for _hash, count in hash_counts.items():\n",
    "            mean_vector_dict[_cls][_hash] = count/category_sum_dict[_cls]\n",
    "    return all_hashes, all_classes, mean_vector_dict\n",
    "\n",
    "def get_cos_sim(dataset, all_hashes, all_classes, mean_vectors):\n",
    "    cos_sims, norm_dict = {}, {}\n",
    "    graph_norm = math.sqrt(sum(count**2 for count in graph.embedding.values()))\n",
    "    for _class in all_classes:\n",
    "        norm_dict[_class] = math.sqrt(sum(count**2 for count in mean_vectors[_class].values()))\n",
    "    all_numerator = sum(count * mean_vectors['all'][_hash] for _hash, count in graph.embedding.items())\n",
    "    all_denom = norm_dict['all'] * graph_norm\n",
    "    cos_sims['all'] = all_numerator / all_denom\n",
    "\n",
    "    class_numerator = sum(count * mean_vectors[graph.y.item()][_hash] for _hash, count in graph.embedding.items())\n",
    "    class_denom = norm_dict[graph.y.item()] * graph_norm\n",
    "    cos_sims['class'] = class_numerator / class_denom\n",
    "    \n",
    "    return cos_sims\n",
    "\n",
    "def calc_z_scores(graph, cos_sims, class_cos_sims):\n",
    "    # Ensure data types are numpy arrays for statistical computation\n",
    "    all_cos_sims = np.array(class_cos_sims['all'])\n",
    "    cat_cos_sims = np.array(class_cos_sims[graph.y.item()])\n",
    "    \n",
    "    # Calculate means and standard deviations for 'all' and specific 'class'\n",
    "    all_mean = np.mean(all_cos_sims)\n",
    "    cat_mean = np.mean(cat_cos_sims)\n",
    "    all_std_dev = np.std(all_cos_sims)\n",
    "    class_std_dev = np.std(cat_cos_sims)\n",
    "    \n",
    "    # Compute z-scores using the standard formula, include flooring to nearest 0.5 if needed\n",
    "    z_scores = {\n",
    "        'all': (cos_sims[graph.id]['all']) / all_std_dev,\n",
    "        'class': (cos_sims[graph.id]['class']) / class_std_dev\n",
    "    }\n",
    "    \n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f943dac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.383161Z",
     "iopub.status.busy": "2024-06-16T13:02:53.382454Z",
     "iopub.status.idle": "2024-06-16T13:02:53.386705Z",
     "shell.execute_reply": "2024-06-16T13:02:53.385662Z"
    },
    "papermill": {
     "duration": 0.016194,
     "end_time": "2024-06-16T13:02:53.388801",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.372607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.io.tu import read_tu_data\n",
    "# data, slices, sizes = read_tu_data('/kaggle/working/', 'ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da002a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.408383Z",
     "iopub.status.busy": "2024-06-16T13:02:53.407967Z",
     "iopub.status.idle": "2024-06-16T13:02:53.423921Z",
     "shell.execute_reply": "2024-06-16T13:02:53.422779Z"
    },
    "papermill": {
     "duration": 0.028445,
     "end_time": "2024-06-16T13:02:53.426055",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.397610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "# from typing import Callable, List, Optional\n",
    "\n",
    "# from torch_geometric.data import Data, InMemoryDataset\n",
    "# from torch_geometric.io import fs#, read_tu_data\n",
    "\n",
    "# def read_file(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "#     name: str,\n",
    "#     dtype: Optional[torch.dtype] = None,\n",
    "# ) -> Tensor:\n",
    "#     path = osp.join(folder, f'{prefix}_{name}.txt')\n",
    "#     return read_txt_array(path, sep=',', dtype=dtype)\n",
    "# def cat(seq: List[Optional[Tensor]]) -> Optional[Tensor]:\n",
    "#     values = [v for v in seq if v is not None]\n",
    "#     values = [v for v in values if v.numel() > 0]\n",
    "#     values = [v.unsqueeze(-1) if v.dim() == 1 else v for v in values]\n",
    "#     return torch.cat(values, dim=-1) if len(values) > 0 else None\n",
    "# def split(data: Data, batch: Tensor) -> Tuple[Data, Dict[str, Tensor]]:\n",
    "#     node_slice = cumsum(torch.from_numpy(np.bincount(batch)))\n",
    "\n",
    "#     assert data.edge_index is not None\n",
    "#     row, _ = data.edge_index\n",
    "#     edge_slice = cumsum(torch.from_numpy(np.bincount(batch[row])))\n",
    "\n",
    "#     # Edge indices should start at zero for every graph.\n",
    "#     data.edge_index -= node_slice[batch[row]].unsqueeze(0)\n",
    "\n",
    "#     slices = {'edge_index': edge_slice}\n",
    "#     if data.x is not None:\n",
    "#         slices['x'] = node_slice\n",
    "#     else:\n",
    "#         # Imitate `collate` functionality:\n",
    "#         data._num_nodes = torch.bincount(batch).tolist()\n",
    "#         data.num_nodes = batch.numel()\n",
    "#     if data.edge_attr is not None:\n",
    "#         slices['edge_attr'] = edge_slice\n",
    "#     if data.y is not None:\n",
    "#         assert isinstance(data.y, Tensor)\n",
    "#         if data.y.size(0) == batch.size(0):\n",
    "#             slices['y'] = node_slice\n",
    "#         else:\n",
    "#             slices['y'] = torch.arange(0, int(batch[-1]) + 2, dtype=torch.long)\n",
    "\n",
    "#     return data, slices\n",
    "# def read_tu_data(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "# ) -> Tuple[Data, Dict[str, Tensor], Dict[str, int]]:\n",
    "#     files = fs.glob(osp.join(folder, f'{prefix}_*.txt'))\n",
    "#     names = [osp.basename(f)[len(prefix) + 1:-4] for f in files]\n",
    "\n",
    "#     edge_index = read_file(folder, prefix, 'A', torch.long).t() - 1\n",
    "#     batch = read_file(folder, prefix, 'graph_indicator', torch.long) - 1\n",
    "\n",
    "#     node_attribute = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_attributes' in names:\n",
    "#         node_attribute = read_file(folder, prefix, 'node_attributes')\n",
    "#         if node_attribute.dim() == 1:\n",
    "#             node_attribute = node_attribute.unsqueeze(-1)\n",
    "\n",
    "#     node_label = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_labels' in names:\n",
    "#         node_label = read_file(folder, prefix, 'node_labels', torch.long)\n",
    "#         if node_label.dim() == 1:\n",
    "#             node_label = node_label.unsqueeze(-1)\n",
    "#         node_label = node_label - node_label.min(dim=0)[0]\n",
    "#         node_labels = list(node_label.unbind(dim=-1))\n",
    "#         node_labels = [one_hot(x) for x in node_labels]\n",
    "#         if len(node_labels) == 1:\n",
    "#             node_label = node_labels[0]\n",
    "#         else:\n",
    "#             node_label = torch.cat(node_labels, dim=-1)\n",
    "\n",
    "#     edge_attribute = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_attributes' in names:\n",
    "#         edge_attribute = read_file(folder, prefix, 'edge_attributes')\n",
    "#         if edge_attribute.dim() == 1:\n",
    "#             edge_attribute = edge_attribute.unsqueeze(-1)\n",
    "\n",
    "#     edge_label = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_labels' in names:\n",
    "#         edge_label = read_file(folder, prefix, 'edge_labels', torch.long)\n",
    "#         if edge_label.dim() == 1:\n",
    "#             edge_label = edge_label.unsqueeze(-1)\n",
    "#         edge_label = edge_label - edge_label.min(dim=0)[0]\n",
    "#         edge_labels = list(edge_label.unbind(dim=-1))\n",
    "#         edge_labels = [one_hot(e) for e in edge_labels]\n",
    "#         if len(edge_labels) == 1:\n",
    "#             edge_label = edge_labels[0]\n",
    "#         else:\n",
    "#             edge_label = torch.cat(edge_labels, dim=-1)\n",
    "\n",
    "#     x = cat([node_attribute, node_label])\n",
    "#     edge_attr = cat([edge_attribute, edge_label])\n",
    "\n",
    "#     y = None\n",
    "#     if 'graph_attributes' in names:  # Regression problem.\n",
    "#         y = read_file(folder, prefix, 'graph_attributes')\n",
    "#     elif 'graph_labels' in names:  # Classification problem.\n",
    "#         y = read_file(folder, prefix, 'graph_labels', torch.long)\n",
    "#         _, y = y.unique(sorted=True, return_inverse=True)\n",
    "\n",
    "#     num_nodes = int(edge_index.max()) + 1 if x is None else x.size(0)\n",
    "#     edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "#     edge_index, edge_attr = coalesce(edge_index, edge_attr, num_nodes)\n",
    "#     cos_sim = torch.tensor([-1.0])\n",
    "#     z_score = torch.tensor([-1.0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data = Data(\n",
    "#         x=x,\n",
    "#         edge_index=edge_index,\n",
    "#         edge_attr=edge_attr,\n",
    "#         y=y,\n",
    "#         cos_sim=torch.tensor([-1.0]),  # Custom attribute\n",
    "#         z_score=torch.tensor([-1.0])   # Custom attribute\n",
    "#     )\n",
    "#     data, slices = split(data, batch)\n",
    "\n",
    "#     sizes = {\n",
    "#         'num_node_attributes': node_attribute.size(-1),\n",
    "#         'num_node_labels': node_label.size(-1),\n",
    "#         'num_edge_attributes': edge_attribute.size(-1),\n",
    "#         'num_edge_labels': edge_label.size(-1),\n",
    "#     }\n",
    "\n",
    "#     return data, slices, sizes\n",
    "\n",
    "# class MyTUDataset(InMemoryDataset):\n",
    "#     r\"\"\"A variety of graph kernel benchmark datasets, *.e.g.*,\n",
    "#     :obj:`\"IMDB-BINARY\"`, :obj:`\"REDDIT-BINARY\"` or :obj:`\"PROTEINS\"`,\n",
    "#     collected from the `TU Dortmund University\n",
    "#     <https://chrsmrrs.github.io/datasets>`_.\n",
    "#     In addition, this dataset wrapper provides `cleaned dataset versions\n",
    "#     <https://github.com/nd7141/graph_datasets>`_ as motivated by the\n",
    "#     `\"Understanding Isomorphism Bias in Graph Data Sets\"\n",
    "#     <https://arxiv.org/abs/1910.12091>`_ paper, containing only non-isomorphic\n",
    "#     graphs.\n",
    "\n",
    "#     .. note::\n",
    "#         Some datasets may not come with any node labels.\n",
    "#         You can then either make use of the argument :obj:`use_node_attr`\n",
    "#         to load additional continuous node attributes (if present) or provide\n",
    "#         synthetic node features using transforms such as\n",
    "#         :class:`torch_geometric.transforms.Constant` or\n",
    "#         :class:`torch_geometric.transforms.OneHotDegree`.\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Root directory where the dataset should be saved.\n",
    "#         name (str): The `name\n",
    "#             <https://chrsmrrs.github.io/datasets/docs/datasets/>`_ of the\n",
    "#             dataset.\n",
    "#         transform (callable, optional): A function/transform that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "#             version. The data object will be transformed before every access.\n",
    "#             (default: :obj:`None`)\n",
    "#         pre_transform (callable, optional): A function/transform that takes in\n",
    "#             an :obj:`torch_geometric.data.Data` object and returns a\n",
    "#             transformed version. The data object will be transformed before\n",
    "#             being saved to disk. (default: :obj:`None`)\n",
    "#         pre_filter (callable, optional): A function that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "#             value, indicating whether the data object should be included in the\n",
    "#             final dataset. (default: :obj:`None`)\n",
    "#         force_reload (bool, optional): Whether to re-process the dataset.\n",
    "#             (default: :obj:`False`)\n",
    "#         use_node_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous node attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         use_edge_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous edge attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         cleaned (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain only non-isomorphic graphs. (default: :obj:`False`)\n",
    "\n",
    "#     **STATS:**\n",
    "\n",
    "#     .. list-table::\n",
    "#         :widths: 20 10 10 10 10 10\n",
    "#         :header-rows: 1\n",
    "\n",
    "#         * - Name\n",
    "#           - #graphs\n",
    "#           - #nodes\n",
    "#           - #edges\n",
    "#           - #features\n",
    "#           - #classes\n",
    "#         * - MUTAG\n",
    "#           - 188\n",
    "#           - ~17.9\n",
    "#           - ~39.6\n",
    "#           - 7\n",
    "#           - 2\n",
    "#         * - ENZYMES\n",
    "#           - 600\n",
    "#           - ~32.6\n",
    "#           - ~124.3\n",
    "#           - 3\n",
    "#           - 6\n",
    "#         * - PROTEINS\n",
    "#           - 1,113\n",
    "#           - ~39.1\n",
    "#           - ~145.6\n",
    "#           - 3\n",
    "#           - 2\n",
    "#         * - COLLAB\n",
    "#           - 5,000\n",
    "#           - ~74.5\n",
    "#           - ~4914.4\n",
    "#           - 0\n",
    "#           - 3\n",
    "#         * - IMDB-BINARY\n",
    "#           - 1,000\n",
    "#           - ~19.8\n",
    "#           - ~193.1\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - REDDIT-BINARY\n",
    "#           - 2,000\n",
    "#           - ~429.6\n",
    "#           - ~995.5\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - ...\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#     \"\"\"\n",
    "\n",
    "#     url = 'https://www.chrsmrrs.com/graphkerneldatasets'\n",
    "#     cleaned_url = ('https://raw.githubusercontent.com/nd7141/'\n",
    "#                    'graph_datasets/master/datasets')\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         root: str,\n",
    "#         name: str,\n",
    "#         transform: Optional[Callable] = None,\n",
    "#         pre_transform: Optional[Callable] = None,\n",
    "#         pre_filter: Optional[Callable] = None,\n",
    "#         force_reload: bool = False,\n",
    "#         use_node_attr: bool = False,\n",
    "#         use_edge_attr: bool = False,\n",
    "#         cleaned: bool = False,\n",
    "#     ) -> None:\n",
    "#         self.name = name\n",
    "#         self.cleaned = cleaned\n",
    "#         super().__init__(root, transform, pre_transform, pre_filter,\n",
    "#                          force_reload=force_reload)\n",
    "\n",
    "#         out = fs.torch_load(self.processed_paths[0])\n",
    "#         if not isinstance(out, tuple) or len(out) < 3:\n",
    "#             raise RuntimeError(\n",
    "#                 \"The 'data' object was created by an older version of PyG. \"\n",
    "#                 \"If this error occurred while loading an already existing \"\n",
    "#                 \"dataset, remove the 'processed/' directory in the dataset's \"\n",
    "#                 \"root folder and try again.\")\n",
    "#         assert len(out) == 3 or len(out) == 4\n",
    "\n",
    "#         if len(out) == 3:  # Backward compatibility.\n",
    "#             data, self.slices, self.sizes = out\n",
    "#             data_cls = Data\n",
    "#         else:\n",
    "#             data, self.slices, self.sizes, data_cls = out\n",
    "\n",
    "#         if not isinstance(data, dict):  # Backward compatibility.\n",
    "#             self.data = data\n",
    "#         else:\n",
    "#             self.data = data_cls.from_dict(data)\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         if self._data.x is not None and not use_node_attr:\n",
    "#             num_node_attributes = self.num_node_attributes\n",
    "#             self._data.x = self._data.x[:, num_node_attributes:]\n",
    "#         if self._data.edge_attr is not None and not use_edge_attr:\n",
    "#             num_edge_attrs = self.num_edge_attributes\n",
    "#             self._data.edge_attr = self._data.edge_attr[:, num_edge_attrs:]\n",
    "\n",
    "#     @property\n",
    "#     def raw_dir(self) -> str:\n",
    "#         name = f'raw{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def processed_dir(self) -> str:\n",
    "#         name = f'processed{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def num_node_labels(self) -> int:\n",
    "#         return self.sizes['num_node_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_node_attributes(self) -> int:\n",
    "#         return self.sizes['num_node_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_labels(self) -> int:\n",
    "#         return self.sizes['num_edge_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_attributes(self) -> int:\n",
    "#         return self.sizes['num_edge_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self) -> List[str]:\n",
    "#         names = ['A', 'graph_indicator']\n",
    "#         return [f'{self.name}_{name}.txt' for name in names]\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self) -> str:\n",
    "#         return 'data.pt'\n",
    "        \n",
    "        \n",
    "#         #Original Function\n",
    "# #     def download(self) -> None:\n",
    "# #         url = self.cleaned_url if self.cleaned else self.url\n",
    "# #         fs.cp(f'{url}/{self.name}.zip', self.raw_dir, extract=True)\n",
    "# #         for filename in fs.ls(osp.join(self.raw_dir, self.name)):\n",
    "# #             fs.mv(filename, osp.join(self.raw_dir, osp.basename(filename)))\n",
    "# #         fs.rm(osp.join(self.raw_dir, self.name))\n",
    "        \n",
    "#     #Dummy Function for already downloaded files\n",
    "#     def download(self) -> None:\n",
    "#         files = {\n",
    "#     'ENZYMES_A.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_A.txt',\n",
    "#     'ENZYMES_graph_indicator.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_indicator.txt',\n",
    "#     'ENZYMES_graph_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_labels.txt',\n",
    "#     'ENZYMES_node_attributes.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_attributes.txt',\n",
    "#     'ENZYMES_node_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_labels.txt'\n",
    "#     }\n",
    "#         dest_dir = '/kaggle/working/ENZYMES/raw/'\n",
    "\n",
    "#         # Ensure destination directory exists\n",
    "#         if not os.path.exists(dest_dir):\n",
    "#             os.makedirs(dest_dir)\n",
    "\n",
    "#         # Function to download and save a file\n",
    "#         def download_and_save(url, destination):\n",
    "#             # Make the HTTP GET request to the file URL\n",
    "#             if os.dir.exists()\n",
    "#             response = requests.get(url)\n",
    "#             if response.status_code == 200:\n",
    "#                 # Write the file contents in binary mode\n",
    "#                 filename = os.path.join(destination, url.split('/')[-1])\n",
    "#                 with open(filename, 'wb') as file:\n",
    "#                     file.write(response.content)\n",
    "#                 print(f\"File saved as {filename}\")\n",
    "#             else:\n",
    "#                 print(f\"Failed to download {url}\")\n",
    "\n",
    "#         # Download and save each file\n",
    "#         for file_url in files.values():\n",
    "#             download_and_save(file_url, dest_dir)\n",
    "\n",
    "#     def process(self) -> None:\n",
    "#         self.data, self.slices, sizes = read_tu_data(self.raw_dir, self.name)\n",
    "#         print(self.data.cos_sim)\n",
    "#         if self.pre_filter is not None or self.pre_transform is not None:\n",
    "#             data_list = [self.get(idx) for idx in range(len(self))]\n",
    "\n",
    "#             if self.pre_filter is not None:\n",
    "#                 data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "#             self.data, self.slices = self.collate(data_list)\n",
    "#             self._data_list = None  # Reset cache.\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         fs.torch_save(\n",
    "#             (self._data.to_dict(), self.slices, sizes, self._data.__class__),\n",
    "#             self.processed_paths[0],\n",
    "#         )\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f'{self.name}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf83451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:53.445855Z",
     "iopub.status.busy": "2024-06-16T13:02:53.445000Z",
     "iopub.status.idle": "2024-06-16T13:02:58.521201Z",
     "shell.execute_reply": "2024-06-16T13:02:58.519890Z"
    },
    "papermill": {
     "duration": 5.088,
     "end_time": "2024-06-16T13:02:58.523388",
     "exception": false,
     "start_time": "2024-06-16T13:02:53.435388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/NCI1.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "data = TUDataset(root=f'/working/{DATASET}', name=f'{DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b57e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:58.544029Z",
     "iopub.status.busy": "2024-06-16T13:02:58.543075Z",
     "iopub.status.idle": "2024-06-16T13:02:58.548504Z",
     "shell.execute_reply": "2024-06-16T13:02:58.547518Z"
    },
    "papermill": {
     "duration": 0.018049,
     "end_time": "2024-06-16T13:02:58.550606",
     "exception": false,
     "start_time": "2024-06-16T13:02:58.532557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import aiohttp  # Import aiohttp to access ClientConnectorError\n",
    "# from requests.exceptions import SSLError\n",
    "\n",
    "# try:\n",
    "#     from torch_geometric.datasets import TUDataset\n",
    "#     data = TUDataset(root='/working/NCI1', name='NCI1')\n",
    "# except aiohttp.ClientConnectorSSLError as e:  # Catch connection errors specifically\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except requests.exceptions.SSLError as e:\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except Exception as e:  # Catch any other exceptions\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca3a584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:58.570138Z",
     "iopub.status.busy": "2024-06-16T13:02:58.569277Z",
     "iopub.status.idle": "2024-06-16T13:02:58.574113Z",
     "shell.execute_reply": "2024-06-16T13:02:58.573143Z"
    },
    "papermill": {
     "duration": 0.016741,
     "end_time": "2024-06-16T13:02:58.576164",
     "exception": false,
     "start_time": "2024-06-16T13:02:58.559423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ID_dataset = IDAddingDataset(data, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe80e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:58.595682Z",
     "iopub.status.busy": "2024-06-16T13:02:58.595052Z",
     "iopub.status.idle": "2024-06-16T13:02:58.607261Z",
     "shell.execute_reply": "2024-06-16T13:02:58.606193Z"
    },
    "papermill": {
     "duration": 0.024441,
     "end_time": "2024-06-16T13:02:58.609527",
     "exception": false,
     "start_time": "2024-06-16T13:02:58.585086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 58], x=[29, 37], y=[1], id=2, num_edges=58, adj_mat=[29, 29])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d23d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:02:58.629211Z",
     "iopub.status.busy": "2024-06-16T13:02:58.628837Z",
     "iopub.status.idle": "2024-06-16T13:03:07.686720Z",
     "shell.execute_reply": "2024-06-16T13:03:07.685577Z"
    },
    "papermill": {
     "duration": 9.07075,
     "end_time": "2024-06-16T13:03:07.689310",
     "exception": false,
     "start_time": "2024-06-16T13:02:58.618560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "for graph in ID_dataset:\n",
    "    embeddings_dict[graph.id] = get_WL_embedding(graph, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e9147b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:07.709036Z",
     "iopub.status.busy": "2024-06-16T13:03:07.708632Z",
     "iopub.status.idle": "2024-06-16T13:03:07.713395Z",
     "shell.execute_reply": "2024-06-16T13:03:07.712412Z"
    },
    "papermill": {
     "duration": 0.017022,
     "end_time": "2024-06-16T13:03:07.715425",
     "exception": false,
     "start_time": "2024-06-16T13:03:07.698403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Embedding_dataset = EmbeddingAddingDataset(ID_dataset, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef414f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:07.734952Z",
     "iopub.status.busy": "2024-06-16T13:03:07.734583Z",
     "iopub.status.idle": "2024-06-16T13:03:16.203722Z",
     "shell.execute_reply": "2024-06-16T13:03:16.202822Z"
    },
    "papermill": {
     "duration": 8.481777,
     "end_time": "2024-06-16T13:03:16.206255",
     "exception": false,
     "start_time": "2024-06-16T13:03:07.724478",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_hashes, all_classes, mean_vector = get_mean_vectors(Embedding_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc92b1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:16.227045Z",
     "iopub.status.busy": "2024-06-16T13:03:16.226185Z",
     "iopub.status.idle": "2024-06-16T13:03:16.232505Z",
     "shell.execute_reply": "2024-06-16T13:03:16.231512Z"
    },
    "papermill": {
     "duration": 0.019023,
     "end_time": "2024-06-16T13:03:16.234603",
     "exception": false,
     "start_time": "2024-06-16T13:03:16.215580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 'all'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9c5a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:16.254959Z",
     "iopub.status.busy": "2024-06-16T13:03:16.254553Z",
     "iopub.status.idle": "2024-06-16T13:04:05.022547Z",
     "shell.execute_reply": "2024-06-16T13:04:05.021403Z"
    },
    "papermill": {
     "duration": 48.781231,
     "end_time": "2024-06-16T13:04:05.025213",
     "exception": false,
     "start_time": "2024-06-16T13:03:16.243982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sims = {}\n",
    "class_cos_sims = {_class: [] for _class in all_classes}\n",
    "for graph in Embedding_dataset:\n",
    "    cos_sims[graph.id] = get_cos_sim(graph, all_hashes, all_classes, mean_vector)\n",
    "    class_cos_sims[graph.y.item()].append(cos_sims[graph.id]['class'])\n",
    "    class_cos_sims['all'].append(cos_sims[graph.id]['all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12fcffc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:05.045380Z",
     "iopub.status.busy": "2024-06-16T13:04:05.045004Z",
     "iopub.status.idle": "2024-06-16T13:04:05.051601Z",
     "shell.execute_reply": "2024-06-16T13:04:05.050608Z"
    },
    "papermill": {
     "duration": 0.01894,
     "end_time": "2024-06-16T13:04:05.053656",
     "exception": false,
     "start_time": "2024-06-16T13:04:05.034716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6423509227491252,\n",
       " 0.7112636989533706,\n",
       " 0.4402153466312972,\n",
       " 0.7522073091602725,\n",
       " 0.5076569993083345,\n",
       " 0.6501313217187085,\n",
       " 0.4927846527721424,\n",
       " 0.7431627688419384,\n",
       " 0.6854934856466498,\n",
       " 0.4847434634533624,\n",
       " 0.756220605212531,\n",
       " 0.7713449866857756,\n",
       " 0.29353732733208826,\n",
       " 0.6938654486592667,\n",
       " 0.6284752556153832,\n",
       " 0.6873632660804837,\n",
       " 0.449891908563749,\n",
       " 0.8522720121492846,\n",
       " 0.6340244056166701,\n",
       " 0.617800088871389,\n",
       " 0.5880338864413497,\n",
       " 0.7685294687858429,\n",
       " 0.7987727087008748,\n",
       " 0.5891318351925006,\n",
       " 0.7727711524286127,\n",
       " 0.6830913052097619,\n",
       " 0.7181998071972092,\n",
       " 0.44252705623036276,\n",
       " 0.6701743362705666,\n",
       " 0.3997777289747845]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cos_sims[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3489d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:05.074059Z",
     "iopub.status.busy": "2024-06-16T13:04:05.073185Z",
     "iopub.status.idle": "2024-06-16T13:04:11.028210Z",
     "shell.execute_reply": "2024-06-16T13:04:11.027174Z"
    },
    "papermill": {
     "duration": 5.967904,
     "end_time": "2024-06-16T13:04:11.030817",
     "exception": false,
     "start_time": "2024-06-16T13:04:05.062913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_z_scores = {}\n",
    "\n",
    "for graph in Embedding_dataset:\n",
    "    all_z_scores[graph.id] = calc_z_scores(graph, cos_sims, class_cos_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e82b724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:11.051662Z",
     "iopub.status.busy": "2024-06-16T13:04:11.050746Z",
     "iopub.status.idle": "2024-06-16T13:04:11.055455Z",
     "shell.execute_reply": "2024-06-16T13:04:11.054484Z"
    },
    "papermill": {
     "duration": 0.017311,
     "end_time": "2024-06-16T13:04:11.057512",
     "exception": false,
     "start_time": "2024-06-16T13:04:11.040201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final transform and dataset\n",
    "Final_dataset = FinalAddingDataset(Embedding_dataset, cos_sims, all_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f48d459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:11.077603Z",
     "iopub.status.busy": "2024-06-16T13:04:11.077102Z",
     "iopub.status.idle": "2024-06-16T13:05:31.725027Z",
     "shell.execute_reply": "2024-06-16T13:05:31.724133Z"
    },
    "papermill": {
     "duration": 80.660769,
     "end_time": "2024-06-16T13:05:31.727517",
     "exception": false,
     "start_time": "2024-06-16T13:04:11.066748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_node_dict = {_cls: {graph.id: graph.num_nodes for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "num_node_mean_dict = {_cls: sum(num_node_dict[_cls].values())/len(num_node_dict[_cls].values()) for _cls in all_classes}\n",
    "node_diff_dict = {_cls: {graph.id: graph.num_nodes - num_node_mean_dict[_cls] for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "pos_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "neg_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "for _cls, _dict in node_diff_dict.items():\n",
    "    for idx, node_diff in _dict.items():\n",
    "        if node_diff > 0:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "        else:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "pos_num_node_dict = {_cls: len(pos_diff_dict[_cls]) for _cls in all_classes}\n",
    "neg_num_node_dict = {_cls: len(neg_diff_dict[_cls]) for _cls in all_classes}\n",
    "percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "for _cls, _dict in pos_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/pos_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/pos_num_node_dict[_cls]\n",
    "for _cls, _dict in neg_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1], reverse=True)):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/neg_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/neg_num_node_dict[_cls]\n",
    "    \n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0ec3963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:31.748385Z",
     "iopub.status.busy": "2024-06-16T13:05:31.747617Z",
     "iopub.status.idle": "2024-06-16T13:05:31.753167Z",
     "shell.execute_reply": "2024-06-16T13:05:31.752227Z"
    },
    "papermill": {
     "duration": 0.018187,
     "end_time": "2024-06-16T13:05:31.755309",
     "exception": false,
     "start_time": "2024-06-16T13:05:31.737122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.23138686131386862, 'class': 0.3244033122260107}\n",
      "{'all': 0.36253041362530414, 'class': 0.48222113979542136}\n",
      "{'all': 0.5666666666666667, 'class': 0.6931320019483682}\n",
      "{'all': 0.5248175182481751, 'class': 0.6546517291768145}\n",
      "{'all': 0.31557177615571774, 'class': 0.42328300048709205}\n",
      "{'all': 0.44720194647201944, 'class': 0.5645396980029226}\n",
      "{'all': 0.02408759124087591, 'class': 0.03653190452995616}\n",
      "{'all': 0.06472019464720194, 'class': 0.10180224062347784}\n",
      "{'all': 0.4474452554744526, 'class': 0.565026790063322}\n",
      "{'all': 0.18880778588807787, 'class': 0.2727715538236727}\n",
      "{'all': 0.5250608272506083, 'class': 0.6551388212372138}\n",
      "{'all': 0.0878345498783455, 'class': 0.13735996103263517}\n",
      "{'all': 0.0051094890510948905, 'class': 0.00876765708718948}\n",
      "{'all': 0.08807785888077858, 'class': 0.13784705309303458}\n",
      "{'all': 0.6274939172749392, 'class': 0.7579152459814905}\n",
      "{'all': 0.44768856447688565, 'class': 0.5655138821237213}\n",
      "{'all': 0.014355231143552312, 'class': 0.02143205065757428}\n",
      "{'all': 0.6277372262773723, 'class': 0.75840233804189}\n",
      "{'all': 0.14793187347931874, 'class': 0.22260107160253287}\n",
      "{'all': 0.11727493917274939, 'class': 0.18022406234778374}\n"
     ]
    }
   ],
   "source": [
    "num_node_percentile_dict = percentile_dict\n",
    "for x in range(20):\n",
    "    print(num_node_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14fe8526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:31.775832Z",
     "iopub.status.busy": "2024-06-16T13:05:31.774955Z",
     "iopub.status.idle": "2024-06-16T13:05:54.805492Z",
     "shell.execute_reply": "2024-06-16T13:05:54.804528Z"
    },
    "papermill": {
     "duration": 23.043347,
     "end_time": "2024-06-16T13:05:54.807988",
     "exception": false,
     "start_time": "2024-06-16T13:05:31.764641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim_dict = {_cls: {} for _cls in all_classes}\n",
    "for graph in Final_dataset:\n",
    "    cos_sim_dict[graph.y.item()][graph.id] = graph.cos_sim['class']\n",
    "    cos_sim_dict['all'][graph.id] = graph.cos_sim['all']\n",
    "            \n",
    "\n",
    "cat_len_dict = {_cls: len(cos_sim_dict[_cls].values()) for _cls in all_classes}\n",
    "cos_sim_percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "\n",
    "\n",
    "for _cls, _dict in cos_sim_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            cos_sim_percentile_dict[idx]['class'] = i/cat_len_dict[_cls]\n",
    "        else:\n",
    "            cos_sim_percentile_dict[idx]['all'] = i/cat_len_dict[_cls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31462e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:54.828809Z",
     "iopub.status.busy": "2024-06-16T13:05:54.828425Z",
     "iopub.status.idle": "2024-06-16T13:05:54.833440Z",
     "shell.execute_reply": "2024-06-16T13:05:54.832466Z"
    },
    "papermill": {
     "duration": 0.018288,
     "end_time": "2024-06-16T13:05:54.836080",
     "exception": false,
     "start_time": "2024-06-16T13:05:54.817792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.4776155717761557, 'class': 0.4656600097418412}\n",
      "{'all': 0.670316301703163, 'class': 0.6819288845591817}\n",
      "{'all': 0.0781021897810219, 'class': 0.11544081831466146}\n",
      "{'all': 0.8423357664233576, 'class': 0.8280565026790063}\n",
      "{'all': 0.21021897810218979, 'class': 0.18947881149537263}\n",
      "{'all': 0.4922141119221411, 'class': 0.4846566000974184}\n",
      "{'all': 0.1148418491484185, 'class': 0.16950803701899658}\n",
      "{'all': 0.8381995133819952, 'class': 0.7968826108134437}\n",
      "{'all': 0.4318734793187348, 'class': 0.5942523136872869}\n",
      "{'all': 0.15742092457420925, 'class': 0.15879201169020946}\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(cos_sim_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ea9768a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:54.856820Z",
     "iopub.status.busy": "2024-06-16T13:05:54.856142Z",
     "iopub.status.idle": "2024-06-16T13:05:54.995481Z",
     "shell.execute_reply": "2024-06-16T13:05:54.994399Z"
    },
    "papermill": {
     "duration": 0.152485,
     "end_time": "2024-06-16T13:05:54.998014",
     "exception": false,
     "start_time": "2024-06-16T13:05:54.845529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles = [x for x in range(35, 91, 5)]\n",
    "cats = ['class', 'all']\n",
    "metrics = ['random', 'graph_order', 'cos_sim']\n",
    "train_indices_dict = {cat: {metric: {percentile: [] for percentile in percentiles} for metric in metrics} for cat in cats}\n",
    "for percentile in percentiles:\n",
    "    for idx, cat_pairs in cos_sim_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01*percentile:\n",
    "                train_indices_dict[cat]['cos_sim'][percentile].append(idx)\n",
    "    for idx, cat_pairs in num_node_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01* percentile:\n",
    "                train_indices_dict[cat]['graph_order'][percentile].append(idx)\n",
    "    for _cls, id_pairs in num_node_dict.items():\n",
    "        for cat in cats:\n",
    "            size = int(percentile * 0.01 * len(id_pairs))\n",
    "            train_indices_dict[cat]['random'][percentile] = np.random.choice(list(id_pairs.keys()), size, replace=False)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "730db238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:55.018872Z",
     "iopub.status.busy": "2024-06-16T13:05:55.018481Z",
     "iopub.status.idle": "2024-06-16T13:05:55.053706Z",
     "shell.execute_reply": "2024-06-16T13:05:55.052604Z"
    },
    "papermill": {
     "duration": 0.048385,
     "end_time": "2024-06-16T13:05:55.056068",
     "exception": false,
     "start_time": "2024-06-16T13:05:55.007683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}_train_indices_dict.pkl'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(train_indices_dict, file)\n",
    "\n",
    "print(\"Dict saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "566ebc97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:55.077595Z",
     "iopub.status.busy": "2024-06-16T13:05:55.076856Z",
     "iopub.status.idle": "2024-06-16T13:05:55.081757Z",
     "shell.execute_reply": "2024-06-16T13:05:55.080831Z"
    },
    "papermill": {
     "duration": 0.017788,
     "end_time": "2024-06-16T13:05:55.083740",
     "exception": false,
     "start_time": "2024-06-16T13:05:55.065952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # for x in range(6):\n",
    "# all_z_scores = [graph.num_nodes for graph in Final_dataset]\n",
    "# num_node_mean = sum(all_z_scores)/600\n",
    "# all_z_scores = [x - num_node_mean for x in all_z_scores]\n",
    "# percentiles = [50, 95, 99]  # Change these values based on your requirements (xx%)\n",
    "# percentile_values = np.percentile(all_z_scores, percentiles)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "# plt.title('Histogram of Z-Scores with Percentiles')\n",
    "# plt.xlabel('Z-Score')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # Add vertical lines for each percentile\n",
    "# for perc, value in zip(percentiles, percentile_values):\n",
    "#     plt.axvline(x=value, color='r', linestyle='--', label=f'{perc}th percentile: {value:.2f}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22538eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:05:55.104932Z",
     "iopub.status.busy": "2024-06-16T13:05:55.104163Z",
     "iopub.status.idle": "2024-06-16T13:06:03.824722Z",
     "shell.execute_reply": "2024-06-16T13:06:03.823663Z"
    },
    "papermill": {
     "duration": 8.73372,
     "end_time": "2024-06-16T13:06:03.826988",
     "exception": false,
     "start_time": "2024-06-16T13:05:55.093268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}.pt'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    torch.save(Final_dataset, file)\n",
    "\n",
    "print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e022f324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:06:03.848151Z",
     "iopub.status.busy": "2024-06-16T13:06:03.847764Z",
     "iopub.status.idle": "2024-06-16T13:06:03.853693Z",
     "shell.execute_reply": "2024-06-16T13:06:03.852748Z"
    },
    "papermill": {
     "duration": 0.018983,
     "end_time": "2024-06-16T13:06:03.855648",
     "exception": false,
     "start_time": "2024-06-16T13:06:03.836665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of '/kaggle/working/':\n",
      "__notebook__.ipynb\n",
      "NCI1.pt\n",
      "NCI1_train_indices_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory you want to list\n",
    "directory_path = '/kaggle/working/'\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "contents = os.listdir(directory_path)\n",
    "\n",
    "print(\"Contents of '/kaggle/working/':\")\n",
    "for item in contents:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d0430",
   "metadata": {
    "papermill": {
     "duration": 0.00988,
     "end_time": "2024-06-16T13:06:03.875203",
     "exception": false,
     "start_time": "2024-06-16T13:06:03.865323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 215.322177,
   "end_time": "2024-06-16T13:06:05.108461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-16T13:02:29.786284",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
