{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9055440c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:43.589998Z",
     "iopub.status.busy": "2024-06-16T13:03:43.589525Z",
     "iopub.status.idle": "2024-06-16T13:03:59.491336Z",
     "shell.execute_reply": "2024-06-16T13:03:59.489600Z"
    },
    "papermill": {
     "duration": 15.915101,
     "end_time": "2024-06-16T13:03:59.494048",
     "exception": false,
     "start_time": "2024-06-16T13:03:43.578947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.5.3\r\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'DD'\n",
    "if 'first_run' not in globals():\n",
    "    !pip install torch torch-geometric\n",
    "    first_run = False\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d96bc8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-16T13:03:59.514816Z",
     "iopub.status.busy": "2024-06-16T13:03:59.514384Z",
     "iopub.status.idle": "2024-06-16T13:04:07.236826Z",
     "shell.execute_reply": "2024-06-16T13:04:07.235717Z"
    },
    "papermill": {
     "duration": 7.736332,
     "end_time": "2024-06-16T13:04:07.239907",
     "exception": false,
     "start_time": "2024-06-16T13:03:59.503575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.io import fs, read_txt_array\n",
    "import torch_geometric.transforms as T\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import math\n",
    "from typing import Callable, List, Optional, Tuple, Dict\n",
    "from torch import Tensor\n",
    "import os\n",
    "import requests\n",
    "from torch_geometric.utils import coalesce, cumsum, one_hot, remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0117d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.260938Z",
     "iopub.status.busy": "2024-06-16T13:04:07.260386Z",
     "iopub.status.idle": "2024-06-16T13:04:07.266493Z",
     "shell.execute_reply": "2024-06-16T13:04:07.265361Z"
    },
    "papermill": {
     "duration": 0.01936,
     "end_time": "2024-06-16T13:04:07.268952",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.249592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MyTransform(BaseTransform):\n",
    "#     def __init__(self, set_ids = False, indices = None, set_initial_features=False, embedding=None, cos_sim=None, z_score=None):\n",
    "#         super(MyTransform, self).__init__()\n",
    "#         self.current_id = 0  # Initialize a counter for unique IDs\n",
    "#         self.set_initial_features = set_initial_features\n",
    "#         self.embedding = embedding  # Assume this is a function if not None\n",
    "#         self.cos_sim = cos_sim      # Assume this is a dictionary or list if not None\n",
    "#         self.z_score = z_score      # Assume this is a dictionary or list if not None\n",
    "#         self.indices = indices\n",
    "#         if set_ids:\n",
    "#             self.assign_ids()\n",
    "\n",
    "#     def assign_ids(self):\n",
    "#         # Create an ID tensor for all data points\n",
    "#         id_tensor = torch.arange(self.indices)\n",
    "#         for i, data in enumerate(self):\n",
    "#             data.id = id_tensor[i]\n",
    "\n",
    "#     def __call__(self, data: Data) -> Data:\n",
    "#         # Assign a unique ID and increment the counter\n",
    "#         if self.set_initial_features:\n",
    "#             data.id = self.current_id\n",
    "#             self.current_id += 1\n",
    "#             data.num_edges = data.edge_index.size(1)  # Number of edges\n",
    "#             data.adj_mat = self.to_numpy_adj(data)  # Convert edge index to adjacency matrix\n",
    "\n",
    "#         if self.embedding:\n",
    "#             data.embedding = self.embedding[data.id] # Assume embedding function takes Data and modifies it\n",
    "\n",
    "#         if self.cos_sim is not None:\n",
    "#             data.cos_sim = self.cos_sim[data.id]  # Fetch cosine similarity based on ID\n",
    "\n",
    "#         if self.z_score is not None:\n",
    "#             data.z_score = self.z_score[data.id]  # Fetch z-score based on ID\n",
    "\n",
    "#         return data\n",
    "\n",
    "#     def to_numpy_adj(self, data):\n",
    "#         # Creates an adjacency matrix from edge_index\n",
    "#         adj_mat = np.zeros((data.num_nodes, data.num_nodes))\n",
    "#         edge_index = data.edge_index.numpy()\n",
    "#         adj_mat[edge_index[0], edge_index[1]] = 1\n",
    "#         return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4b22aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.289611Z",
     "iopub.status.busy": "2024-06-16T13:04:07.289258Z",
     "iopub.status.idle": "2024-06-16T13:04:07.297192Z",
     "shell.execute_reply": "2024-06-16T13:04:07.296001Z"
    },
    "papermill": {
     "duration": 0.020825,
     "end_time": "2024-06-16T13:04:07.299569",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.278744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IDAddingDataset:\n",
    "    def __init__(self, dataset, attr_func):\n",
    "        self.dataset = dataset\n",
    "        self.attr_func = attr_func\n",
    "        self.indices = np.arange(0, len(dataset.indices()))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.id = self.indices[idx]\n",
    "        data.num_edges = self.dataset[idx].edge_index.size(1)\n",
    "        data.adj_mat = to_scipy_sparse_matrix(self.dataset[idx].edge_index, num_nodes=self.dataset[idx].num_nodes).toarray().astype(int)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456e2258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.320042Z",
     "iopub.status.busy": "2024-06-16T13:04:07.319645Z",
     "iopub.status.idle": "2024-06-16T13:04:07.326342Z",
     "shell.execute_reply": "2024-06-16T13:04:07.325093Z"
    },
    "papermill": {
     "duration": 0.01967,
     "end_time": "2024-06-16T13:04:07.328692",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.309022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingAddingDataset:\n",
    "    def __init__(self, dataset, embedding_dict):\n",
    "        self.dataset = dataset\n",
    "        self.embedding_dict = embedding_dict\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.embedding = self.embedding_dict[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942bde9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.348662Z",
     "iopub.status.busy": "2024-06-16T13:04:07.348258Z",
     "iopub.status.idle": "2024-06-16T13:04:07.355261Z",
     "shell.execute_reply": "2024-06-16T13:04:07.354138Z"
    },
    "papermill": {
     "duration": 0.019715,
     "end_time": "2024-06-16T13:04:07.357670",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.337955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalAddingDataset:\n",
    "    def __init__(self, Embedding_dataset, cos_sims, all_z_scores):\n",
    "        self.dataset = Embedding_dataset\n",
    "        self.cos_sims = cos_sims\n",
    "        self.all_z_scores = all_z_scores\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.cos_sim = self.cos_sims[self.dataset[idx].id]\n",
    "        data.z_score = self.all_z_scores[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e895f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.377461Z",
     "iopub.status.busy": "2024-06-16T13:04:07.377095Z",
     "iopub.status.idle": "2024-06-16T13:04:07.385614Z",
     "shell.execute_reply": "2024-06-16T13:04:07.384245Z"
    },
    "papermill": {
     "duration": 0.0215,
     "end_time": "2024-06-16T13:04:07.388341",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.366841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stable_hash(value):\n",
    "    return hashlib.md5(str(value).encode()).hexdigest()\n",
    "def get_WL_embedding(data, n_iter):\n",
    "    graph = data.adj_mat\n",
    "    graph_hash_dict = {}\n",
    "    labels = [np.sum(graph[x]) for x in range(len(graph))]  # Initialize labels based on node degrees\n",
    "    for _ in range(n_iter):\n",
    "        neighbor_labels = [sorted([labels[j] for j in range(len(graph)) if graph[i, j] == 1]) for i in range(len(graph))]\n",
    "        hashes = np.array([stable_hash((labels[i], tuple(neighbor_labels[i]))) for i in range(len(graph))])\n",
    "        \n",
    "        for unique_hash in set(hashes):\n",
    "            graph_hash_dict[unique_hash] = np.sum(hashes == unique_hash)\n",
    "\n",
    "        labels = hashes.tolist()\n",
    "\n",
    "    return graph_hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801f3157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.409173Z",
     "iopub.status.busy": "2024-06-16T13:04:07.408750Z",
     "iopub.status.idle": "2024-06-16T13:04:07.423606Z",
     "shell.execute_reply": "2024-06-16T13:04:07.422518Z"
    },
    "papermill": {
     "duration": 0.027896,
     "end_time": "2024-06-16T13:04:07.426047",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.398151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_vectors(dataset):\n",
    "    all_hashes = set()\n",
    "    all_classes = set()\n",
    "    for graph in dataset:\n",
    "        all_hashes.update(graph.embedding.keys())\n",
    "        all_classes.add(graph.y.item())\n",
    "    all_classes.add('all')\n",
    "\n",
    "    vector_sum_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    category_sum_dict = {_cls: 0 for _cls in all_classes}\n",
    "    mean_vector_dict = {_cls: {h: 0 for h in all_hashes} for _cls in all_classes}\n",
    "    \n",
    "    \n",
    "    for graph in dataset:\n",
    "        for _hash, count in graph.embedding.items():\n",
    "            vector_sum_dict[graph.y.item()][_hash] += count\n",
    "            category_sum_dict[graph.y.item()] += 1\n",
    "            vector_sum_dict['all'][_hash] += count\n",
    "            category_sum_dict['all'] += 1\n",
    "    for _cls, hash_counts in vector_sum_dict.items():\n",
    "        for _hash, count in hash_counts.items():\n",
    "            mean_vector_dict[_cls][_hash] = count/category_sum_dict[_cls]\n",
    "    return all_hashes, all_classes, mean_vector_dict\n",
    "\n",
    "def get_cos_sim(dataset, all_hashes, all_classes, mean_vectors):\n",
    "    cos_sims, norm_dict = {}, {}\n",
    "    graph_norm = math.sqrt(sum(count**2 for count in graph.embedding.values()))\n",
    "    for _class in all_classes:\n",
    "        norm_dict[_class] = math.sqrt(sum(count**2 for count in mean_vectors[_class].values()))\n",
    "    all_numerator = sum(count * mean_vectors['all'][_hash] for _hash, count in graph.embedding.items())\n",
    "    all_denom = norm_dict['all'] * graph_norm\n",
    "    cos_sims['all'] = all_numerator / all_denom\n",
    "\n",
    "    class_numerator = sum(count * mean_vectors[graph.y.item()][_hash] for _hash, count in graph.embedding.items())\n",
    "    class_denom = norm_dict[graph.y.item()] * graph_norm\n",
    "    cos_sims['class'] = class_numerator / class_denom\n",
    "    \n",
    "    return cos_sims\n",
    "\n",
    "def calc_z_scores(graph, cos_sims, class_cos_sims):\n",
    "    # Ensure data types are numpy arrays for statistical computation\n",
    "    all_cos_sims = np.array(class_cos_sims['all'])\n",
    "    cat_cos_sims = np.array(class_cos_sims[graph.y.item()])\n",
    "    \n",
    "    # Calculate means and standard deviations for 'all' and specific 'class'\n",
    "    all_mean = np.mean(all_cos_sims)\n",
    "    cat_mean = np.mean(cat_cos_sims)\n",
    "    all_std_dev = np.std(all_cos_sims)\n",
    "    class_std_dev = np.std(cat_cos_sims)\n",
    "    \n",
    "    # Compute z-scores using the standard formula, include flooring to nearest 0.5 if needed\n",
    "    z_scores = {\n",
    "        'all': (cos_sims[graph.id]['all']) / all_std_dev,\n",
    "        'class': (cos_sims[graph.id]['class']) / class_std_dev\n",
    "    }\n",
    "    \n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8aecfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.446397Z",
     "iopub.status.busy": "2024-06-16T13:04:07.445959Z",
     "iopub.status.idle": "2024-06-16T13:04:07.450814Z",
     "shell.execute_reply": "2024-06-16T13:04:07.449640Z"
    },
    "papermill": {
     "duration": 0.0179,
     "end_time": "2024-06-16T13:04:07.453097",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.435197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch_geometric.io.tu import read_tu_data\n",
    "# data, slices, sizes = read_tu_data('/kaggle/working/', 'ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebcf3cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.473516Z",
     "iopub.status.busy": "2024-06-16T13:04:07.473101Z",
     "iopub.status.idle": "2024-06-16T13:04:07.489788Z",
     "shell.execute_reply": "2024-06-16T13:04:07.488471Z"
    },
    "papermill": {
     "duration": 0.030093,
     "end_time": "2024-06-16T13:04:07.492296",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.462203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "# from typing import Callable, List, Optional\n",
    "\n",
    "# from torch_geometric.data import Data, InMemoryDataset\n",
    "# from torch_geometric.io import fs#, read_tu_data\n",
    "\n",
    "# def read_file(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "#     name: str,\n",
    "#     dtype: Optional[torch.dtype] = None,\n",
    "# ) -> Tensor:\n",
    "#     path = osp.join(folder, f'{prefix}_{name}.txt')\n",
    "#     return read_txt_array(path, sep=',', dtype=dtype)\n",
    "# def cat(seq: List[Optional[Tensor]]) -> Optional[Tensor]:\n",
    "#     values = [v for v in seq if v is not None]\n",
    "#     values = [v for v in values if v.numel() > 0]\n",
    "#     values = [v.unsqueeze(-1) if v.dim() == 1 else v for v in values]\n",
    "#     return torch.cat(values, dim=-1) if len(values) > 0 else None\n",
    "# def split(data: Data, batch: Tensor) -> Tuple[Data, Dict[str, Tensor]]:\n",
    "#     node_slice = cumsum(torch.from_numpy(np.bincount(batch)))\n",
    "\n",
    "#     assert data.edge_index is not None\n",
    "#     row, _ = data.edge_index\n",
    "#     edge_slice = cumsum(torch.from_numpy(np.bincount(batch[row])))\n",
    "\n",
    "#     # Edge indices should start at zero for every graph.\n",
    "#     data.edge_index -= node_slice[batch[row]].unsqueeze(0)\n",
    "\n",
    "#     slices = {'edge_index': edge_slice}\n",
    "#     if data.x is not None:\n",
    "#         slices['x'] = node_slice\n",
    "#     else:\n",
    "#         # Imitate `collate` functionality:\n",
    "#         data._num_nodes = torch.bincount(batch).tolist()\n",
    "#         data.num_nodes = batch.numel()\n",
    "#     if data.edge_attr is not None:\n",
    "#         slices['edge_attr'] = edge_slice\n",
    "#     if data.y is not None:\n",
    "#         assert isinstance(data.y, Tensor)\n",
    "#         if data.y.size(0) == batch.size(0):\n",
    "#             slices['y'] = node_slice\n",
    "#         else:\n",
    "#             slices['y'] = torch.arange(0, int(batch[-1]) + 2, dtype=torch.long)\n",
    "\n",
    "#     return data, slices\n",
    "# def read_tu_data(\n",
    "#     folder: str,\n",
    "#     prefix: str,\n",
    "# ) -> Tuple[Data, Dict[str, Tensor], Dict[str, int]]:\n",
    "#     files = fs.glob(osp.join(folder, f'{prefix}_*.txt'))\n",
    "#     names = [osp.basename(f)[len(prefix) + 1:-4] for f in files]\n",
    "\n",
    "#     edge_index = read_file(folder, prefix, 'A', torch.long).t() - 1\n",
    "#     batch = read_file(folder, prefix, 'graph_indicator', torch.long) - 1\n",
    "\n",
    "#     node_attribute = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_attributes' in names:\n",
    "#         node_attribute = read_file(folder, prefix, 'node_attributes')\n",
    "#         if node_attribute.dim() == 1:\n",
    "#             node_attribute = node_attribute.unsqueeze(-1)\n",
    "\n",
    "#     node_label = torch.empty((batch.size(0), 0))\n",
    "#     if 'node_labels' in names:\n",
    "#         node_label = read_file(folder, prefix, 'node_labels', torch.long)\n",
    "#         if node_label.dim() == 1:\n",
    "#             node_label = node_label.unsqueeze(-1)\n",
    "#         node_label = node_label - node_label.min(dim=0)[0]\n",
    "#         node_labels = list(node_label.unbind(dim=-1))\n",
    "#         node_labels = [one_hot(x) for x in node_labels]\n",
    "#         if len(node_labels) == 1:\n",
    "#             node_label = node_labels[0]\n",
    "#         else:\n",
    "#             node_label = torch.cat(node_labels, dim=-1)\n",
    "\n",
    "#     edge_attribute = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_attributes' in names:\n",
    "#         edge_attribute = read_file(folder, prefix, 'edge_attributes')\n",
    "#         if edge_attribute.dim() == 1:\n",
    "#             edge_attribute = edge_attribute.unsqueeze(-1)\n",
    "\n",
    "#     edge_label = torch.empty((edge_index.size(1), 0))\n",
    "#     if 'edge_labels' in names:\n",
    "#         edge_label = read_file(folder, prefix, 'edge_labels', torch.long)\n",
    "#         if edge_label.dim() == 1:\n",
    "#             edge_label = edge_label.unsqueeze(-1)\n",
    "#         edge_label = edge_label - edge_label.min(dim=0)[0]\n",
    "#         edge_labels = list(edge_label.unbind(dim=-1))\n",
    "#         edge_labels = [one_hot(e) for e in edge_labels]\n",
    "#         if len(edge_labels) == 1:\n",
    "#             edge_label = edge_labels[0]\n",
    "#         else:\n",
    "#             edge_label = torch.cat(edge_labels, dim=-1)\n",
    "\n",
    "#     x = cat([node_attribute, node_label])\n",
    "#     edge_attr = cat([edge_attribute, edge_label])\n",
    "\n",
    "#     y = None\n",
    "#     if 'graph_attributes' in names:  # Regression problem.\n",
    "#         y = read_file(folder, prefix, 'graph_attributes')\n",
    "#     elif 'graph_labels' in names:  # Classification problem.\n",
    "#         y = read_file(folder, prefix, 'graph_labels', torch.long)\n",
    "#         _, y = y.unique(sorted=True, return_inverse=True)\n",
    "\n",
    "#     num_nodes = int(edge_index.max()) + 1 if x is None else x.size(0)\n",
    "#     edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "#     edge_index, edge_attr = coalesce(edge_index, edge_attr, num_nodes)\n",
    "#     cos_sim = torch.tensor([-1.0])\n",
    "#     z_score = torch.tensor([-1.0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data = Data(\n",
    "#         x=x,\n",
    "#         edge_index=edge_index,\n",
    "#         edge_attr=edge_attr,\n",
    "#         y=y,\n",
    "#         cos_sim=torch.tensor([-1.0]),  # Custom attribute\n",
    "#         z_score=torch.tensor([-1.0])   # Custom attribute\n",
    "#     )\n",
    "#     data, slices = split(data, batch)\n",
    "\n",
    "#     sizes = {\n",
    "#         'num_node_attributes': node_attribute.size(-1),\n",
    "#         'num_node_labels': node_label.size(-1),\n",
    "#         'num_edge_attributes': edge_attribute.size(-1),\n",
    "#         'num_edge_labels': edge_label.size(-1),\n",
    "#     }\n",
    "\n",
    "#     return data, slices, sizes\n",
    "\n",
    "# class MyTUDataset(InMemoryDataset):\n",
    "#     r\"\"\"A variety of graph kernel benchmark datasets, *.e.g.*,\n",
    "#     :obj:`\"IMDB-BINARY\"`, :obj:`\"REDDIT-BINARY\"` or :obj:`\"PROTEINS\"`,\n",
    "#     collected from the `TU Dortmund University\n",
    "#     <https://chrsmrrs.github.io/datasets>`_.\n",
    "#     In addition, this dataset wrapper provides `cleaned dataset versions\n",
    "#     <https://github.com/nd7141/graph_datasets>`_ as motivated by the\n",
    "#     `\"Understanding Isomorphism Bias in Graph Data Sets\"\n",
    "#     <https://arxiv.org/abs/1910.12091>`_ paper, containing only non-isomorphic\n",
    "#     graphs.\n",
    "\n",
    "#     .. note::\n",
    "#         Some datasets may not come with any node labels.\n",
    "#         You can then either make use of the argument :obj:`use_node_attr`\n",
    "#         to load additional continuous node attributes (if present) or provide\n",
    "#         synthetic node features using transforms such as\n",
    "#         :class:`torch_geometric.transforms.Constant` or\n",
    "#         :class:`torch_geometric.transforms.OneHotDegree`.\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Root directory where the dataset should be saved.\n",
    "#         name (str): The `name\n",
    "#             <https://chrsmrrs.github.io/datasets/docs/datasets/>`_ of the\n",
    "#             dataset.\n",
    "#         transform (callable, optional): A function/transform that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "#             version. The data object will be transformed before every access.\n",
    "#             (default: :obj:`None`)\n",
    "#         pre_transform (callable, optional): A function/transform that takes in\n",
    "#             an :obj:`torch_geometric.data.Data` object and returns a\n",
    "#             transformed version. The data object will be transformed before\n",
    "#             being saved to disk. (default: :obj:`None`)\n",
    "#         pre_filter (callable, optional): A function that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "#             value, indicating whether the data object should be included in the\n",
    "#             final dataset. (default: :obj:`None`)\n",
    "#         force_reload (bool, optional): Whether to re-process the dataset.\n",
    "#             (default: :obj:`False`)\n",
    "#         use_node_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous node attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         use_edge_attr (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain additional continuous edge attributes (if present).\n",
    "#             (default: :obj:`False`)\n",
    "#         cleaned (bool, optional): If :obj:`True`, the dataset will\n",
    "#             contain only non-isomorphic graphs. (default: :obj:`False`)\n",
    "\n",
    "#     **STATS:**\n",
    "\n",
    "#     .. list-table::\n",
    "#         :widths: 20 10 10 10 10 10\n",
    "#         :header-rows: 1\n",
    "\n",
    "#         * - Name\n",
    "#           - #graphs\n",
    "#           - #nodes\n",
    "#           - #edges\n",
    "#           - #features\n",
    "#           - #classes\n",
    "#         * - MUTAG\n",
    "#           - 188\n",
    "#           - ~17.9\n",
    "#           - ~39.6\n",
    "#           - 7\n",
    "#           - 2\n",
    "#         * - ENZYMES\n",
    "#           - 600\n",
    "#           - ~32.6\n",
    "#           - ~124.3\n",
    "#           - 3\n",
    "#           - 6\n",
    "#         * - PROTEINS\n",
    "#           - 1,113\n",
    "#           - ~39.1\n",
    "#           - ~145.6\n",
    "#           - 3\n",
    "#           - 2\n",
    "#         * - COLLAB\n",
    "#           - 5,000\n",
    "#           - ~74.5\n",
    "#           - ~4914.4\n",
    "#           - 0\n",
    "#           - 3\n",
    "#         * - IMDB-BINARY\n",
    "#           - 1,000\n",
    "#           - ~19.8\n",
    "#           - ~193.1\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - REDDIT-BINARY\n",
    "#           - 2,000\n",
    "#           - ~429.6\n",
    "#           - ~995.5\n",
    "#           - 0\n",
    "#           - 2\n",
    "#         * - ...\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#           -\n",
    "#     \"\"\"\n",
    "\n",
    "#     url = 'https://www.chrsmrrs.com/graphkerneldatasets'\n",
    "#     cleaned_url = ('https://raw.githubusercontent.com/nd7141/'\n",
    "#                    'graph_datasets/master/datasets')\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         root: str,\n",
    "#         name: str,\n",
    "#         transform: Optional[Callable] = None,\n",
    "#         pre_transform: Optional[Callable] = None,\n",
    "#         pre_filter: Optional[Callable] = None,\n",
    "#         force_reload: bool = False,\n",
    "#         use_node_attr: bool = False,\n",
    "#         use_edge_attr: bool = False,\n",
    "#         cleaned: bool = False,\n",
    "#     ) -> None:\n",
    "#         self.name = name\n",
    "#         self.cleaned = cleaned\n",
    "#         super().__init__(root, transform, pre_transform, pre_filter,\n",
    "#                          force_reload=force_reload)\n",
    "\n",
    "#         out = fs.torch_load(self.processed_paths[0])\n",
    "#         if not isinstance(out, tuple) or len(out) < 3:\n",
    "#             raise RuntimeError(\n",
    "#                 \"The 'data' object was created by an older version of PyG. \"\n",
    "#                 \"If this error occurred while loading an already existing \"\n",
    "#                 \"dataset, remove the 'processed/' directory in the dataset's \"\n",
    "#                 \"root folder and try again.\")\n",
    "#         assert len(out) == 3 or len(out) == 4\n",
    "\n",
    "#         if len(out) == 3:  # Backward compatibility.\n",
    "#             data, self.slices, self.sizes = out\n",
    "#             data_cls = Data\n",
    "#         else:\n",
    "#             data, self.slices, self.sizes, data_cls = out\n",
    "\n",
    "#         if not isinstance(data, dict):  # Backward compatibility.\n",
    "#             self.data = data\n",
    "#         else:\n",
    "#             self.data = data_cls.from_dict(data)\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         if self._data.x is not None and not use_node_attr:\n",
    "#             num_node_attributes = self.num_node_attributes\n",
    "#             self._data.x = self._data.x[:, num_node_attributes:]\n",
    "#         if self._data.edge_attr is not None and not use_edge_attr:\n",
    "#             num_edge_attrs = self.num_edge_attributes\n",
    "#             self._data.edge_attr = self._data.edge_attr[:, num_edge_attrs:]\n",
    "\n",
    "#     @property\n",
    "#     def raw_dir(self) -> str:\n",
    "#         name = f'raw{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def processed_dir(self) -> str:\n",
    "#         name = f'processed{\"_cleaned\" if self.cleaned else \"\"}'\n",
    "#         return osp.join(self.root, self.name, name)\n",
    "\n",
    "#     @property\n",
    "#     def num_node_labels(self) -> int:\n",
    "#         return self.sizes['num_node_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_node_attributes(self) -> int:\n",
    "#         return self.sizes['num_node_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_labels(self) -> int:\n",
    "#         return self.sizes['num_edge_labels']\n",
    "\n",
    "#     @property\n",
    "#     def num_edge_attributes(self) -> int:\n",
    "#         return self.sizes['num_edge_attributes']\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self) -> List[str]:\n",
    "#         names = ['A', 'graph_indicator']\n",
    "#         return [f'{self.name}_{name}.txt' for name in names]\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self) -> str:\n",
    "#         return 'data.pt'\n",
    "        \n",
    "        \n",
    "#         #Original Function\n",
    "# #     def download(self) -> None:\n",
    "# #         url = self.cleaned_url if self.cleaned else self.url\n",
    "# #         fs.cp(f'{url}/{self.name}.zip', self.raw_dir, extract=True)\n",
    "# #         for filename in fs.ls(osp.join(self.raw_dir, self.name)):\n",
    "# #             fs.mv(filename, osp.join(self.raw_dir, osp.basename(filename)))\n",
    "# #         fs.rm(osp.join(self.raw_dir, self.name))\n",
    "        \n",
    "#     #Dummy Function for already downloaded files\n",
    "#     def download(self) -> None:\n",
    "#         files = {\n",
    "#     'ENZYMES_A.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_A.txt',\n",
    "#     'ENZYMES_graph_indicator.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_indicator.txt',\n",
    "#     'ENZYMES_graph_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_graph_labels.txt',\n",
    "#     'ENZYMES_node_attributes.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_attributes.txt',\n",
    "#     'ENZYMES_node_labels.txt': 'https://raw.githubusercontent.com/snap-stanford/GraphRNN/master/dataset/ENZYMES/ENZYMES_node_labels.txt'\n",
    "#     }\n",
    "#         dest_dir = '/kaggle/working/ENZYMES/raw/'\n",
    "\n",
    "#         # Ensure destination directory exists\n",
    "#         if not os.path.exists(dest_dir):\n",
    "#             os.makedirs(dest_dir)\n",
    "\n",
    "#         # Function to download and save a file\n",
    "#         def download_and_save(url, destination):\n",
    "#             # Make the HTTP GET request to the file URL\n",
    "#             if os.dir.exists()\n",
    "#             response = requests.get(url)\n",
    "#             if response.status_code == 200:\n",
    "#                 # Write the file contents in binary mode\n",
    "#                 filename = os.path.join(destination, url.split('/')[-1])\n",
    "#                 with open(filename, 'wb') as file:\n",
    "#                     file.write(response.content)\n",
    "#                 print(f\"File saved as {filename}\")\n",
    "#             else:\n",
    "#                 print(f\"Failed to download {url}\")\n",
    "\n",
    "#         # Download and save each file\n",
    "#         for file_url in files.values():\n",
    "#             download_and_save(file_url, dest_dir)\n",
    "\n",
    "#     def process(self) -> None:\n",
    "#         self.data, self.slices, sizes = read_tu_data(self.raw_dir, self.name)\n",
    "#         print(self.data.cos_sim)\n",
    "#         if self.pre_filter is not None or self.pre_transform is not None:\n",
    "#             data_list = [self.get(idx) for idx in range(len(self))]\n",
    "\n",
    "#             if self.pre_filter is not None:\n",
    "#                 data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "#             self.data, self.slices = self.collate(data_list)\n",
    "#             self._data_list = None  # Reset cache.\n",
    "\n",
    "#         assert isinstance(self._data, Data)\n",
    "#         fs.torch_save(\n",
    "#             (self._data.to_dict(), self.slices, sizes, self._data.__class__),\n",
    "#             self.processed_paths[0],\n",
    "#         )\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f'{self.name}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c7d0da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:07.513644Z",
     "iopub.status.busy": "2024-06-16T13:04:07.512554Z",
     "iopub.status.idle": "2024-06-16T13:04:18.750570Z",
     "shell.execute_reply": "2024-06-16T13:04:18.749422Z"
    },
    "papermill": {
     "duration": 11.250747,
     "end_time": "2024-06-16T13:04:18.752922",
     "exception": false,
     "start_time": "2024-06-16T13:04:07.502175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/DD.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "data = TUDataset(root=f'/working/{DATASET}', name=f'{DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87736a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:18.774644Z",
     "iopub.status.busy": "2024-06-16T13:04:18.773687Z",
     "iopub.status.idle": "2024-06-16T13:04:18.779573Z",
     "shell.execute_reply": "2024-06-16T13:04:18.778293Z"
    },
    "papermill": {
     "duration": 0.019659,
     "end_time": "2024-06-16T13:04:18.782112",
     "exception": false,
     "start_time": "2024-06-16T13:04:18.762453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import aiohttp  # Import aiohttp to access ClientConnectorError\n",
    "# from requests.exceptions import SSLError\n",
    "\n",
    "# try:\n",
    "#     from torch_geometric.datasets import TUDataset\n",
    "#     data = TUDataset(root='/working/NCI1', name='NCI1')\n",
    "# except aiohttp.ClientConnectorSSLError as e:  # Catch connection errors specifically\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except requests.exceptions.SSLError as e:\n",
    "#     print(f\"Connection error occurred: {e}\")\n",
    "#     # Specify the folder where your dataset files are located\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)\n",
    "# except Exception as e:  # Catch any other exceptions\n",
    "#     print(f\"An unexpected error occurred: {e}\")\n",
    "#     folder = '/kaggle/working/'\n",
    "#     # Specify the prefix used in your dataset files\n",
    "#     prefix = 'NCI1'\n",
    "#     # Call the function assuming MyTUDataset is properly defined and imported\n",
    "#     data = MyTUDataset(folder, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c128a751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:18.802961Z",
     "iopub.status.busy": "2024-06-16T13:04:18.802540Z",
     "iopub.status.idle": "2024-06-16T13:04:18.808155Z",
     "shell.execute_reply": "2024-06-16T13:04:18.807108Z"
    },
    "papermill": {
     "duration": 0.018978,
     "end_time": "2024-06-16T13:04:18.810594",
     "exception": false,
     "start_time": "2024-06-16T13:04:18.791616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ID_dataset = IDAddingDataset(data, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcde5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:18.831024Z",
     "iopub.status.busy": "2024-06-16T13:04:18.830599Z",
     "iopub.status.idle": "2024-06-16T13:04:18.844225Z",
     "shell.execute_reply": "2024-06-16T13:04:18.843056Z"
    },
    "papermill": {
     "duration": 0.026916,
     "end_time": "2024-06-16T13:04:18.846849",
     "exception": false,
     "start_time": "2024-06-16T13:04:18.819933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 902], x=[188, 89], y=[1], id=2, num_edges=902, adj_mat=[188, 188])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e827b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:04:18.868215Z",
     "iopub.status.busy": "2024-06-16T13:04:18.867289Z",
     "iopub.status.idle": "2024-06-16T13:06:34.182900Z",
     "shell.execute_reply": "2024-06-16T13:06:34.181584Z"
    },
    "papermill": {
     "duration": 135.329488,
     "end_time": "2024-06-16T13:06:34.185969",
     "exception": false,
     "start_time": "2024-06-16T13:04:18.856481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "for graph in ID_dataset:\n",
    "    embeddings_dict[graph.id] = get_WL_embedding(graph, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f82dadad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:06:34.207731Z",
     "iopub.status.busy": "2024-06-16T13:06:34.207327Z",
     "iopub.status.idle": "2024-06-16T13:06:34.212613Z",
     "shell.execute_reply": "2024-06-16T13:06:34.211436Z"
    },
    "papermill": {
     "duration": 0.018547,
     "end_time": "2024-06-16T13:06:34.214982",
     "exception": false,
     "start_time": "2024-06-16T13:06:34.196435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Embedding_dataset = EmbeddingAddingDataset(ID_dataset, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35a36bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:06:34.236227Z",
     "iopub.status.busy": "2024-06-16T13:06:34.235821Z",
     "iopub.status.idle": "2024-06-16T13:06:46.410580Z",
     "shell.execute_reply": "2024-06-16T13:06:46.409443Z"
    },
    "papermill": {
     "duration": 12.188782,
     "end_time": "2024-06-16T13:06:46.413266",
     "exception": false,
     "start_time": "2024-06-16T13:06:34.224484",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_hashes, all_classes, mean_vector = get_mean_vectors(Embedding_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad96dbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:06:46.434491Z",
     "iopub.status.busy": "2024-06-16T13:06:46.434085Z",
     "iopub.status.idle": "2024-06-16T13:06:46.441409Z",
     "shell.execute_reply": "2024-06-16T13:06:46.440163Z"
    },
    "papermill": {
     "duration": 0.020607,
     "end_time": "2024-06-16T13:06:46.443643",
     "exception": false,
     "start_time": "2024-06-16T13:06:46.423036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 'all'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c47d0885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:06:46.465161Z",
     "iopub.status.busy": "2024-06-16T13:06:46.464752Z",
     "iopub.status.idle": "2024-06-16T13:14:50.117756Z",
     "shell.execute_reply": "2024-06-16T13:14:50.116492Z"
    },
    "papermill": {
     "duration": 483.667405,
     "end_time": "2024-06-16T13:14:50.120563",
     "exception": false,
     "start_time": "2024-06-16T13:06:46.453158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sims = {}\n",
    "class_cos_sims = {_class: [] for _class in all_classes}\n",
    "for graph in Embedding_dataset:\n",
    "    cos_sims[graph.id] = get_cos_sim(graph, all_hashes, all_classes, mean_vector)\n",
    "    class_cos_sims[graph.y.item()].append(cos_sims[graph.id]['class'])\n",
    "    class_cos_sims['all'].append(cos_sims[graph.id]['all'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6acf6c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:14:50.142778Z",
     "iopub.status.busy": "2024-06-16T13:14:50.142337Z",
     "iopub.status.idle": "2024-06-16T13:14:50.150269Z",
     "shell.execute_reply": "2024-06-16T13:14:50.149088Z"
    },
    "papermill": {
     "duration": 0.021486,
     "end_time": "2024-06-16T13:14:50.152494",
     "exception": false,
     "start_time": "2024-06-16T13:14:50.131008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32067023826583735,\n",
       " 0.47598331473795513,\n",
       " 0.3698638051703808,\n",
       " 0.2048801002445235,\n",
       " 0.34130605422383015,\n",
       " 0.8458389757068067,\n",
       " 0.6632897748113278,\n",
       " 0.37223439172811273,\n",
       " 0.4374908233387877,\n",
       " 0.35445337353035955,\n",
       " 0.39800961726288536,\n",
       " 0.18389547320395327,\n",
       " 0.42438046476467695,\n",
       " 0.23719959756785144,\n",
       " 0.42830277553229024,\n",
       " 0.5276144384493383,\n",
       " 0.4212979093191598,\n",
       " 0.20233035245711278,\n",
       " 0.18717879011593613,\n",
       " 0.47615506040872035,\n",
       " 0.874617175202521,\n",
       " 0.5292987899332061,\n",
       " 0.35199042977118833,\n",
       " 0.20910902817035387,\n",
       " 0.29139978555821594,\n",
       " 0.3546778764287951,\n",
       " 0.31148842343481353,\n",
       " 0.27337469841321027,\n",
       " 0.23672514132359393,\n",
       " 0.3514310207478517]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_cos_sims[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1473ec7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:14:50.174256Z",
     "iopub.status.busy": "2024-06-16T13:14:50.173454Z",
     "iopub.status.idle": "2024-06-16T13:14:52.831941Z",
     "shell.execute_reply": "2024-06-16T13:14:52.830723Z"
    },
    "papermill": {
     "duration": 2.672433,
     "end_time": "2024-06-16T13:14:52.834517",
     "exception": false,
     "start_time": "2024-06-16T13:14:50.162084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_z_scores = {}\n",
    "\n",
    "for graph in Embedding_dataset:\n",
    "    all_z_scores[graph.id] = calc_z_scores(graph, cos_sims, class_cos_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7060b67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:14:52.855966Z",
     "iopub.status.busy": "2024-06-16T13:14:52.855527Z",
     "iopub.status.idle": "2024-06-16T13:14:52.860817Z",
     "shell.execute_reply": "2024-06-16T13:14:52.859500Z"
    },
    "papermill": {
     "duration": 0.018921,
     "end_time": "2024-06-16T13:14:52.863322",
     "exception": false,
     "start_time": "2024-06-16T13:14:52.844401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final transform and dataset\n",
    "Final_dataset = FinalAddingDataset(Embedding_dataset, cos_sims, all_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6718f6df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:14:52.884721Z",
     "iopub.status.busy": "2024-06-16T13:14:52.884330Z",
     "iopub.status.idle": "2024-06-16T13:15:58.405371Z",
     "shell.execute_reply": "2024-06-16T13:15:58.404176Z"
    },
    "papermill": {
     "duration": 65.534715,
     "end_time": "2024-06-16T13:15:58.407921",
     "exception": false,
     "start_time": "2024-06-16T13:14:52.873206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_node_dict = {_cls: {graph.id: graph.num_nodes for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "num_node_mean_dict = {_cls: sum(num_node_dict[_cls].values())/len(num_node_dict[_cls].values()) for _cls in all_classes}\n",
    "node_diff_dict = {_cls: {graph.id: graph.num_nodes - num_node_mean_dict[_cls] for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "pos_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "neg_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "for _cls, _dict in node_diff_dict.items():\n",
    "    for idx, node_diff in _dict.items():\n",
    "        if node_diff > 0:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "        else:\n",
    "            pos_diff_dict[_cls][idx] = node_diff\n",
    "pos_num_node_dict = {_cls: len(pos_diff_dict[_cls]) for _cls in all_classes}\n",
    "neg_num_node_dict = {_cls: len(neg_diff_dict[_cls]) for _cls in all_classes}\n",
    "percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "for _cls, _dict in pos_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/pos_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/pos_num_node_dict[_cls]\n",
    "for _cls, _dict in neg_diff_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1], reverse=True)):\n",
    "        if _cls != 'all':\n",
    "            percentile_dict[idx]['class'] = i/neg_num_node_dict[_cls]\n",
    "        else:\n",
    "            percentile_dict[idx]['all'] = i/neg_num_node_dict[_cls]\n",
    "    \n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d180ff04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:15:58.429967Z",
     "iopub.status.busy": "2024-06-16T13:15:58.429161Z",
     "iopub.status.idle": "2024-06-16T13:15:58.435288Z",
     "shell.execute_reply": "2024-06-16T13:15:58.434003Z"
    },
    "papermill": {
     "duration": 0.019847,
     "end_time": "2024-06-16T13:15:58.437805",
     "exception": false,
     "start_time": "2024-06-16T13:15:58.417958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.6918505942275043, 'class': 0.5586107091172214}\n",
      "{'all': 0.7359932088285229, 'class': 0.61794500723589}\n",
      "{'all': 0.3684210526315789, 'class': 0.16208393632416787}\n",
      "{'all': 0.1460101867572156, 'class': 0.030390738060781478}\n",
      "{'all': 0.3370118845500849, 'class': 0.14327062228654125}\n",
      "{'all': 0.99830220713073, 'class': 0.9971056439942113}\n",
      "{'all': 0.9957555178268251, 'class': 0.9927641099855282}\n",
      "{'all': 0.8998302207130731, 'class': 0.8639652677279306}\n",
      "{'all': 0.7775891341256367, 'class': 0.6714905933429812}\n",
      "{'all': 0.2563667232597623, 'class': 0.0824891461649783}\n",
      "{'all': 0.6511035653650254, 'class': 0.5007235890014472}\n",
      "{'all': 0.4864176570458404, 'class': 0.28798842257597684}\n",
      "{'all': 0.6612903225806451, 'class': 0.5151953690303908}\n",
      "{'all': 0.5738539898132428, 'class': 0.3994211287988423}\n",
      "{'all': 0.4567062818336163, 'class': 0.2633863965267728}\n",
      "{'all': 0.8616298811544991, 'class': 0.8017366136034733}\n",
      "{'all': 0.5297113752122241, 'class': 0.3357452966714906}\n",
      "{'all': 0.45161290322580644, 'class': 0.2590448625180897}\n",
      "{'all': 0.27164685908319186, 'class': 0.08972503617945007}\n",
      "{'all': 0.7368421052631579, 'class': 0.6193921852387844}\n"
     ]
    }
   ],
   "source": [
    "num_node_percentile_dict = percentile_dict\n",
    "for x in range(20):\n",
    "    print(num_node_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b00ed78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:15:58.459226Z",
     "iopub.status.busy": "2024-06-16T13:15:58.458838Z",
     "iopub.status.idle": "2024-06-16T13:16:16.935932Z",
     "shell.execute_reply": "2024-06-16T13:16:16.934678Z"
    },
    "papermill": {
     "duration": 18.491495,
     "end_time": "2024-06-16T13:16:16.939082",
     "exception": false,
     "start_time": "2024-06-16T13:15:58.447587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_sim_dict = {_cls: {} for _cls in all_classes}\n",
    "for graph in Final_dataset:\n",
    "    cos_sim_dict[graph.y.item()][graph.id] = graph.cos_sim['class']\n",
    "    cos_sim_dict['all'][graph.id] = graph.cos_sim['all']\n",
    "            \n",
    "\n",
    "cat_len_dict = {_cls: len(cos_sim_dict[_cls].values()) for _cls in all_classes}\n",
    "cos_sim_percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "\n",
    "\n",
    "for _cls, _dict in cos_sim_dict.items():\n",
    "    for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "        if _cls != 'all':\n",
    "            cos_sim_percentile_dict[idx]['class'] = i/cat_len_dict[_cls]\n",
    "        else:\n",
    "            cos_sim_percentile_dict[idx]['all'] = i/cat_len_dict[_cls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d83415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:16.961007Z",
     "iopub.status.busy": "2024-06-16T13:16:16.960585Z",
     "iopub.status.idle": "2024-06-16T13:16:16.966615Z",
     "shell.execute_reply": "2024-06-16T13:16:16.965243Z"
    },
    "papermill": {
     "duration": 0.020359,
     "end_time": "2024-06-16T13:16:16.969495",
     "exception": false,
     "start_time": "2024-06-16T13:16:16.949136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 0.45076400679117146, 'class': 0.35311143270622286}\n",
      "{'all': 0.8692699490662139, 'class': 0.8219971056439942}\n",
      "{'all': 0.6112054329371817, 'class': 0.49782923299565845}\n",
      "{'all': 0.13752122241086587, 'class': 0.0824891461649783}\n",
      "{'all': 0.530560271646859, 'class': 0.4196816208393632}\n",
      "{'all': 0.99830220713073, 'class': 0.9971056439942113}\n",
      "{'all': 0.9932088285229203, 'class': 0.9898697539797395}\n",
      "{'all': 0.5967741935483871, 'class': 0.5065123010130246}\n",
      "{'all': 0.7784380305602716, 'class': 0.7091172214182344}\n",
      "{'all': 0.5730050933786078, 'class': 0.4602026049204052}\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(cos_sim_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad560ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:16.991658Z",
     "iopub.status.busy": "2024-06-16T13:16:16.991248Z",
     "iopub.status.idle": "2024-06-16T13:16:17.041430Z",
     "shell.execute_reply": "2024-06-16T13:16:17.040280Z"
    },
    "papermill": {
     "duration": 0.063965,
     "end_time": "2024-06-16T13:16:17.043937",
     "exception": false,
     "start_time": "2024-06-16T13:16:16.979972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentiles = [x for x in range(35, 91, 5)]\n",
    "cats = ['class', 'all']\n",
    "metrics = ['random', 'graph_order', 'cos_sim']\n",
    "train_indices_dict = {cat: {metric: {percentile: [] for percentile in percentiles} for metric in metrics} for cat in cats}\n",
    "for percentile in percentiles:\n",
    "    for idx, cat_pairs in cos_sim_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01*percentile:\n",
    "                train_indices_dict[cat]['cos_sim'][percentile].append(idx)\n",
    "    for idx, cat_pairs in num_node_percentile_dict.items():\n",
    "        for cat, val in cat_pairs.items():\n",
    "            if val < 0.01* percentile:\n",
    "                train_indices_dict[cat]['graph_order'][percentile].append(idx)\n",
    "    for _cls, id_pairs in num_node_dict.items():\n",
    "        for cat in cats:\n",
    "            size = int(percentile * 0.01 * len(id_pairs))\n",
    "            train_indices_dict[cat]['random'][percentile] = np.random.choice(list(id_pairs.keys()), size, replace=False)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc4393d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:17.065734Z",
     "iopub.status.busy": "2024-06-16T13:16:17.065339Z",
     "iopub.status.idle": "2024-06-16T13:16:17.080042Z",
     "shell.execute_reply": "2024-06-16T13:16:17.078829Z"
    },
    "papermill": {
     "duration": 0.02847,
     "end_time": "2024-06-16T13:16:17.082585",
     "exception": false,
     "start_time": "2024-06-16T13:16:17.054115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}_train_indices_dict.pkl'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(train_indices_dict, file)\n",
    "\n",
    "print(\"Dict saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa0dd55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:17.104913Z",
     "iopub.status.busy": "2024-06-16T13:16:17.104504Z",
     "iopub.status.idle": "2024-06-16T13:16:17.110226Z",
     "shell.execute_reply": "2024-06-16T13:16:17.109073Z"
    },
    "papermill": {
     "duration": 0.019591,
     "end_time": "2024-06-16T13:16:17.112708",
     "exception": false,
     "start_time": "2024-06-16T13:16:17.093117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # for x in range(6):\n",
    "# all_z_scores = [graph.num_nodes for graph in Final_dataset]\n",
    "# num_node_mean = sum(all_z_scores)/600\n",
    "# all_z_scores = [x - num_node_mean for x in all_z_scores]\n",
    "# percentiles = [50, 95, 99]  # Change these values based on your requirements (xx%)\n",
    "# percentile_values = np.percentile(all_z_scores, percentiles)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "# plt.title('Histogram of Z-Scores with Percentiles')\n",
    "# plt.xlabel('Z-Score')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # Add vertical lines for each percentile\n",
    "# for perc, value in zip(percentiles, percentile_values):\n",
    "#     plt.axvline(x=value, color='r', linestyle='--', label=f'{perc}th percentile: {value:.2f}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a217c427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:17.135104Z",
     "iopub.status.busy": "2024-06-16T13:16:17.134742Z",
     "iopub.status.idle": "2024-06-16T13:16:49.648249Z",
     "shell.execute_reply": "2024-06-16T13:16:49.646969Z"
    },
    "papermill": {
     "duration": 32.536869,
     "end_time": "2024-06-16T13:16:49.660481",
     "exception": false,
     "start_time": "2024-06-16T13:16:17.123612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the file where you want to save the dataset\n",
    "file_path = f'/kaggle/working/{DATASET}.pt'\n",
    "\n",
    "# Saving the dataset\n",
    "with open(file_path, 'wb') as file:\n",
    "    torch.save(Final_dataset, file)\n",
    "\n",
    "print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ac5e7ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T13:16:49.682467Z",
     "iopub.status.busy": "2024-06-16T13:16:49.682091Z",
     "iopub.status.idle": "2024-06-16T13:16:49.688638Z",
     "shell.execute_reply": "2024-06-16T13:16:49.687497Z"
    },
    "papermill": {
     "duration": 0.020546,
     "end_time": "2024-06-16T13:16:49.690848",
     "exception": false,
     "start_time": "2024-06-16T13:16:49.670302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of '/kaggle/working/':\n",
      "DD_train_indices_dict.pkl\n",
      "DD.pt\n",
      "__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory you want to list\n",
    "directory_path = '/kaggle/working/'\n",
    "\n",
    "# List all files and directories in the specified path\n",
    "contents = os.listdir(directory_path)\n",
    "\n",
    "print(\"Contents of '/kaggle/working/':\")\n",
    "for item in contents:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db4b50",
   "metadata": {
    "papermill": {
     "duration": 0.00954,
     "end_time": "2024-06-16T13:16:49.710536",
     "exception": false,
     "start_time": "2024-06-16T13:16:49.700996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 790.888755,
   "end_time": "2024-06-16T13:16:51.447780",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-16T13:03:40.559025",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
