{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84a12ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:32:10.321896Z",
     "iopub.status.busy": "2024-09-30T15:32:10.321448Z",
     "iopub.status.idle": "2024-09-30T15:32:32.949239Z",
     "shell.execute_reply": "2024-09-30T15:32:32.948043Z"
    },
    "papermill": {
     "duration": 22.648972,
     "end_time": "2024-09-30T15:32:32.952307",
     "exception": false,
     "start_time": "2024-09-30T15:32:10.303335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\r\n",
      "Successfully installed torch-geometric-2.6.1\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install torch torch-geometric\n",
    "first_run = False\n",
    "import os\n",
    "import os.path as osp\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "from typing import Callable, Dict, List, Optional\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    "    extract_tar,\n",
    "    extract_zip,\n",
    ")\n",
    "\n",
    "\n",
    "class MalNetTiny(InMemoryDataset):\n",
    "    r\"\"\"The MalNet Tiny dataset from the\n",
    "    `\"A Large-Scale Database for Graph Representation Learning\"\n",
    "    <https://openreview.net/pdf?id=1xDTDk3XPW>`_ paper.\n",
    "    :class:`MalNetTiny` contains 5,000 malicious and benign software function\n",
    "    call graphs across 5 different types. Each graph contains at most 5k nodes.\n",
    "\n",
    "    Args:\n",
    "        root (str): Root directory where the dataset should be saved.\n",
    "        split (str, optional): If :obj:`\"train\"`, loads the training dataset.\n",
    "            If :obj:`\"val\"`, loads the validation dataset.\n",
    "            If :obj:`\"trainval\"`, loads the training and validation dataset.\n",
    "            If :obj:`\"test\"`, loads the test dataset.\n",
    "            If :obj:`None`, loads the entire dataset.\n",
    "            (default: :obj:`None`)\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "        pre_filter (callable, optional): A function that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
    "            value, indicating whether the data object should be included in the\n",
    "            final dataset. (default: :obj:`None`)\n",
    "        force_reload (bool, optional): Whether to re-process the dataset.\n",
    "            (default: :obj:`False`)\n",
    "    \"\"\"\n",
    "    data_url = ('http://malnet.cc.gatech.edu/'\n",
    "                'graph-data/malnet-graphs-tiny.tar.gz')\n",
    "    split_url = 'http://malnet.cc.gatech.edu/split-info/split_info_tiny.zip'\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        split: Optional[str] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "        force_reload: bool = False,\n",
    "    ) -> None:\n",
    "        if split not in {'train', 'val', 'trainval', 'test', None}:\n",
    "            raise ValueError(f'Split \"{split}\" found, but expected either '\n",
    "                             f'\"train\", \"val\", \"trainval\", \"test\" or None')\n",
    "        super().__init__(root, transform, pre_transform, pre_filter,\n",
    "                         force_reload=force_reload)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "        if split is not None:\n",
    "            split_slices = torch.load(self.processed_paths[1])\n",
    "            if split == 'train':\n",
    "                self._indices = range(split_slices[0], split_slices[1])\n",
    "            elif split == 'val':\n",
    "                self._indices = range(split_slices[1], split_slices[2])\n",
    "            elif split == 'trainval':\n",
    "                self._indices = range(split_slices[0], split_slices[2])\n",
    "            elif split == 'test':\n",
    "                self._indices = range(split_slices[2], split_slices[3])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['malnet-graphs-tiny', osp.join('split_info_tiny', 'type')]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        return ['data.pt', 'split_slices.pt']\n",
    "\n",
    "    def download(self) -> None:\n",
    "        path = download_url(self.data_url, self.raw_dir)\n",
    "        extract_tar(path, self.raw_dir)\n",
    "        os.unlink(path)\n",
    "\n",
    "        path = download_url(self.split_url, self.raw_dir)\n",
    "        extract_zip(path, self.raw_dir)\n",
    "        os.unlink(path)\n",
    "\n",
    "    def process(self) -> None:\n",
    "        y_map: Dict[str, int] = {}\n",
    "        data_list = []\n",
    "        split_slices = [0]\n",
    "\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            with open(osp.join(self.raw_paths[1], f'{split}.txt'), 'r') as f:\n",
    "                filenames = f.read().split('\\n')[:-1]\n",
    "                split_slices.append(split_slices[-1] + len(filenames))\n",
    "\n",
    "            for filename in filenames:\n",
    "                path = osp.join(self.raw_paths[0], f'{filename}.edgelist')\n",
    "                malware_type = filename.split('/')[0]\n",
    "                y = y_map.setdefault(malware_type, len(y_map))\n",
    "\n",
    "                with open(path, 'r') as f:\n",
    "                    edges = f.read().split('\\n')[5:-1]\n",
    "\n",
    "                edge_indices = [[int(s) for s in e.split()] for e in edges]\n",
    "                edge_index = torch.tensor(edge_indices).t().contiguous()\n",
    "                num_nodes = int(edge_index.max()) + 1\n",
    "                data = Data(edge_index=edge_index, y=y, num_nodes=num_nodes)\n",
    "                data_list.append(data)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])\n",
    "        torch.save(split_slices, self.processed_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83992a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:32:32.990402Z",
     "iopub.status.busy": "2024-09-30T15:32:32.989491Z",
     "iopub.status.idle": "2024-09-30T15:33:26.718862Z",
     "shell.execute_reply": "2024-09-30T15:33:26.717640Z"
    },
    "papermill": {
     "duration": 53.751848,
     "end_time": "2024-09-30T15:33:26.721865",
     "exception": false,
     "start_time": "2024-09-30T15:32:32.970017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://malnet.cc.gatech.edu/graph-data/malnet-graphs-tiny.tar.gz\n",
      "Extracting /kaggle/working/malnetTiny/raw/malnet-graphs-tiny.tar.gz\n",
      "Downloading http://malnet.cc.gatech.edu/split-info/split_info_tiny.zip\n",
      "Extracting /kaggle/working/malnetTiny/raw/split_info_tiny.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch - Number of graphs: 32\n",
      "Batch - Edge index shape: torch.Size([2, 103175])\n",
      "Batch - Labels: tensor([2, 3, 3, 2, 0, 3, 3, 0, 2, 3, 0, 4, 0, 0, 0, 0, 4, 4, 1, 1, 2, 0, 0, 0,\n",
      "        2, 2, 1, 4, 0, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Instantiate the dataset class for the train split\n",
    "dataset_root = '/kaggle/working/malnetTiny'  # Set the path where you want to download the data\n",
    "\n",
    "all_dataset = MalNetTiny(root=dataset_root, split=None)\n",
    "# Load the dataset with the train split\n",
    "train_dataset = MalNetTiny(root=dataset_root, split='train')\n",
    "\n",
    "# Load the validation and test splits as well if needed\n",
    "val_dataset = MalNetTiny(root=dataset_root, split='val')\n",
    "test_dataset = MalNetTiny(root=dataset_root, split='test')\n",
    "\n",
    "# Create data loaders for each split (if needed)\n",
    "all_loader = DataLoader(all_dataset, batch_size=32, shuffle = False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through the dataset and print some basic information about the batches\n",
    "for data in train_loader:\n",
    "    print(f\"Batch - Number of graphs: {data.num_graphs}\")\n",
    "    print(f\"Batch - Edge index shape: {data.edge_index.shape}\")\n",
    "    print(f\"Batch - Labels: {data.y}\")\n",
    "    break  # Only show the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a17d617",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:26.756810Z",
     "iopub.status.busy": "2024-09-30T15:33:26.756404Z",
     "iopub.status.idle": "2024-09-30T15:33:27.024114Z",
     "shell.execute_reply": "2024-09-30T15:33:27.023110Z"
    },
    "papermill": {
     "duration": 0.287551,
     "end_time": "2024-09-30T15:33:27.026571",
     "exception": false,
     "start_time": "2024-09-30T15:33:26.739020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.io import fs, read_txt_array\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import math\n",
    "from typing import Callable, List, Optional, Tuple, Dict\n",
    "from torch import Tensor\n",
    "import os\n",
    "import gc\n",
    "import requests\n",
    "from torch_geometric.utils import coalesce, cumsum, one_hot, remove_self_loops\n",
    "from scipy.sparse import coo_array\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bb8729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.060331Z",
     "iopub.status.busy": "2024-09-30T15:33:27.059960Z",
     "iopub.status.idle": "2024-09-30T15:33:27.067793Z",
     "shell.execute_reply": "2024-09-30T15:33:27.066607Z"
    },
    "papermill": {
     "duration": 0.027577,
     "end_time": "2024-09-30T15:33:27.070138",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.042561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IDAddingDataset:\n",
    "    def __init__(self, dataset, attr_func):\n",
    "        self.dataset = dataset\n",
    "        self.attr_func = attr_func\n",
    "        self.indices = np.arange(0, len(dataset.indices()))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.id = self.indices[idx]\n",
    "        data.num_edges = self.dataset[idx].edge_index.size(1)\n",
    "        data.adj_mat = to_scipy_sparse_matrix(self.dataset[idx].edge_index, num_nodes=self.dataset[idx].num_nodes).toarray().astype(int)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c844661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.104873Z",
     "iopub.status.busy": "2024-09-30T15:33:27.103638Z",
     "iopub.status.idle": "2024-09-30T15:33:27.110778Z",
     "shell.execute_reply": "2024-09-30T15:33:27.109448Z"
    },
    "papermill": {
     "duration": 0.026925,
     "end_time": "2024-09-30T15:33:27.113090",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.086165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingAddingDataset:\n",
    "    def __init__(self, dataset, embedding_dict):\n",
    "        self.dataset = dataset\n",
    "        self.embedding_dict = embedding_dict\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.embedding = self.embedding_dict[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b96c2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.146784Z",
     "iopub.status.busy": "2024-09-30T15:33:27.146390Z",
     "iopub.status.idle": "2024-09-30T15:33:27.153268Z",
     "shell.execute_reply": "2024-09-30T15:33:27.152014Z"
    },
    "papermill": {
     "duration": 0.026395,
     "end_time": "2024-09-30T15:33:27.155522",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.129127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalAddingDataset:\n",
    "    def __init__(self, Embedding_dataset, cos_sims, all_z_scores):\n",
    "        self.dataset = Embedding_dataset\n",
    "        self.cos_sims = cos_sims\n",
    "        self.all_z_scores = all_z_scores\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx].clone()  # Clone the data to avoid modifying the original dataset\n",
    "        data.cos_sim = self.cos_sims[self.dataset[idx].id]\n",
    "        data.z_score = self.all_z_scores[self.dataset[idx].id]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb90bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.188709Z",
     "iopub.status.busy": "2024-09-30T15:33:27.188308Z",
     "iopub.status.idle": "2024-09-30T15:33:27.203935Z",
     "shell.execute_reply": "2024-09-30T15:33:27.202833Z"
    },
    "papermill": {
     "duration": 0.035266,
     "end_time": "2024-09-30T15:33:27.206509",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.171243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xxhash\n",
    "\n",
    "def stable_hash(value):\n",
    "    return xxhash.xxh64(str(value)).intdigest()\n",
    "\n",
    "def get_WL_embedding(data, n_iter):\n",
    "    graph = data.adj_mat\n",
    "    graph_order = graph.shape[0]  # Number of nodes\n",
    "    graph_hash_dict = {}  # Mapping of unique labels and counts\n",
    "\n",
    "    # Initialize labels based on node degrees\n",
    "    labels = np.sum(graph, axis=1)\n",
    "    hashed_labels = np.array([stable_hash(label) for label in labels])\n",
    "\n",
    "    # Precompute neighbor indices\n",
    "    indices = [np.nonzero(graph[i])[0] for i in range(graph_order)]\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Concatenate node's hash with its sorted neighbor hashes\n",
    "        hashes = np.array([\n",
    "            stable_hash((hashed_labels[i],) + tuple(np.sort(hashed_labels[indices[i]])))\n",
    "            for i in range(graph_order)\n",
    "        ])\n",
    "\n",
    "        # Update the graph hash dictionary with counts\n",
    "        unique_hashes, counts = np.unique(hashes, return_counts=True)\n",
    "\n",
    "        for h, c in zip(unique_hashes, counts):\n",
    "            graph_hash_dict[h] = graph_hash_dict.get(h, 0) + c\n",
    "\n",
    "        # Update labels for the next iteration\n",
    "        hashed_labels = hashes\n",
    "\n",
    "    return graph_hash_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d081fa01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.240149Z",
     "iopub.status.busy": "2024-09-30T15:33:27.239774Z",
     "iopub.status.idle": "2024-09-30T15:33:27.251132Z",
     "shell.execute_reply": "2024-09-30T15:33:27.249786Z"
    },
    "papermill": {
     "duration": 0.031382,
     "end_time": "2024-09-30T15:33:27.253744",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.222362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mean_vectors(dataset, all_hashes, all_classes):\n",
    "    empty_array = np.zeros(dataset[0].embedding.todense().shape)\n",
    "    mean_vector_dict = {_cls: empty_array for _cls in all_classes}\n",
    "    samples_per_class_dict = {_cls:0 for _cls in all_classes}\n",
    "    \n",
    "    for graph in tqdm(dataset, desc='4/8 Calculating Mean vectors'):\n",
    "        \n",
    "        mean_vector_dict[int(graph.y.item())]+=graph.embedding.toarray()\n",
    "        samples_per_class_dict[int(graph.y.item())]+=1\n",
    "    for _cls in all_classes:\n",
    "        mean_vector_dict[_cls] /= samples_per_class_dict[_cls]\n",
    "    return mean_vector_dict\n",
    "\n",
    "def get_cos_sim(dataset, mean_vectors):\n",
    "    cos_sims, norm_dict = {}, {}\n",
    "    \n",
    "    # Precompute the norm for each class mean vector\n",
    "    for _class in range(5):\n",
    "        norm_dict[_class] = np.linalg.norm(mean_vectors[_class])  # L2 norm of the mean vector\n",
    "    \n",
    "    # Compute cosine similarity for each graph\n",
    "    for graph in tqdm(dataset, desc='5/8 Calculating cosine similarities'):\n",
    "        graph_embedding = graph.embedding.todense()[0]  # Get the graph's embedding as a dense vector\n",
    "        graph_norm = np.linalg.norm(graph_embedding)  # L2 norm of the graph's embedding\n",
    "        \n",
    "        # Dot product between the graph's embedding and its class mean vector\n",
    "        class_numerator = graph_embedding @ mean_vectors[graph.y.item()][0]\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        class_denom = norm_dict[graph.y.item()] * graph_norm\n",
    "        cos_sims[graph.id] = class_numerator / class_denom if class_denom != 0 else 0.0\n",
    "    \n",
    "    return cos_sims\n",
    "\n",
    "\n",
    "def calc_z_scores(dataset, cos_sims, class_cos_sims):\n",
    "    # Ensure data types are numpy arrays for statistical computation\n",
    "    z_scores = {}\n",
    "    SDs = {_cls: np.std(class_cos_sims[_cls]) for _cls in class_cos_sims.keys()}\n",
    "    for graph in tqdm(dataset, desc='7/8 Calculating z-scores'):\n",
    "        cos_sim = cos_sims[graph.id]\n",
    "        z_scores[graph.id]= cos_sim/SDs[graph.y.item()]\n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5f9027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.287795Z",
     "iopub.status.busy": "2024-09-30T15:33:27.287374Z",
     "iopub.status.idle": "2024-09-30T15:33:27.304901Z",
     "shell.execute_reply": "2024-09-30T15:33:27.303560Z"
    },
    "papermill": {
     "duration": 0.037598,
     "end_time": "2024-09-30T15:33:27.307420",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.269822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Process_dataset(dataset, prefix):\n",
    "    ID_dataset = IDAddingDataset(dataset, None)\n",
    "    embeddings_dict = {}\n",
    "    all_hashes=set()\n",
    "    all_classes = set()\n",
    "    from tqdm import tqdm\n",
    "    for graph in tqdm(ID_dataset, desc='1/8 Adding Embeddings'):\n",
    "        embedding = get_WL_embedding(graph, 3)\n",
    "        embeddings_dict[graph.id] = embedding\n",
    "        all_hashes.update(embedding.keys())\n",
    "        all_classes.update(graph.y)\n",
    "    gc.collect()\n",
    "    all_classes = set(range(5))\n",
    "    all_hashes_new = list(all_hashes)\n",
    "    empty_vector = np.zeros(len(all_hashes_new))\n",
    "    index_dict = {all_hashes_new[i]: i for i in range(len(all_hashes_new))}\n",
    "    new_embedding_dict = {}\n",
    "    sum_vector = empty_vector.copy()\n",
    "    indices_to_delete = []\n",
    "\n",
    "    # Create coo_arrays as before and calculate sum_vector\n",
    "    for graph in tqdm(ID_dataset, desc='2/8 Standardizing Vectors'):\n",
    "        this_vector = empty_vector.copy()\n",
    "        for key, value in embeddings_dict[graph.id].items():\n",
    "            this_vector[index_dict[key]] = value\n",
    "            sum_vector[index_dict[key]] += value\n",
    "        new_embedding_dict[graph.id] = coo_array(this_vector)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Identify indices to delete\n",
    "    for i, val in enumerate(sum_vector):\n",
    "        if val < 7:  # If this value is present in less than 0.2% of samples\n",
    "            indices_to_delete.append(i)\n",
    "\n",
    "    # Function to filter out the indices from coo_array\n",
    "    def filter_coo_array(sparse_matrix, indices_to_delete):\n",
    "        vector = sparse_matrix.todense()[0]\n",
    "        vector = np.delete(vector, indices_to_delete)\n",
    "        return coo_array(vector)\n",
    "\n",
    "\n",
    "    # Recreate new_embedding_dict with filtered indices\n",
    "    filtered_embedding_dict = {}\n",
    "    for graph_id, sparse_matrix in tqdm(new_embedding_dict.items(), desc='3/8 Filtering out rare hashes.'):\n",
    "        filtered_embedding_dict[graph_id] = filter_coo_array(sparse_matrix, indices_to_delete)\n",
    "\n",
    "    gc.collect()\n",
    "    Embedding_dataset = EmbeddingAddingDataset(ID_dataset, filtered_embedding_dict)\n",
    "    mean_vector = get_mean_vectors(Embedding_dataset, all_hashes, all_classes)\n",
    "    \n",
    "    cos_sims = get_cos_sim(Embedding_dataset, mean_vector)\n",
    "    class_cos_sims = {_class: [] for _class in all_classes}\n",
    "    for graph in tqdm(Embedding_dataset, desc='6/8 grouping cosine sims by category'):\n",
    "        class_cos_sims[graph.y.item()].append(cos_sims[graph.id])\n",
    "        \n",
    "    z_scores = calc_z_scores(Embedding_dataset, cos_sims, class_cos_sims)\n",
    "\n",
    "    class_z_scores = {i: [] for i in range(5)}\n",
    "    Final_dataset = FinalAddingDataset(Embedding_dataset, cos_sims, z_scores)\n",
    "    for graph in tqdm(Final_dataset, desc='8/8 grouping z-scores by category'):\n",
    "        class_z_scores[graph.y.item()].append(graph.z_score)\n",
    "    class_z_scores = {cat: np.array(scores) for cat, scores in class_z_scores.items()}\n",
    "    \n",
    "    if not os.path.exists(f'/kaggle/working/{prefix}'):\n",
    "        print(f\"Creating directory: /kaggle/working/{prefix}\")\n",
    "        os.mkdir(f'/kaggle/working/{prefix}')\n",
    "    else:\n",
    "        print(f\"Directory already exists: /kaggle/working/{prefix}\")\n",
    "\n",
    "\n",
    "        # Saving the dataset\n",
    "        with open(f'/kaggle/working/{prefix}/malnetProcessed.pt', 'wb') as file:\n",
    "            torch.save(Final_dataset, file)\n",
    "\n",
    "        with open(f'/kaggle/working/{prefix}/classCossims.pt', 'wb') as file:\n",
    "            torch.save(class_cos_sims, file)\n",
    "\n",
    "        with open(f'/kaggle/working/{prefix}/datasetCossims.pt', 'wb') as file:\n",
    "            torch.save(cos_sims, file)\n",
    "\n",
    "        with open(f'/kaggle/working/{prefix}/zScores.pt', 'wb') as file:\n",
    "            torch.save(z_scores, file)\n",
    "\n",
    "        with open(f'/kaggle/working/{prefix}/ClassZScores.pt', 'wb') as file:\n",
    "            torch.save(class_z_scores, file)\n",
    "\n",
    "        with open(f'/kaggle/working/{prefix}/meanVectors.pt', 'wb') as file:\n",
    "            torch.save(mean_vector, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6400ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T15:33:27.341656Z",
     "iopub.status.busy": "2024-09-30T15:33:27.341246Z",
     "iopub.status.idle": "2024-09-30T16:08:56.766029Z",
     "shell.execute_reply": "2024-09-30T16:08:56.764936Z"
    },
    "papermill": {
     "duration": 2129.445823,
     "end_time": "2024-09-30T16:08:56.769250",
     "exception": false,
     "start_time": "2024-09-30T15:33:27.323427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/8 Adding Embeddings: 100%|██████████| 5000/5000 [06:12<00:00, 13.43it/s]\n",
      "2/8 Standardizing Vectors: 100%|██████████| 5000/5000 [02:03<00:00, 40.35it/s]\n",
      "3/8 Filtering out rare hashes.: 100%|██████████| 5000/5000 [01:39<00:00, 50.29it/s]\n",
      "4/8 Calculating Mean vectors: 100%|██████████| 5000/5000 [03:29<00:00, 23.88it/s]\n",
      "5/8 Calculating cosine similarities: 100%|██████████| 5000/5000 [04:44<00:00, 17.58it/s]\n",
      "6/8 grouping cosine sims by category: 100%|██████████| 5000/5000 [03:27<00:00, 24.11it/s]\n",
      "7/8 Calculating z-scores: 100%|██████████| 5000/5000 [03:27<00:00, 24.12it/s]\n",
      "8/8 grouping z-scores by category: 100%|██████████| 5000/5000 [10:24<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /kaggle/working/all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Process_dataset(all_dataset, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45827e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:08:57.977507Z",
     "iopub.status.busy": "2024-09-30T16:08:57.977114Z",
     "iopub.status.idle": "2024-09-30T16:33:40.688834Z",
     "shell.execute_reply": "2024-09-30T16:33:40.687157Z"
    },
    "papermill": {
     "duration": 1483.357025,
     "end_time": "2024-09-30T16:33:40.691939",
     "exception": false,
     "start_time": "2024-09-30T16:08:57.334914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/8 Adding Embeddings: 100%|██████████| 3500/3500 [04:14<00:00, 13.73it/s]\n",
      "2/8 Standardizing Vectors: 100%|██████████| 3500/3500 [01:23<00:00, 42.10it/s]\n",
      "3/8 Filtering out rare hashes.: 100%|██████████| 3500/3500 [01:08<00:00, 50.88it/s]\n",
      "4/8 Calculating Mean vectors: 100%|██████████| 3500/3500 [02:22<00:00, 24.49it/s]\n",
      "5/8 Calculating cosine similarities: 100%|██████████| 3500/3500 [03:21<00:00, 17.34it/s]\n",
      "6/8 grouping cosine sims by category: 100%|██████████| 3500/3500 [02:23<00:00, 24.42it/s]\n",
      "7/8 Calculating z-scores: 100%|██████████| 3500/3500 [02:24<00:00, 24.27it/s]\n",
      "8/8 grouping z-scores by category: 100%|██████████| 3500/3500 [07:22<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /kaggle/working/train\n"
     ]
    }
   ],
   "source": [
    "Process_dataset(train_dataset, 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa7e3ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:33:42.608724Z",
     "iopub.status.busy": "2024-09-30T16:33:42.607560Z",
     "iopub.status.idle": "2024-09-30T16:41:06.649783Z",
     "shell.execute_reply": "2024-09-30T16:41:06.648294Z"
    },
    "papermill": {
     "duration": 445.006794,
     "end_time": "2024-09-30T16:41:06.653204",
     "exception": false,
     "start_time": "2024-09-30T16:33:41.646410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/8 Adding Embeddings: 100%|██████████| 1000/1000 [01:18<00:00, 12.77it/s]\n",
      "2/8 Standardizing Vectors: 100%|██████████| 1000/1000 [00:24<00:00, 41.17it/s]\n",
      "3/8 Filtering out rare hashes.: 100%|██████████| 1000/1000 [00:09<00:00, 101.29it/s]\n",
      "4/8 Calculating Mean vectors: 100%|██████████| 1000/1000 [00:42<00:00, 23.36it/s]\n",
      "5/8 Calculating cosine similarities: 100%|██████████| 1000/1000 [00:57<00:00, 17.43it/s]\n",
      "6/8 grouping cosine sims by category: 100%|██████████| 1000/1000 [00:42<00:00, 23.43it/s]\n",
      "7/8 Calculating z-scores: 100%|██████████| 1000/1000 [00:42<00:00, 23.42it/s]\n",
      "8/8 grouping z-scores by category: 100%|██████████| 1000/1000 [02:25<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /kaggle/working/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Process_dataset(test_dataset, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d32448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:41:08.974299Z",
     "iopub.status.busy": "2024-09-30T16:41:08.973826Z",
     "iopub.status.idle": "2024-09-30T16:44:29.337978Z",
     "shell.execute_reply": "2024-09-30T16:44:29.336710Z"
    },
    "papermill": {
     "duration": 201.595935,
     "end_time": "2024-09-30T16:44:29.340840",
     "exception": false,
     "start_time": "2024-09-30T16:41:07.744905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/8 Adding Embeddings: 100%|██████████| 500/500 [00:38<00:00, 13.00it/s]\n",
      "2/8 Standardizing Vectors: 100%|██████████| 500/500 [00:11<00:00, 41.90it/s]\n",
      "3/8 Filtering out rare hashes.: 100%|██████████| 500/500 [00:02<00:00, 177.36it/s]\n",
      "4/8 Calculating Mean vectors: 100%|██████████| 500/500 [00:21<00:00, 23.74it/s]\n",
      "5/8 Calculating cosine similarities: 100%|██████████| 500/500 [00:20<00:00, 24.21it/s]\n",
      "6/8 grouping cosine sims by category: 100%|██████████| 500/500 [00:20<00:00, 24.26it/s]\n",
      "7/8 Calculating z-scores: 100%|██████████| 500/500 [00:20<00:00, 24.03it/s]\n",
      "8/8 grouping z-scores by category: 100%|██████████| 500/500 [01:03<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /kaggle/working/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Process_dataset(val_dataset, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0871b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:31.661213Z",
     "iopub.status.busy": "2024-09-30T16:44:31.660844Z",
     "iopub.status.idle": "2024-09-30T16:44:31.665742Z",
     "shell.execute_reply": "2024-09-30T16:44:31.664635Z"
    },
    "papermill": {
     "duration": 1.205686,
     "end_time": "2024-09-30T16:44:31.667927",
     "exception": false,
     "start_time": "2024-09-30T16:44:30.462241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print([x for x in os.scandir('/kaggle/working/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9405f52f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:34.029769Z",
     "iopub.status.busy": "2024-09-30T16:44:34.029282Z",
     "iopub.status.idle": "2024-09-30T16:44:34.033970Z",
     "shell.execute_reply": "2024-09-30T16:44:34.032892Z"
    },
    "papermill": {
     "duration": 1.163442,
     "end_time": "2024-09-30T16:44:34.036537",
     "exception": false,
     "start_time": "2024-09-30T16:44:32.873095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ID_dataset = IDAddingDataset(train_dataset, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1708b63f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:36.478606Z",
     "iopub.status.busy": "2024-09-30T16:44:36.478154Z",
     "iopub.status.idle": "2024-09-30T16:44:36.482963Z",
     "shell.execute_reply": "2024-09-30T16:44:36.481893Z"
    },
    "papermill": {
     "duration": 1.250072,
     "end_time": "2024-09-30T16:44:36.485205",
     "exception": false,
     "start_time": "2024-09-30T16:44:35.235133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del data\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d79d33d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:38.817112Z",
     "iopub.status.busy": "2024-09-30T16:44:38.816705Z",
     "iopub.status.idle": "2024-09-30T16:44:38.821452Z",
     "shell.execute_reply": "2024-09-30T16:44:38.820402Z"
    },
    "papermill": {
     "duration": 1.20555,
     "end_time": "2024-09-30T16:44:38.823886",
     "exception": false,
     "start_time": "2024-09-30T16:44:37.618336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import networkx as nx\n",
    "# G = nx.from_numpy_array(ID_dataset[1].adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7106307d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:41.161723Z",
     "iopub.status.busy": "2024-09-30T16:44:41.161320Z",
     "iopub.status.idle": "2024-09-30T16:44:41.167980Z",
     "shell.execute_reply": "2024-09-30T16:44:41.166275Z"
    },
    "papermill": {
     "duration": 1.156197,
     "end_time": "2024-09-30T16:44:41.171409",
     "exception": false,
     "start_time": "2024-09-30T16:44:40.015212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install graphistry\n",
    "# # import graphistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e60319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:43.586531Z",
     "iopub.status.busy": "2024-09-30T16:44:43.586137Z",
     "iopub.status.idle": "2024-09-30T16:44:43.591060Z",
     "shell.execute_reply": "2024-09-30T16:44:43.589971Z"
    },
    "papermill": {
     "duration": 1.224426,
     "end_time": "2024-09-30T16:44:43.593678",
     "exception": false,
     "start_time": "2024-09-30T16:44:42.369252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphistry.register(api=3, username='lukemiller1987', password='yhwggP56C9tm!WF', protocol='https', server='hub.graphistry.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "431d67aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:45.917267Z",
     "iopub.status.busy": "2024-09-30T16:44:45.916880Z",
     "iopub.status.idle": "2024-09-30T16:44:45.921991Z",
     "shell.execute_reply": "2024-09-30T16:44:45.920873Z"
    },
    "papermill": {
     "duration": 1.205712,
     "end_time": "2024-09-30T16:44:45.924156",
     "exception": false,
     "start_time": "2024-09-30T16:44:44.718444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphistry.bind(source='src', destination='dst', node='nodeid').plot(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9d7c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:48.239415Z",
     "iopub.status.busy": "2024-09-30T16:44:48.239065Z",
     "iopub.status.idle": "2024-09-30T16:44:48.243745Z",
     "shell.execute_reply": "2024-09-30T16:44:48.242809Z"
    },
    "papermill": {
     "duration": 1.117464,
     "end_time": "2024-09-30T16:44:48.246017",
     "exception": false,
     "start_time": "2024-09-30T16:44:47.128553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embeddings_dict = {}\n",
    "# all_hashes=set()\n",
    "# all_classes = set()\n",
    "# from tqdm import tqdm\n",
    "# for graph in tqdm(ID_dataset, desc='1/ Calculating Embeddings'):\n",
    "#     embedding = get_WL_embedding(graph, 3)\n",
    "#     embeddings_dict[graph.id] = embedding\n",
    "#     all_hashes.update(embedding.keys())\n",
    "#     all_classes.update(graph.y)\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "187072cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:50.650410Z",
     "iopub.status.busy": "2024-09-30T16:44:50.649978Z",
     "iopub.status.idle": "2024-09-30T16:44:50.654893Z",
     "shell.execute_reply": "2024-09-30T16:44:50.653678Z"
    },
    "papermill": {
     "duration": 1.218276,
     "end_time": "2024-09-30T16:44:50.657480",
     "exception": false,
     "start_time": "2024-09-30T16:44:49.439204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_classes = set(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de901244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:53.042168Z",
     "iopub.status.busy": "2024-09-30T16:44:53.041755Z",
     "iopub.status.idle": "2024-09-30T16:44:53.047918Z",
     "shell.execute_reply": "2024-09-30T16:44:53.046654Z"
    },
    "papermill": {
     "duration": 1.22715,
     "end_time": "2024-09-30T16:44:53.050337",
     "exception": false,
     "start_time": "2024-09-30T16:44:51.823187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy.sparse import coo_array\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# all_hashes_new = list(all_hashes)\n",
    "# empty_vector = np.zeros(len(all_hashes_new))\n",
    "# index_dict = {all_hashes_new[i]: i for i in range(len(all_hashes_new))}\n",
    "# new_embedding_dict = {}\n",
    "# sum_vector = empty_vector.copy()\n",
    "# indices_to_delete = []\n",
    "\n",
    "# # Create coo_arrays as before and calculate sum_vector\n",
    "# for graph in tqdm(ID_dataset):\n",
    "#     this_vector = empty_vector.copy()\n",
    "#     for key, value in embeddings_dict[graph.id].items():\n",
    "#         this_vector[index_dict[key]] = value\n",
    "#         sum_vector[index_dict[key]] += value\n",
    "#     new_embedding_dict[graph.id] = coo_array(this_vector)\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# # Identify indices to delete\n",
    "# for i, val in enumerate(sum_vector):\n",
    "#     if val < 7:  # If this value is present in less than 0.2% of samples\n",
    "#         indices_to_delete.append(i)\n",
    "\n",
    "# # Function to filter out the indices from coo_array\n",
    "# def filter_coo_array(sparse_matrix, indices_to_delete):\n",
    "#     vector = sparse_matrix.todense()[0]\n",
    "#     vector = np.delete(vector, indices_to_delete)\n",
    "#     return coo_array(vector)\n",
    "\n",
    "\n",
    "# # Recreate new_embedding_dict with filtered indices\n",
    "# filtered_embedding_dict = {}\n",
    "# for graph_id, sparse_matrix in tqdm(new_embedding_dict.items()):\n",
    "#     filtered_embedding_dict[graph_id] = filter_coo_array(sparse_matrix, indices_to_delete)\n",
    "\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4264bd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:55.386422Z",
     "iopub.status.busy": "2024-09-30T16:44:55.386048Z",
     "iopub.status.idle": "2024-09-30T16:44:55.390873Z",
     "shell.execute_reply": "2024-09-30T16:44:55.389674Z"
    },
    "papermill": {
     "duration": 1.11976,
     "end_time": "2024-09-30T16:44:55.393140",
     "exception": false,
     "start_time": "2024-09-30T16:44:54.273380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding_dataset = EmbeddingAddingDataset(ID_dataset, filtered_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48d31b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:44:57.785706Z",
     "iopub.status.busy": "2024-09-30T16:44:57.784833Z",
     "iopub.status.idle": "2024-09-30T16:44:57.789554Z",
     "shell.execute_reply": "2024-09-30T16:44:57.788495Z"
    },
    "papermill": {
     "duration": 1.205355,
     "end_time": "2024-09-30T16:44:57.791751",
     "exception": false,
     "start_time": "2024-09-30T16:44:56.586396",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean_vector = get_mean_vectors(Embedding_dataset, all_hashes, all_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b62238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:00.100344Z",
     "iopub.status.busy": "2024-09-30T16:45:00.099965Z",
     "iopub.status.idle": "2024-09-30T16:45:00.104473Z",
     "shell.execute_reply": "2024-09-30T16:45:00.103436Z"
    },
    "papermill": {
     "duration": 1.199244,
     "end_time": "2024-09-30T16:45:00.106898",
     "exception": false,
     "start_time": "2024-09-30T16:44:58.907654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cos_sims = get_cos_sim(Embedding_dataset, mean_vector)\n",
    "# class_cos_sims = {_class: [] for _class in all_classes}\n",
    "# for graph in tqdm(Embedding_dataset):\n",
    "# #     class_cos_sims[graph.y.item()].append(cos_sims[graph.id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75c76f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:02.417984Z",
     "iopub.status.busy": "2024-09-30T16:45:02.417597Z",
     "iopub.status.idle": "2024-09-30T16:45:02.422231Z",
     "shell.execute_reply": "2024-09-30T16:45:02.421248Z"
    },
    "papermill": {
     "duration": 1.2126,
     "end_time": "2024-09-30T16:45:02.424352",
     "exception": false,
     "start_time": "2024-09-30T16:45:01.211752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# z_scores = calc_z_scores(Embedding_dataset, cos_sims, class_cos_sims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f86b",
   "metadata": {
    "papermill": {
     "duration": 1.131821,
     "end_time": "2024-09-30T16:45:04.770533",
     "exception": false,
     "start_time": "2024-09-30T16:45:03.638712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Left off here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e900eba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:07.172885Z",
     "iopub.status.busy": "2024-09-30T16:45:07.172484Z",
     "iopub.status.idle": "2024-09-30T16:45:07.177217Z",
     "shell.execute_reply": "2024-09-30T16:45:07.176076Z"
    },
    "papermill": {
     "duration": 1.202177,
     "end_time": "2024-09-30T16:45:07.179500",
     "exception": false,
     "start_time": "2024-09-30T16:45:05.977323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final transform and dataset\n",
    "# Final_dataset = FinalAddingDataset(Embedding_dataset, cos_sims, z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c545e555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:09.482675Z",
     "iopub.status.busy": "2024-09-30T16:45:09.482257Z",
     "iopub.status.idle": "2024-09-30T16:45:09.486924Z",
     "shell.execute_reply": "2024-09-30T16:45:09.485861Z"
    },
    "papermill": {
     "duration": 1.198618,
     "end_time": "2024-09-30T16:45:09.489299",
     "exception": false,
     "start_time": "2024-09-30T16:45:08.290681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class_z_scores = {i: [] for i in range(5)}\n",
    "# for graph in tqdm(Final_dataset):\n",
    "#     class_z_scores[graph.y.item()].append(graph.z_score)\n",
    "# class_z_scores = {cat: np.array(scores) for cat, scores in class_z_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2a842d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:11.808435Z",
     "iopub.status.busy": "2024-09-30T16:45:11.808044Z",
     "iopub.status.idle": "2024-09-30T16:45:11.814346Z",
     "shell.execute_reply": "2024-09-30T16:45:11.812859Z"
    },
    "papermill": {
     "duration": 1.119824,
     "end_time": "2024-09-30T16:45:11.816755",
     "exception": false,
     "start_time": "2024-09-30T16:45:10.696931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Saving the dataset\n",
    "# with open('/kaggle/working/malnetProcessed.pt', 'wb') as file:\n",
    "#     torch.save(Final_dataset, file)\n",
    "    \n",
    "# with open('/kaggle/working/classCossims.pt', 'wb') as file:\n",
    "#     torch.save(class_cos_sims, file)\n",
    "    \n",
    "# with open('/kaggle/working/datasetCossims.pt', 'wb') as file:\n",
    "#     torch.save(cos_sims, file)\n",
    "    \n",
    "# with open('/kaggle/working/zScores.pt', 'wb') as file:\n",
    "#     torch.save(z_scores, file)\n",
    "    \n",
    "# with open('/kaggle/working/ClassZScores.pt', 'wb') as file:\n",
    "#     torch.save(class_z_scores, file)\n",
    "    \n",
    "# with open('/kaggle/working/meanVectors.pt', 'wb') as file:\n",
    "#     torch.save(mean_vector, file)\n",
    "\n",
    "# print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b331c525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:14.237347Z",
     "iopub.status.busy": "2024-09-30T16:45:14.236986Z",
     "iopub.status.idle": "2024-09-30T16:45:14.241631Z",
     "shell.execute_reply": "2024-09-30T16:45:14.240557Z"
    },
    "papermill": {
     "duration": 1.230443,
     "end_time": "2024-09-30T16:45:14.243853",
     "exception": false,
     "start_time": "2024-09-30T16:45:13.013410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6633549f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:16.549689Z",
     "iopub.status.busy": "2024-09-30T16:45:16.549239Z",
     "iopub.status.idle": "2024-09-30T16:45:16.554095Z",
     "shell.execute_reply": "2024-09-30T16:45:16.552907Z"
    },
    "papermill": {
     "duration": 1.206954,
     "end_time": "2024-09-30T16:45:16.556816",
     "exception": false,
     "start_time": "2024-09-30T16:45:15.349862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# type(Final_dataset[0].embedding.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baef98aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:18.878643Z",
     "iopub.status.busy": "2024-09-30T16:45:18.878254Z",
     "iopub.status.idle": "2024-09-30T16:45:18.883668Z",
     "shell.execute_reply": "2024-09-30T16:45:18.882433Z"
    },
    "papermill": {
     "duration": 1.123781,
     "end_time": "2024-09-30T16:45:18.885988",
     "exception": false,
     "start_time": "2024-09-30T16:45:17.762207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming Final_dataset is a list or dictionary containing your data\n",
    "# # Extract embeddings and labels for visualization\n",
    "\n",
    "# # Step 1: Extract embeddings and labels\n",
    "# embeddings = {x: np.zeros(Final_dataset[0].embedding.todense()[0].shape) for x in range(5)}\n",
    "# counts = {x: 0 for x in range(5)}\n",
    "# for graph in tqdm(Final_dataset):\n",
    "#     embeddings[graph.y.item()] += graph.embedding.todense()[0]\n",
    "#     counts[graph.y.item()] += 1\n",
    "# df_category_means = pd.DataFrame(embeddings).T\n",
    "\n",
    "# # Step 3: Plot heatmap of the prevalence of each dimension across categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69e2eee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:21.291460Z",
     "iopub.status.busy": "2024-09-30T16:45:21.291074Z",
     "iopub.status.idle": "2024-09-30T16:45:21.296174Z",
     "shell.execute_reply": "2024-09-30T16:45:21.294759Z"
    },
    "papermill": {
     "duration": 1.213977,
     "end_time": "2024-09-30T16:45:21.298410",
     "exception": false,
     "start_time": "2024-09-30T16:45:20.084433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf0fbb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:23.662534Z",
     "iopub.status.busy": "2024-09-30T16:45:23.662146Z",
     "iopub.status.idle": "2024-09-30T16:45:23.666985Z",
     "shell.execute_reply": "2024-09-30T16:45:23.665707Z"
    },
    "papermill": {
     "duration": 1.259882,
     "end_time": "2024-09-30T16:45:23.669717",
     "exception": false,
     "start_time": "2024-09-30T16:45:22.409835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for cat, vec in embeddings.items():\n",
    "#     print(f'Category {cat}, mean {np.mean(vec)}, max {np.max(vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f9fb304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:26.029742Z",
     "iopub.status.busy": "2024-09-30T16:45:26.029278Z",
     "iopub.status.idle": "2024-09-30T16:45:26.033997Z",
     "shell.execute_reply": "2024-09-30T16:45:26.032898Z"
    },
    "papermill": {
     "duration": 1.125438,
     "end_time": "2024-09-30T16:45:26.036327",
     "exception": false,
     "start_time": "2024-09-30T16:45:24.910889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for k, v in embeddings.items():\n",
    "#     embeddings[k] = v/counts[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9cc1a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:28.423124Z",
     "iopub.status.busy": "2024-09-30T16:45:28.422724Z",
     "iopub.status.idle": "2024-09-30T16:45:28.427621Z",
     "shell.execute_reply": "2024-09-30T16:45:28.426467Z"
    },
    "papermill": {
     "duration": 1.205295,
     "end_time": "2024-09-30T16:45:28.430065",
     "exception": false,
     "start_time": "2024-09-30T16:45:27.224770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for cat, vec in embeddings.items():\n",
    "#     print(f'Category {cat}, mean {np.mean(vec)}, max {np.max(vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a949f15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:30.758870Z",
     "iopub.status.busy": "2024-09-30T16:45:30.757521Z",
     "iopub.status.idle": "2024-09-30T16:45:30.763887Z",
     "shell.execute_reply": "2024-09-30T16:45:30.762391Z"
    },
    "papermill": {
     "duration": 1.222546,
     "end_time": "2024-09-30T16:45:30.766762",
     "exception": false,
     "start_time": "2024-09-30T16:45:29.544216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e56ad417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:33.163915Z",
     "iopub.status.busy": "2024-09-30T16:45:33.163489Z",
     "iopub.status.idle": "2024-09-30T16:45:33.168365Z",
     "shell.execute_reply": "2024-09-30T16:45:33.167062Z"
    },
    "papermill": {
     "duration": 1.156761,
     "end_time": "2024-09-30T16:45:33.171245",
     "exception": false,
     "start_time": "2024-09-30T16:45:32.014484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_mean = np.zeros(embeddings[0].shape)\n",
    "# for cat, vec in embeddings.items():\n",
    "#     total_mean += vec\n",
    "# total_mean /= 5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "510c5680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:35.613864Z",
     "iopub.status.busy": "2024-09-30T16:45:35.613124Z",
     "iopub.status.idle": "2024-09-30T16:45:35.617785Z",
     "shell.execute_reply": "2024-09-30T16:45:35.616659Z"
    },
    "papermill": {
     "duration": 1.209623,
     "end_time": "2024-09-30T16:45:35.619937",
     "exception": false,
     "start_time": "2024-09-30T16:45:34.410314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# difference_embeddings= {}\n",
    "# for cat in range(5):\n",
    "#     difference_embeddings[cat] = embeddings[cat]-total_mean\n",
    "# df_diff_means = pd.DataFrame(embeddings).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b355830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:37.918199Z",
     "iopub.status.busy": "2024-09-30T16:45:37.917826Z",
     "iopub.status.idle": "2024-09-30T16:45:37.922983Z",
     "shell.execute_reply": "2024-09-30T16:45:37.921836Z"
    },
    "papermill": {
     "duration": 1.196256,
     "end_time": "2024-09-30T16:45:37.925280",
     "exception": false,
     "start_time": "2024-09-30T16:45:36.729024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib.colors import LogNorm\n",
    "\n",
    "# plt.figure(figsize=(20, 5))\n",
    "# # LogNorm is used for logarithmic color scaling\n",
    "# sns.heatmap(df_diff_means, cmap='hsv', norm=LogNorm(vmin=1e-6, vmax=500), annot=False, cbar=True, cbar_kws={\"label\": \"Mean prevalence by dimension\"})\n",
    "# plt.title(\"Mean Embedding Vectors by Category\", fontsize=30)\n",
    "# plt.xlabel(\"Embedding Dimension\", fontsize=16)\n",
    "# plt.ylabel(\"Classification Category\", fontsize=16)\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c87e640f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:40.246220Z",
     "iopub.status.busy": "2024-09-30T16:45:40.245782Z",
     "iopub.status.idle": "2024-09-30T16:45:40.252019Z",
     "shell.execute_reply": "2024-09-30T16:45:40.250794Z"
    },
    "papermill": {
     "duration": 1.129457,
     "end_time": "2024-09-30T16:45:40.254422",
     "exception": false,
     "start_time": "2024-09-30T16:45:39.124965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "# # Scaling options:\n",
    "# # Option 1: Z-Score Normalization (StandardScaler)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Option 2: Robust Scaling (based on IQR to handle outliers)\n",
    "# # scaler = RobustScaler()\n",
    "\n",
    "# # Normalize the embeddings by category (per row) using the chosen scaler\n",
    "# df_normalized = pd.DataFrame(scaler.fit_transform(df_category_means.T).T, columns=df_category_means.columns)\n",
    "\n",
    "# # Plotting each category's spectrum in separate plots, ignoring zero values\n",
    "# for category in df_normalized.index:\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "    \n",
    "#     # Get the spectrum values and remove zero values\n",
    "#     spectrum_values = df_normalized.loc[category]\n",
    "#     not_small_indices = spectrum_values > 0.3\n",
    "#     not_big_indices = spectrum_values < 50\n",
    "#     just_right_indices = not_small_indices & not_big_indices\n",
    "#     spectrum_values_non_zero = spectrum_values[just_right_indices]\n",
    "#     dimensions_non_zero = df_normalized.columns[just_right_indices]\n",
    "    \n",
    "#     # Plot the spectrum for this category\n",
    "#     plt.plot(dimensions_non_zero, spectrum_values_non_zero, label=f'Category {category}', linewidth=2)\n",
    "    \n",
    "#     # Add labels and title\n",
    "#     plt.xlabel('Embedding Dimensions')\n",
    "#     plt.ylabel('Scaled Value')\n",
    "#     plt.title(f'Scaled Spectrum for Category {category}')\n",
    "#     plt.grid(True)\n",
    "    \n",
    "#     # Show the plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75179783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:42.647292Z",
     "iopub.status.busy": "2024-09-30T16:45:42.646893Z",
     "iopub.status.idle": "2024-09-30T16:45:42.652895Z",
     "shell.execute_reply": "2024-09-30T16:45:42.651739Z"
    },
    "papermill": {
     "duration": 1.210493,
     "end_time": "2024-09-30T16:45:42.655214",
     "exception": false,
     "start_time": "2024-09-30T16:45:41.444721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Min-Max scaling for each category individually\n",
    "# scalers = {}\n",
    "# df_scaled = pd.DataFrame()\n",
    "\n",
    "# # Apply Min-Max scaling for each category\n",
    "# for category in df_category_means.index:\n",
    "#     scaler = MinMaxScaler()\n",
    "#     scaled_values = scaler.fit_transform(df_category_means.loc[category].values.reshape(-1, 1)).flatten()\n",
    "#     df_scaled[category] = scaled_values\n",
    "\n",
    "# df_scaled = df_scaled.T  # Transpose back so categories are rows\n",
    "\n",
    "# # Plotting all categories on the same chart with different colors\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Colors for each category\n",
    "# colors = plt.cm.hsv(np.linspace(0, 0.8, len(df_scaled.index)))\n",
    "\n",
    "# # Plot each category's spectrum as a line\n",
    "# for idx, category in enumerate(df_scaled.index):\n",
    "#     # Get the spectrum values and remove zero values\n",
    "#     spectrum_values = df_scaled.loc[category]\n",
    "#     non_zero_indices = spectrum_values > 0.001\n",
    "#     too_big_indices = spectrum_values < 0.8\n",
    "#     my_indices = non_zero_indices & too_big_indices\n",
    "#     spectrum_values_non_zero = spectrum_values[my_indices]\n",
    "#     dimensions_non_zero = df_scaled.columns[my_indices]\n",
    "    \n",
    "#     # Plot the spectrum for this category with a unique color\n",
    "#     plt.plot(dimensions_non_zero, spectrum_values_non_zero, color=colors[idx], label=f'Category {category}', linewidth=1)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Embedding Dimensions')\n",
    "# plt.ylabel('Min-Max Scaled Value')\n",
    "# plt.title('Scaled Spectra of Mean Embeddings by Category')\n",
    "# plt.grid(True)\n",
    "# plt.yscale('log')\n",
    "\n",
    "# # Show the legend\n",
    "# plt.legend(title='Category')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "473fdf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:44.975340Z",
     "iopub.status.busy": "2024-09-30T16:45:44.974953Z",
     "iopub.status.idle": "2024-09-30T16:45:44.980490Z",
     "shell.execute_reply": "2024-09-30T16:45:44.979416Z"
    },
    "papermill": {
     "duration": 1.202198,
     "end_time": "2024-09-30T16:45:44.982756",
     "exception": false,
     "start_time": "2024-09-30T16:45:43.780558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Extract embeddings and labels\n",
    "# # This will use the 'embeddings' and 'labels' you already have in your dataset\n",
    "# X = np.array(embeddings.values())  # X has shape (600, 27816)\n",
    "# y = np.array(embeddings.keys())  # Labels for each embedding\n",
    "\n",
    "# # Step 2: Apply t-SNE to reduce dimensions\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000, metric='cosine')\n",
    "# X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# # Step 3: Create a DataFrame with the results\n",
    "# df_tsne = pd.DataFrame(X_tsne, columns=['t-SNE 1', 't-SNE 2'])\n",
    "# df_tsne['label'] = y\n",
    "\n",
    "# # Step 4: Plot the t-SNE results using seaborn\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.scatterplot(x='t-SNE 1', y='t-SNE 2', hue='label', palette='tab10', data=df_tsne, s=60)\n",
    "# plt.title(\"t-SNE Visualization of Embeddings\", fontsize=16)\n",
    "# plt.xlabel(\"t-SNE 1\", fontsize=12)\n",
    "# plt.ylabel(\"t-SNE 2\", fontsize=12)\n",
    "# plt.legend(title=\"Category\", loc='best')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b63e7318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:47.291186Z",
     "iopub.status.busy": "2024-09-30T16:45:47.290812Z",
     "iopub.status.idle": "2024-09-30T16:45:47.296223Z",
     "shell.execute_reply": "2024-09-30T16:45:47.294887Z"
    },
    "papermill": {
     "duration": 1.115111,
     "end_time": "2024-09-30T16:45:47.298659",
     "exception": false,
     "start_time": "2024-09-30T16:45:46.183548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming embeddings are already extracted in `X` (shape: 600 embeddings, 27816 dimensions)\n",
    "# # We'll calculate the correlation matrix across all embedding dimensions\n",
    "\n",
    "# # Step 1: Convert embeddings to DataFrame for easier manipulation\n",
    "# df_embeddings = pd.DataFrame(X)  # X has shape (600, 27816), where each column is a dimension\n",
    "\n",
    "# # Step 2: Calculate the correlation matrix\n",
    "# corr_matrix = df_embeddings.corr()\n",
    "\n",
    "# # Step 3: Plot the correlation matrix using seaborn heatmap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(corr_matrix, cmap='coolwarm', annot=False, linewidths=0.5)\n",
    "# plt.title(\"Correlation Matrix of Embedding Dimensions\", fontsize=16)\n",
    "# plt.xlabel(\"Embedding Dimension\", fontsize=12)\n",
    "# plt.ylabel(\"Embedding Dimension\", fontsize=12)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4432d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:49.678754Z",
     "iopub.status.busy": "2024-09-30T16:45:49.678346Z",
     "iopub.status.idle": "2024-09-30T16:45:49.682952Z",
     "shell.execute_reply": "2024-09-30T16:45:49.681946Z"
    },
    "papermill": {
     "duration": 1.19621,
     "end_time": "2024-09-30T16:45:49.685323",
     "exception": false,
     "start_time": "2024-09-30T16:45:48.489113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cos_sims = {i: [] for i in range(5)}\n",
    "# for graph in tqdm(Final_dataset):\n",
    "#     cos_sims[graph.y.item()].append(graph.cos_sim)\n",
    "    \n",
    "# cos_sims = {i: np.array(cos_sims[i]) for i in cos_sims.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c107c6",
   "metadata": {
    "papermill": {
     "duration": 1.199185,
     "end_time": "2024-09-30T16:45:51.990026",
     "exception": false,
     "start_time": "2024-09-30T16:45:50.790841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3dee5b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:54.310750Z",
     "iopub.status.busy": "2024-09-30T16:45:54.310034Z",
     "iopub.status.idle": "2024-09-30T16:45:54.315989Z",
     "shell.execute_reply": "2024-09-30T16:45:54.314968Z"
    },
    "papermill": {
     "duration": 1.137454,
     "end_time": "2024-09-30T16:45:54.318489",
     "exception": false,
     "start_time": "2024-09-30T16:45:53.181035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "\n",
    "# num_buckets = 40  # 100 bins for increments of 0.01\n",
    "# bin_edges = np.linspace(0, 1, num_buckets + 1)  # Create bin edges from 0 to 1 in increments of 0.01\n",
    "\n",
    "# # Create a color map for different categories\n",
    "# colors = cm.viridis(np.linspace(0, 1, 5))  # Assuming 5 categories\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Loop through each category and plot their fill-between curve\n",
    "# for i in range(5):\n",
    "#     # Get the cosine similarity values for the current category\n",
    "#     cos_sim_values = np.array(cos_sims[i])\n",
    "    \n",
    "#     # Use np.histogram to calculate the counts in each bucket (bin)\n",
    "#     counts, _ = np.histogram(cos_sim_values, bins=bin_edges)\n",
    "    \n",
    "#     # The midpoint of each bin for plotting on the x-axis\n",
    "#     bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "#     # Use plt.fill_between to create smooth curves for each category\n",
    "#     plt.fill_between(bin_centers, counts, color=colors[i], alpha=0.8, label=f'Category {i}')\n",
    "    \n",
    "#     # Plot smooth line over the fill_between\n",
    "#     plt.plot(bin_centers, counts, color=colors[i], linewidth=2, alpha=0.8)\n",
    "\n",
    "# # Customize the appearance of the plot\n",
    "# plt.xlabel('Cosine Similarity', fontsize=16, color='white')\n",
    "# plt.ylabel('Count', fontsize=16, color='white')\n",
    "# plt.title('Cosine Similarity Distribution for All Categories', fontsize=20, color='white')\n",
    "\n",
    "# # Set a dark background and gridlines for a more visually engaging look\n",
    "# plt.style.use('dark_background')\n",
    "# plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.8)\n",
    "\n",
    "# # Set the x-axis limits and style\n",
    "# plt.xlim(0.13, 1)\n",
    "\n",
    "# # Show the legend to differentiate the categories\n",
    "# plt.legend(title='Category', fontsize=12)\n",
    "# plt.yscale('log')\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc806fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:56.768389Z",
     "iopub.status.busy": "2024-09-30T16:45:56.768001Z",
     "iopub.status.idle": "2024-09-30T16:45:56.774104Z",
     "shell.execute_reply": "2024-09-30T16:45:56.772976Z"
    },
    "papermill": {
     "duration": 1.213514,
     "end_time": "2024-09-30T16:45:56.776648",
     "exception": false,
     "start_time": "2024-09-30T16:45:55.563134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `Final_dataset` contains distribution scores for each embedding\n",
    "\n",
    "# # Step 1: Extract distribution scores and labels\n",
    "# distribution_scores = []\n",
    "# labels = []\n",
    "\n",
    "# for data in Final_dataset:\n",
    "#     score = data.z_score  # Assuming 'z_score' stores the distribution score for each embedding\n",
    "#     label = int(data.y.item())  # Extract the class label\n",
    "    \n",
    "#     distribution_scores.append(score)\n",
    "#     labels.append(label)\n",
    "\n",
    "# # Convert to numpy arrays for easier manipulation\n",
    "# distribution_scores = np.array(distribution_scores)\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# # Step 2: Create a DataFrame for easier plotting\n",
    "# df_scores = pd.DataFrame({\n",
    "#     'distribution_score': distribution_scores,\n",
    "#     'label': labels\n",
    "# })\n",
    "\n",
    "# # Step 3: Plot KDE for each category\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.kdeplot(data=df_scores, x='distribution_score', hue='label', fill=True, palette='tab10')\n",
    "# plt.title(\"KDE Plot of Distribution Scores by Category\", fontsize=16)\n",
    "# plt.xlabel(\"Distribution Score\", fontsize=12)\n",
    "# plt.ylabel(\"Density\", fontsize=12)\n",
    "# plt.legend(title=\"Category\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "935cde6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:45:59.072333Z",
     "iopub.status.busy": "2024-09-30T16:45:59.071946Z",
     "iopub.status.idle": "2024-09-30T16:45:59.077698Z",
     "shell.execute_reply": "2024-09-30T16:45:59.076516Z"
    },
    "papermill": {
     "duration": 1.19185,
     "end_time": "2024-09-30T16:45:59.080007",
     "exception": false,
     "start_time": "2024-09-30T16:45:57.888157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Step 3: Define a list of colormaps for each category\n",
    "# colormaps = ['Reds', 'Blues', 'Greens', 'Purples', 'Oranges', 'YlOrRd']  # List of colormaps\n",
    "# fig, ax = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "# # Plot each category's heatmap on the same figure, one after the other\n",
    "# num_categories = len(unique_labels)\n",
    "# step = df_category_means.shape[0] // num_categories  # Calculate the step for splitting the x-axis\n",
    "# for i, label in enumerate(unique_labels):\n",
    "#     # Define the range of columns for this category\n",
    "#     category_range = range(i * step, (i + 1) * step)\n",
    "#     # Select the subset of the DataFrame for this category\n",
    "#     data_subset = df_category_means.iloc[:, [i]]\n",
    "#     # Plot the heatmap for the current category using a different colormap\n",
    "#     sns.heatmap(data_subset.T, cmap=colormaps[i % len(colormaps)], norm=LogNorm(vmin=1e-4, vmax=np.max(df_category_means.values)),\n",
    "#                 annot=False, cbar=(i == num_categories - 1), ax=ax,\n",
    "#                 yticklabels=False, xticklabels=False, cbar_kws={'orientation': 'vertical'})\n",
    "\n",
    "# # Customize the overall plot\n",
    "# ax.set_title(\"Heatmap with Different Colormaps for Each Category\", fontsize=16)\n",
    "# ax.set_xlabel(\"Embedding Dimension\", fontsize=12)\n",
    "# ax.set_ylabel(\"Classification Category\", fontsize=12)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15b89ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:01.380770Z",
     "iopub.status.busy": "2024-09-30T16:46:01.380342Z",
     "iopub.status.idle": "2024-09-30T16:46:01.385089Z",
     "shell.execute_reply": "2024-09-30T16:46:01.383758Z"
    },
    "papermill": {
     "duration": 1.114736,
     "end_time": "2024-09-30T16:46:01.387448",
     "exception": false,
     "start_time": "2024-09-30T16:46:00.272712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final_dataset[8]\n",
    "# high_graph = nx.from_numpy_array(Final_dataset[8].adj_mat)\n",
    "# nx.draw_kamada_kawai(high_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e02661cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:03.811759Z",
     "iopub.status.busy": "2024-09-30T16:46:03.811348Z",
     "iopub.status.idle": "2024-09-30T16:46:03.816330Z",
     "shell.execute_reply": "2024-09-30T16:46:03.815167Z"
    },
    "papermill": {
     "duration": 1.234543,
     "end_time": "2024-09-30T16:46:03.818720",
     "exception": false,
     "start_time": "2024-09-30T16:46:02.584177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# low_embedding = Final_dataset[2].embedding[0]\n",
    "# high_embedding = Final_dataset[8].embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "114065d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:06.124107Z",
     "iopub.status.busy": "2024-09-30T16:46:06.123703Z",
     "iopub.status.idle": "2024-09-30T16:46:06.128501Z",
     "shell.execute_reply": "2024-09-30T16:46:06.127394Z"
    },
    "papermill": {
     "duration": 1.194343,
     "end_time": "2024-09-30T16:46:06.131078",
     "exception": false,
     "start_time": "2024-09-30T16:46:04.936735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set(low_embedding.keys()) & set(high_embedding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b43f0c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:08.443322Z",
     "iopub.status.busy": "2024-09-30T16:46:08.442934Z",
     "iopub.status.idle": "2024-09-30T16:46:08.447503Z",
     "shell.execute_reply": "2024-09-30T16:46:08.446472Z"
    },
    "papermill": {
     "duration": 1.119121,
     "end_time": "2024-09-30T16:46:08.449824",
     "exception": false,
     "start_time": "2024-09-30T16:46:07.330703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sorted(high_embedding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bc859a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:10.843363Z",
     "iopub.status.busy": "2024-09-30T16:46:10.842986Z",
     "iopub.status.idle": "2024-09-30T16:46:10.847610Z",
     "shell.execute_reply": "2024-09-30T16:46:10.846644Z"
    },
    "papermill": {
     "duration": 1.207684,
     "end_time": "2024-09-30T16:46:10.849834",
     "exception": false,
     "start_time": "2024-09-30T16:46:09.642150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(high_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dde621a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:13.147662Z",
     "iopub.status.busy": "2024-09-30T16:46:13.147263Z",
     "iopub.status.idle": "2024-09-30T16:46:13.152044Z",
     "shell.execute_reply": "2024-09-30T16:46:13.150835Z"
    },
    "papermill": {
     "duration": 1.204391,
     "end_time": "2024-09-30T16:46:13.154538",
     "exception": false,
     "start_time": "2024-09-30T16:46:11.950147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(low_embedding and high_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac1e731d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:15.479174Z",
     "iopub.status.busy": "2024-09-30T16:46:15.478138Z",
     "iopub.status.idle": "2024-09-30T16:46:15.483221Z",
     "shell.execute_reply": "2024-09-30T16:46:15.482095Z"
    },
    "papermill": {
     "duration": 1.112991,
     "end_time": "2024-09-30T16:46:15.485489",
     "exception": false,
     "start_time": "2024-09-30T16:46:14.372498",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(low_embedding.symmetric_difference(high_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f13dfb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:17.884259Z",
     "iopub.status.busy": "2024-09-30T16:46:17.883862Z",
     "iopub.status.idle": "2024-09-30T16:46:17.888950Z",
     "shell.execute_reply": "2024-09-30T16:46:17.887665Z"
    },
    "papermill": {
     "duration": 1.211755,
     "end_time": "2024-09-30T16:46:17.891634",
     "exception": false,
     "start_time": "2024-09-30T16:46:16.679879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common_embeddings = set(low_embedding.keys()) and set(high_embedding.keys())\n",
    "# both_embeddings = set(low_embedding.keys()) or set(high_embedding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ba57cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:20.198177Z",
     "iopub.status.busy": "2024-09-30T16:46:20.197779Z",
     "iopub.status.idle": "2024-09-30T16:46:20.202815Z",
     "shell.execute_reply": "2024-09-30T16:46:20.201668Z"
    },
    "papermill": {
     "duration": 1.196163,
     "end_time": "2024-09-30T16:46:20.205120",
     "exception": false,
     "start_time": "2024-09-30T16:46:19.008957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set(low_embedding.keys()).symmetric_difference(set(high_embedding.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a6c591c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:22.536232Z",
     "iopub.status.busy": "2024-09-30T16:46:22.535852Z",
     "iopub.status.idle": "2024-09-30T16:46:22.540810Z",
     "shell.execute_reply": "2024-09-30T16:46:22.539305Z"
    },
    "papermill": {
     "duration": 1.123477,
     "end_time": "2024-09-30T16:46:22.543176",
     "exception": false,
     "start_time": "2024-09-30T16:46:21.419699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# both_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82f79dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:24.963435Z",
     "iopub.status.busy": "2024-09-30T16:46:24.963010Z",
     "iopub.status.idle": "2024-09-30T16:46:24.968128Z",
     "shell.execute_reply": "2024-09-30T16:46:24.966992Z"
    },
    "papermill": {
     "duration": 1.20777,
     "end_time": "2024-09-30T16:46:24.970726",
     "exception": false,
     "start_time": "2024-09-30T16:46:23.762956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set(both_embeddings - common_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9558791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:27.359012Z",
     "iopub.status.busy": "2024-09-30T16:46:27.358635Z",
     "iopub.status.idle": "2024-09-30T16:46:27.364512Z",
     "shell.execute_reply": "2024-09-30T16:46:27.363440Z"
    },
    "papermill": {
     "duration": 1.279012,
     "end_time": "2024-09-30T16:46:27.366941",
     "exception": false,
     "start_time": "2024-09-30T16:46:26.087929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_node_dict = {_cls: {graph.id: graph.num_nodes for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "# num_node_mean_dict = {_cls: sum(num_node_dict[_cls].values())/len(num_node_dict[_cls].values()) for _cls in all_classes}\n",
    "# node_diff_dict = {_cls: {graph.id: graph.num_nodes - num_node_mean_dict[_cls] for graph in Final_dataset if graph.y.item() == _cls or _cls == 'all'} for _cls in all_classes}\n",
    "# pos_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "# neg_diff_dict = {_cls: {} for _cls in all_classes}\n",
    "# for _cls, _dict in node_diff_dict.items():\n",
    "#     for idx, node_diff in _dict.items():\n",
    "#         if node_diff > 0:\n",
    "#             pos_diff_dict[_cls][idx] = node_diff\n",
    "#         else:\n",
    "#             pos_diff_dict[_cls][idx] = node_diff\n",
    "# pos_num_node_dict = {_cls: len(pos_diff_dict[_cls]) for _cls in all_classes}\n",
    "# neg_num_node_dict = {_cls: len(neg_diff_dict[_cls]) for _cls in all_classes}\n",
    "# percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "# for _cls, _dict in pos_diff_dict.items():\n",
    "#     for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "#         if _cls != 'all':\n",
    "#             percentile_dict[idx]['class'] = i/pos_num_node_dict[_cls]\n",
    "#         else:\n",
    "#             percentile_dict[idx]['all'] = i/pos_num_node_dict[_cls]\n",
    "# for _cls, _dict in neg_diff_dict.items():\n",
    "#     for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1], reverse=True)):\n",
    "#         if _cls != 'all':\n",
    "#             percentile_dict[idx]['class'] = i/neg_num_node_dict[_cls]\n",
    "#         else:\n",
    "#             percentile_dict[idx]['all'] = i/neg_num_node_dict[_cls]\n",
    "    \n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34a1192d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:29.697171Z",
     "iopub.status.busy": "2024-09-30T16:46:29.696797Z",
     "iopub.status.idle": "2024-09-30T16:46:29.701457Z",
     "shell.execute_reply": "2024-09-30T16:46:29.700400Z"
    },
    "papermill": {
     "duration": 1.114832,
     "end_time": "2024-09-30T16:46:29.703632",
     "exception": false,
     "start_time": "2024-09-30T16:46:28.588800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_node_percentile_dict = percentile_dict\n",
    "# for x in range(20):\n",
    "#     print(num_node_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33e3b543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:32.097968Z",
     "iopub.status.busy": "2024-09-30T16:46:32.097593Z",
     "iopub.status.idle": "2024-09-30T16:46:32.103002Z",
     "shell.execute_reply": "2024-09-30T16:46:32.101672Z"
    },
    "papermill": {
     "duration": 1.210484,
     "end_time": "2024-09-30T16:46:32.105418",
     "exception": false,
     "start_time": "2024-09-30T16:46:30.894934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cos_sim_dict = {_cls: {} for _cls in all_classes}\n",
    "# for graph in Final_dataset:\n",
    "#     cos_sim_dict[graph.y.item()][graph.id] = graph.cos_sim['class']\n",
    "#     cos_sim_dict['all'][graph.id] = graph.cos_sim['all']\n",
    "            \n",
    "\n",
    "# cat_len_dict = {_cls: len(cos_sim_dict[_cls].values()) for _cls in all_classes}\n",
    "# cos_sim_percentile_dict = {graph.id: {'all': 0, 'class': 0} for graph in Final_dataset}\n",
    "\n",
    "\n",
    "# for _cls, _dict in cos_sim_dict.items():\n",
    "#     for i, (idx, val) in enumerate(sorted(_dict.items(), key = lambda x: x[1])):\n",
    "#         if _cls != 'all':\n",
    "#             cos_sim_percentile_dict[idx]['class'] = i/cat_len_dict[_cls]\n",
    "#         else:\n",
    "#             cos_sim_percentile_dict[idx]['all'] = i/cat_len_dict[_cls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3893e1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:34.431979Z",
     "iopub.status.busy": "2024-09-30T16:46:34.431598Z",
     "iopub.status.idle": "2024-09-30T16:46:34.436644Z",
     "shell.execute_reply": "2024-09-30T16:46:34.435288Z"
    },
    "papermill": {
     "duration": 1.217372,
     "end_time": "2024-09-30T16:46:34.439005",
     "exception": false,
     "start_time": "2024-09-30T16:46:33.221633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in range(10):\n",
    "#     print(cos_sim_percentile_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f6e2e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:36.748360Z",
     "iopub.status.busy": "2024-09-30T16:46:36.747520Z",
     "iopub.status.idle": "2024-09-30T16:46:36.752921Z",
     "shell.execute_reply": "2024-09-30T16:46:36.751760Z"
    },
    "papermill": {
     "duration": 1.110945,
     "end_time": "2024-09-30T16:46:36.755130",
     "exception": false,
     "start_time": "2024-09-30T16:46:35.644185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# percentiles = [x for x in range(35, 91, 5)]\n",
    "# cats = ['class', 'all']\n",
    "# metrics = ['random', 'graph_order', 'cos_sim']\n",
    "# train_indices_dict = {cat: {metric: {percentile: [] for percentile in percentiles} for metric in metrics} for cat in cats}\n",
    "# for percentile in percentiles:\n",
    "#     for idx, cat_pairs in cos_sim_percentile_dict.items():\n",
    "#         for cat, val in cat_pairs.items():\n",
    "#             if val < 0.01*percentile:\n",
    "#                 train_indices_dict[cat]['cos_sim'][percentile].append(idx)\n",
    "#     for idx, cat_pairs in num_node_percentile_dict.items():\n",
    "#         for cat, val in cat_pairs.items():\n",
    "#             if val < 0.01* percentile:\n",
    "#                 train_indices_dict[cat]['graph_order'][percentile].append(idx)\n",
    "#     for _cls, id_pairs in num_node_dict.items():\n",
    "#         for cat in cats:\n",
    "#             size = int(percentile * 0.01 * len(id_pairs))\n",
    "#             train_indices_dict[cat]['random'][percentile] = np.random.choice(list(id_pairs.keys()), size, replace=False)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c493092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:39.137259Z",
     "iopub.status.busy": "2024-09-30T16:46:39.136905Z",
     "iopub.status.idle": "2024-09-30T16:46:39.141430Z",
     "shell.execute_reply": "2024-09-30T16:46:39.140398Z"
    },
    "papermill": {
     "duration": 1.20728,
     "end_time": "2024-09-30T16:46:39.143551",
     "exception": false,
     "start_time": "2024-09-30T16:46:37.936271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Specify the path to the file where you want to save the dataset\n",
    "# file_path = f'/kaggle/working/{DATASET}_train_indices_dict.pkl'\n",
    "\n",
    "# # Saving the dataset\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     pickle.dump(train_indices_dict, file)\n",
    "\n",
    "# print(\"Dict saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f099ff76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:41.437604Z",
     "iopub.status.busy": "2024-09-30T16:46:41.437212Z",
     "iopub.status.idle": "2024-09-30T16:46:41.442567Z",
     "shell.execute_reply": "2024-09-30T16:46:41.441464Z"
    },
    "papermill": {
     "duration": 1.201423,
     "end_time": "2024-09-30T16:46:41.444943",
     "exception": false,
     "start_time": "2024-09-30T16:46:40.243520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # for x in range(6):\n",
    "# all_z_scores = [graph.num_nodes for graph in Final_dataset]\n",
    "# num_node_mean = sum(all_z_scores)/600\n",
    "# all_z_scores = [x - num_node_mean for x in all_z_scores]\n",
    "# percentiles = [50, 95, 99]  # Change these values based on your requirements (xx%)\n",
    "# percentile_values = np.percentile(all_z_scores, percentiles)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_z_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "# plt.title('Histogram of Z-Scores with Percentiles')\n",
    "# plt.xlabel('Z-Score')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# # Add vertical lines for each percentile\n",
    "# for perc, value in zip(percentiles, percentile_values):\n",
    "#     plt.axvline(x=value, color='r', linestyle='--', label=f'{perc}th percentile: {value:.2f}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b023b9ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:43.779653Z",
     "iopub.status.busy": "2024-09-30T16:46:43.779153Z",
     "iopub.status.idle": "2024-09-30T16:46:43.783894Z",
     "shell.execute_reply": "2024-09-30T16:46:43.782732Z"
    },
    "papermill": {
     "duration": 1.146308,
     "end_time": "2024-09-30T16:46:43.786274",
     "exception": false,
     "start_time": "2024-09-30T16:46:42.639966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Specify the path to the file where you want to save the dataset\n",
    "# file_path = f'/kaggle/working/{DATASET}.pt'\n",
    "\n",
    "# # Saving the dataset\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     torch.save(Final_dataset, file)\n",
    "\n",
    "# print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c158fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-30T16:46:46.182424Z",
     "iopub.status.busy": "2024-09-30T16:46:46.181650Z",
     "iopub.status.idle": "2024-09-30T16:46:46.186651Z",
     "shell.execute_reply": "2024-09-30T16:46:46.185618Z"
    },
    "papermill": {
     "duration": 1.204872,
     "end_time": "2024-09-30T16:46:46.189157",
     "exception": false,
     "start_time": "2024-09-30T16:46:44.984285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the directory you want to list\n",
    "# directory_path = '/kaggle/working/'\n",
    "\n",
    "# # List all files and directories in the specified path\n",
    "# contents = os.listdir(directory_path)\n",
    "\n",
    "# print(\"Contents of '/kaggle/working/':\")\n",
    "# for item in contents:\n",
    "#     print(item)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4481.879969,
   "end_time": "2024-09-30T16:46:48.736281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-30T15:32:06.856312",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
